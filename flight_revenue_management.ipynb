{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Overview** \n",
    "This notebook aims to analyze and predict seat sales and fare prices for specific flights in August 2019, based on historical data from June 2019. The primary objective is to compare real-life results with predictions generated by different modeling approaches.\n",
    "\n",
    "For a summary of the results, please head to the Conclusion section. \n",
    "\n",
    "**Real-Life Data**\n",
    "\n",
    "The dataset provides the actual sales data for the months of June 2019 and a partial of August 2019. It includes information on:\n",
    "\n",
    "- **Flight Numbers** (e.g., TR 202, TR 203)\n",
    "- **Seat Capacity** for each flight (180 max)\n",
    "- **Segment City Pairs** (e.g., SINPNH, PNHSIN)\n",
    "- **Seats Sold**\n",
    "- **Average Fare** in SGD for each flight segment\n",
    "\n",
    "This data serves as the benchmark against which the prediction models will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Data DataFrame:\n",
      "     BookingDate DepartureDate Flight Number  Seat Capacity SegmentCityPair  \\\n",
      "0     2018-08-03    2019-06-25        TR 202            180          SINPNH   \n",
      "1     2018-08-03    2019-06-29        TR 203            180          PNHSIN   \n",
      "2     2018-08-06    2019-06-11        TR 202            180          SINPNH   \n",
      "3     2018-08-09    2019-06-11        TR 202            180          SINPNH   \n",
      "4     2018-09-26    2019-06-09        TR 202            180          SINPNH   \n",
      "...          ...           ...           ...            ...             ...   \n",
      "2555  2019-06-28    2019-06-30        TR 203            180          PNHSIN   \n",
      "2556  2019-06-29    2019-06-29        TR 203            180          PNHSIN   \n",
      "2557  2019-06-29    2019-06-30        TR 202            180          SINPNH   \n",
      "2558  2019-06-29    2019-06-30        TR 203            180          PNHSIN   \n",
      "2559  2019-06-30    2019-06-30        TR 202            180          SINPNH   \n",
      "\n",
      "      Seats Sold  AverageFare (SGD)  Unnamed: 7  Unnamed: 8  \\\n",
      "0              1             3.7000         NaN         NaN   \n",
      "1              1             6.4349         NaN         NaN   \n",
      "2              2            41.7000         NaN         NaN   \n",
      "3              1            63.7000         NaN         NaN   \n",
      "4              1            46.7152         NaN         NaN   \n",
      "...          ...                ...         ...         ...   \n",
      "2555           1           198.2085         NaN         NaN   \n",
      "2556           1            60.9113         NaN         NaN   \n",
      "2557           8            26.7375         NaN         NaN   \n",
      "2558           1           198.2085         NaN         NaN   \n",
      "2559           1            41.7000         NaN         NaN   \n",
      "\n",
      "                                             Unnamed: 9  \n",
      "0                                                   NaN  \n",
      "1                                                 Notes  \n",
      "2     Each line of data shows a summary of bookings ...  \n",
      "3                                          BookingDate   \n",
      "4                                        Departure Date  \n",
      "...                                                 ...  \n",
      "2555                                                NaN  \n",
      "2556                                                NaN  \n",
      "2557                                                NaN  \n",
      "2558                                                NaN  \n",
      "2559                                                NaN  \n",
      "\n",
      "[2560 rows x 10 columns]\n",
      "\n",
      "Future Flights DataFrame:\n",
      "   DepartureDate Flight Number  Seat Capacity SegmentCityPair  Seats Sold  \\\n",
      "0     2019-08-04        TR 202            180          SINPNH          50   \n",
      "1     2019-08-04        TR 203            180          PNHSIN          52   \n",
      "2     2019-08-05        TR 202            180          SINPNH          59   \n",
      "3     2019-08-05        TR 203            180          PNHSIN          27   \n",
      "4     2019-08-06        TR 202            180          SINPNH          67   \n",
      "5     2019-08-06        TR 203            180          PNHSIN          49   \n",
      "6     2019-08-07        TR 202            180          SINPNH          59   \n",
      "7     2019-08-07        TR 203            180          PNHSIN          42   \n",
      "8     2019-08-08        TR 202            180          SINPNH          54   \n",
      "9     2019-08-08        TR 203            180          PNHSIN          57   \n",
      "10    2019-08-09        TR 202            180          SINPNH          98   \n",
      "11    2019-08-09        TR 203            180          PNHSIN          56   \n",
      "12    2019-08-10        TR 202            180          SINPNH          46   \n",
      "13    2019-08-10        TR 203            180          PNHSIN          63   \n",
      "14    2019-08-11        TR 202            180          SINPNH          38   \n",
      "15    2019-08-11        TR 203            180          PNHSIN          44   \n",
      "16    2019-08-12        TR 202            180          SINPNH          29   \n",
      "17    2019-08-12        TR 203            180          PNHSIN          87   \n",
      "\n",
      "    AverageFare (SGD)  Unnamed: 6  \\\n",
      "0           15.044384         NaN   \n",
      "1           26.990975         NaN   \n",
      "2           14.565322         NaN   \n",
      "3           24.089670         NaN   \n",
      "4           34.611594         NaN   \n",
      "5           14.928288         NaN   \n",
      "6           61.896822         NaN   \n",
      "7           11.681010         NaN   \n",
      "8          138.419413         NaN   \n",
      "9           15.594739         NaN   \n",
      "10         193.643116         NaN   \n",
      "11          29.271027         NaN   \n",
      "12          74.963043         NaN   \n",
      "13          35.213646         NaN   \n",
      "14          12.220000         NaN   \n",
      "15          34.030000         NaN   \n",
      "16           5.710000         NaN   \n",
      "17         207.390000         NaN   \n",
      "\n",
      "                                           Unnamed: 7  \n",
      "0                                               Notes  \n",
      "1   Each line of data shows a summary of bookings ...  \n",
      "2                                      Departure Date  \n",
      "3                                       Flight Number  \n",
      "4                                      Seat Capacity   \n",
      "5                                  Segment City Pair   \n",
      "6                                          Seats Sold  \n",
      "7                                        Average Fare  \n",
      "8                                                 NaN  \n",
      "9                             All data are fictitious  \n",
      "10                                                NaN  \n",
      "11             Data has been extracted on 14 Jul 2019  \n",
      "12                                                NaN  \n",
      "13                                                NaN  \n",
      "14                                                NaN  \n",
      "15                                                NaN  \n",
      "16                                                NaN  \n",
      "17                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'zerd.xlsx'\n",
    "\n",
    "# Read the first sheet\n",
    "historical_data = pd.read_excel(file_path, sheet_name='Historical Data')\n",
    "print(\"Historical Data DataFrame:\")\n",
    "print(historical_data)\n",
    "\n",
    "# Read the second sheet\n",
    "future_flights = pd.read_excel(file_path, sheet_name='Future Flights')\n",
    "print(\"\\nFuture Flights DataFrame:\")\n",
    "print(future_flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookingDate</th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Seat Capacity</th>\n",
       "      <th>SegmentCityPair</th>\n",
       "      <th>Seats Sold</th>\n",
       "      <th>AverageFare (SGD)</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>2</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Each line of data shows a summary of bookings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BookingDate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>1</td>\n",
       "      <td>46.7152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Departure Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>1</td>\n",
       "      <td>60.9113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>8</td>\n",
       "      <td>26.7375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookingDate DepartureDate Flight Number  Seat Capacity SegmentCityPair  \\\n",
       "0     2018-08-03    2019-06-25        TR 202            180          SINPNH   \n",
       "1     2018-08-03    2019-06-29        TR 203            180          PNHSIN   \n",
       "2     2018-08-06    2019-06-11        TR 202            180          SINPNH   \n",
       "3     2018-08-09    2019-06-11        TR 202            180          SINPNH   \n",
       "4     2018-09-26    2019-06-09        TR 202            180          SINPNH   \n",
       "...          ...           ...           ...            ...             ...   \n",
       "2555  2019-06-28    2019-06-30        TR 203            180          PNHSIN   \n",
       "2556  2019-06-29    2019-06-29        TR 203            180          PNHSIN   \n",
       "2557  2019-06-29    2019-06-30        TR 202            180          SINPNH   \n",
       "2558  2019-06-29    2019-06-30        TR 203            180          PNHSIN   \n",
       "2559  2019-06-30    2019-06-30        TR 202            180          SINPNH   \n",
       "\n",
       "      Seats Sold  AverageFare (SGD)  Unnamed: 7  Unnamed: 8  \\\n",
       "0              1             3.7000         NaN         NaN   \n",
       "1              1             6.4349         NaN         NaN   \n",
       "2              2            41.7000         NaN         NaN   \n",
       "3              1            63.7000         NaN         NaN   \n",
       "4              1            46.7152         NaN         NaN   \n",
       "...          ...                ...         ...         ...   \n",
       "2555           1           198.2085         NaN         NaN   \n",
       "2556           1            60.9113         NaN         NaN   \n",
       "2557           8            26.7375         NaN         NaN   \n",
       "2558           1           198.2085         NaN         NaN   \n",
       "2559           1            41.7000         NaN         NaN   \n",
       "\n",
       "                                             Unnamed: 9  \n",
       "0                                                   NaN  \n",
       "1                                                 Notes  \n",
       "2     Each line of data shows a summary of bookings ...  \n",
       "3                                          BookingDate   \n",
       "4                                        Departure Date  \n",
       "...                                                 ...  \n",
       "2555                                                NaN  \n",
       "2556                                                NaN  \n",
       "2557                                                NaN  \n",
       "2558                                                NaN  \n",
       "2559                                                NaN  \n",
       "\n",
       "[2560 rows x 10 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Seat Capacity</th>\n",
       "      <th>SegmentCityPair</th>\n",
       "      <th>Seats Sold</th>\n",
       "      <th>AverageFare (SGD)</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>50</td>\n",
       "      <td>15.044384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Notes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>52</td>\n",
       "      <td>26.990975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Each line of data shows a summary of bookings ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>59</td>\n",
       "      <td>14.565322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Departure Date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>27</td>\n",
       "      <td>24.089670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flight Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>67</td>\n",
       "      <td>34.611594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seat Capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>49</td>\n",
       "      <td>14.928288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Segment City Pair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>59</td>\n",
       "      <td>61.896822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seats Sold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>42</td>\n",
       "      <td>11.681010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average Fare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>54</td>\n",
       "      <td>138.419413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>57</td>\n",
       "      <td>15.594739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All data are fictitious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>98</td>\n",
       "      <td>193.643116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>56</td>\n",
       "      <td>29.271027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data has been extracted on 14 Jul 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>46</td>\n",
       "      <td>74.963043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>63</td>\n",
       "      <td>35.213646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>38</td>\n",
       "      <td>12.220000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>44</td>\n",
       "      <td>34.030000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>29</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>87</td>\n",
       "      <td>207.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate Flight Number  Seat Capacity SegmentCityPair  Seats Sold  \\\n",
       "0     2019-08-04        TR 202            180          SINPNH          50   \n",
       "1     2019-08-04        TR 203            180          PNHSIN          52   \n",
       "2     2019-08-05        TR 202            180          SINPNH          59   \n",
       "3     2019-08-05        TR 203            180          PNHSIN          27   \n",
       "4     2019-08-06        TR 202            180          SINPNH          67   \n",
       "5     2019-08-06        TR 203            180          PNHSIN          49   \n",
       "6     2019-08-07        TR 202            180          SINPNH          59   \n",
       "7     2019-08-07        TR 203            180          PNHSIN          42   \n",
       "8     2019-08-08        TR 202            180          SINPNH          54   \n",
       "9     2019-08-08        TR 203            180          PNHSIN          57   \n",
       "10    2019-08-09        TR 202            180          SINPNH          98   \n",
       "11    2019-08-09        TR 203            180          PNHSIN          56   \n",
       "12    2019-08-10        TR 202            180          SINPNH          46   \n",
       "13    2019-08-10        TR 203            180          PNHSIN          63   \n",
       "14    2019-08-11        TR 202            180          SINPNH          38   \n",
       "15    2019-08-11        TR 203            180          PNHSIN          44   \n",
       "16    2019-08-12        TR 202            180          SINPNH          29   \n",
       "17    2019-08-12        TR 203            180          PNHSIN          87   \n",
       "\n",
       "    AverageFare (SGD)  Unnamed: 6  \\\n",
       "0           15.044384         NaN   \n",
       "1           26.990975         NaN   \n",
       "2           14.565322         NaN   \n",
       "3           24.089670         NaN   \n",
       "4           34.611594         NaN   \n",
       "5           14.928288         NaN   \n",
       "6           61.896822         NaN   \n",
       "7           11.681010         NaN   \n",
       "8          138.419413         NaN   \n",
       "9           15.594739         NaN   \n",
       "10         193.643116         NaN   \n",
       "11          29.271027         NaN   \n",
       "12          74.963043         NaN   \n",
       "13          35.213646         NaN   \n",
       "14          12.220000         NaN   \n",
       "15          34.030000         NaN   \n",
       "16           5.710000         NaN   \n",
       "17         207.390000         NaN   \n",
       "\n",
       "                                           Unnamed: 7  \n",
       "0                                               Notes  \n",
       "1   Each line of data shows a summary of bookings ...  \n",
       "2                                      Departure Date  \n",
       "3                                       Flight Number  \n",
       "4                                      Seat Capacity   \n",
       "5                                  Segment City Pair   \n",
       "6                                          Seats Sold  \n",
       "7                                        Average Fare  \n",
       "8                                                 NaN  \n",
       "9                             All data are fictitious  \n",
       "10                                                NaN  \n",
       "11             Data has been extracted on 14 Jul 2019  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "                 BookingDate                  DepartureDate Flight Number  \\\n",
      "count                  2560                           2560          2560   \n",
      "unique                  NaN                            NaN             2   \n",
      "top                     NaN                            NaN        TR 203   \n",
      "freq                    NaN                            NaN          1309   \n",
      "mean    2019-05-06 12:02:15  2019-06-15 16:14:48.750000128           NaN   \n",
      "min     2018-08-03 00:00:00            2019-06-01 00:00:00           NaN   \n",
      "25%     2019-04-20 00:00:00            2019-06-08 00:00:00           NaN   \n",
      "50%     2019-05-17 00:00:00            2019-06-16 00:00:00           NaN   \n",
      "75%     2019-06-03 00:00:00            2019-06-23 00:00:00           NaN   \n",
      "max     2019-06-30 00:00:00            2019-06-30 00:00:00           NaN   \n",
      "std                     NaN                            NaN           NaN   \n",
      "\n",
      "        Seat Capacity SegmentCityPair   Seats Sold  AverageFare (SGD)  \\\n",
      "count          2560.0            2560  2560.000000        2560.000000   \n",
      "unique            NaN               2          NaN                NaN   \n",
      "top               NaN          PNHSIN          NaN                NaN   \n",
      "freq              NaN            1309          NaN                NaN   \n",
      "mean            180.0             NaN     3.992188          52.411861   \n",
      "min             180.0             NaN     1.000000         -24.495000   \n",
      "25%             180.0             NaN     2.000000          26.700000   \n",
      "50%             180.0             NaN     3.000000          43.342610   \n",
      "75%             180.0             NaN     5.000000          65.000000   \n",
      "max             180.0             NaN    26.000000         382.846333   \n",
      "std               0.0             NaN     3.345767          36.577991   \n",
      "\n",
      "        Unnamed: 7  Unnamed: 8 Unnamed: 9  \n",
      "count          0.0         0.0         10  \n",
      "unique         NaN         NaN         10  \n",
      "top            NaN         NaN      Notes  \n",
      "freq           NaN         NaN          1  \n",
      "mean           NaN         NaN        NaN  \n",
      "min            NaN         NaN        NaN  \n",
      "25%            NaN         NaN        NaN  \n",
      "50%            NaN         NaN        NaN  \n",
      "75%            NaN         NaN        NaN  \n",
      "max            NaN         NaN        NaN  \n",
      "std            NaN         NaN        NaN  \n",
      "\n",
      "Unique values:\n",
      " BookingDate           189\n",
      "DepartureDate          30\n",
      "Flight Number           2\n",
      "Seat Capacity           1\n",
      "SegmentCityPair         2\n",
      "Seats Sold             24\n",
      "AverageFare (SGD)    1192\n",
      "Unnamed: 7              0\n",
      "Unnamed: 8              0\n",
      "Unnamed: 9             10\n",
      "dtype: int64\n",
      "\n",
      "Missing values:\n",
      " BookingDate             0\n",
      "DepartureDate           0\n",
      "Flight Number           0\n",
      "Seat Capacity           0\n",
      "SegmentCityPair         0\n",
      "Seats Sold              0\n",
      "AverageFare (SGD)       0\n",
      "Unnamed: 7           2560\n",
      "Unnamed: 8           2560\n",
      "Unnamed: 9           2550\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "description = historical_data.describe(include='all')\n",
    "unique_values = historical_data.nunique()\n",
    "missing_values = historical_data.isnull().sum()\n",
    "\n",
    "print(\"Description:\\n\", description)\n",
    "print(\"\\nUnique values:\\n\", unique_values)\n",
    "print(\"\\nMissing values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "                 BookingDate                  DepartureDate Flight Number  \\\n",
      "count                  2560                           2560          2560   \n",
      "unique                  NaN                            NaN             2   \n",
      "top                     NaN                            NaN        TR 203   \n",
      "freq                    NaN                            NaN          1309   \n",
      "mean    2019-05-06 12:02:15  2019-06-15 16:14:48.750000128           NaN   \n",
      "min     2018-08-03 00:00:00            2019-06-01 00:00:00           NaN   \n",
      "25%     2019-04-20 00:00:00            2019-06-08 00:00:00           NaN   \n",
      "50%     2019-05-17 00:00:00            2019-06-16 00:00:00           NaN   \n",
      "75%     2019-06-03 00:00:00            2019-06-23 00:00:00           NaN   \n",
      "max     2019-06-30 00:00:00            2019-06-30 00:00:00           NaN   \n",
      "std                     NaN                            NaN           NaN   \n",
      "\n",
      "        Seat Capacity SegmentCityPair   Seats Sold  AverageFare (SGD)  \n",
      "count          2560.0            2560  2560.000000        2560.000000  \n",
      "unique            NaN               2          NaN                NaN  \n",
      "top               NaN          PNHSIN          NaN                NaN  \n",
      "freq              NaN            1309          NaN                NaN  \n",
      "mean            180.0             NaN     3.992188          52.411861  \n",
      "min             180.0             NaN     1.000000         -24.495000  \n",
      "25%             180.0             NaN     2.000000          26.700000  \n",
      "50%             180.0             NaN     3.000000          43.342610  \n",
      "75%             180.0             NaN     5.000000          65.000000  \n",
      "max             180.0             NaN    26.000000         382.846333  \n",
      "std               0.0             NaN     3.345767          36.577991  \n",
      "\n",
      "Unique values:\n",
      " BookingDate           189\n",
      "DepartureDate          30\n",
      "Flight Number           2\n",
      "Seat Capacity           1\n",
      "SegmentCityPair         2\n",
      "Seats Sold             24\n",
      "AverageFare (SGD)    1192\n",
      "dtype: int64\n",
      "\n",
      "Missing values:\n",
      " BookingDate          0\n",
      "DepartureDate        0\n",
      "Flight Number        0\n",
      "Seat Capacity        0\n",
      "SegmentCityPair      0\n",
      "Seats Sold           0\n",
      "AverageFare (SGD)    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_data = historical_data.loc[:, ~historical_data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "description = filtered_data.describe(include='all')\n",
    "unique_values = filtered_data.nunique()\n",
    "missing_values = filtered_data.isnull().sum()\n",
    "\n",
    "print(\"Description:\\n\", description)\n",
    "print(\"\\nUnique values:\\n\", unique_values)\n",
    "print(\"\\nMissing values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Name: BookingDate\n",
      "Data Type: datetime64[ns]\n",
      "Unique Values: <DatetimeArray>\n",
      "['2018-08-03 00:00:00', '2018-08-06 00:00:00', '2018-08-09 00:00:00',\n",
      " '2018-09-26 00:00:00', '2018-10-11 00:00:00', '2018-10-12 00:00:00',\n",
      " '2018-10-13 00:00:00', '2018-10-14 00:00:00', '2018-10-21 00:00:00',\n",
      " '2018-10-26 00:00:00',\n",
      " ...\n",
      " '2019-06-21 00:00:00', '2019-06-22 00:00:00', '2019-06-23 00:00:00',\n",
      " '2019-06-24 00:00:00', '2019-06-25 00:00:00', '2019-06-26 00:00:00',\n",
      " '2019-06-27 00:00:00', '2019-06-28 00:00:00', '2019-06-29 00:00:00',\n",
      " '2019-06-30 00:00:00']\n",
      "Length: 189, dtype: datetime64[ns]\n",
      "--------------------------------------------------\n",
      "Column Name: DepartureDate\n",
      "Data Type: datetime64[ns]\n",
      "Unique Values: <DatetimeArray>\n",
      "['2019-06-25 00:00:00', '2019-06-29 00:00:00', '2019-06-11 00:00:00',\n",
      " '2019-06-09 00:00:00', '2019-06-10 00:00:00', '2019-06-15 00:00:00',\n",
      " '2019-06-27 00:00:00', '2019-06-03 00:00:00', '2019-06-06 00:00:00',\n",
      " '2019-06-24 00:00:00', '2019-06-23 00:00:00', '2019-06-26 00:00:00',\n",
      " '2019-06-22 00:00:00', '2019-06-20 00:00:00', '2019-06-08 00:00:00',\n",
      " '2019-06-13 00:00:00', '2019-06-02 00:00:00', '2019-06-01 00:00:00',\n",
      " '2019-06-12 00:00:00', '2019-06-21 00:00:00', '2019-06-18 00:00:00',\n",
      " '2019-06-19 00:00:00', '2019-06-30 00:00:00', '2019-06-17 00:00:00',\n",
      " '2019-06-28 00:00:00', '2019-06-04 00:00:00', '2019-06-14 00:00:00',\n",
      " '2019-06-07 00:00:00', '2019-06-05 00:00:00', '2019-06-16 00:00:00']\n",
      "Length: 30, dtype: datetime64[ns]\n",
      "--------------------------------------------------\n",
      "Column Name: Flight Number\n",
      "Data Type: object\n",
      "Unique Values: ['TR 202' 'TR 203']\n",
      "--------------------------------------------------\n",
      "Column Name: Seat Capacity\n",
      "Data Type: int64\n",
      "Unique Values: [180]\n",
      "--------------------------------------------------\n",
      "Column Name: SegmentCityPair\n",
      "Data Type: object\n",
      "Unique Values: ['SINPNH' 'PNHSIN']\n",
      "--------------------------------------------------\n",
      "Column Name: Seats Sold\n",
      "Data Type: int64\n",
      "Unique Values: [ 1  2  3  6  5  4 19  7  9 14 24  8 12 10 15 13 26 21 11 22 20 16 18 17]\n",
      "--------------------------------------------------\n",
      "Column Name: AverageFare (SGD)\n",
      "Data Type: float64\n",
      "Unique Values: [  3.7      6.4349  41.7    ...  61.5698 198.2085  26.7375]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column in the DataFrame\n",
    "for column in filtered_data.columns:\n",
    "    \n",
    "    # Get unique values of the column\n",
    "    unique_values = filtered_data[column].unique()\n",
    "\n",
    "    # Get data type of the column\n",
    "    data_type = filtered_data[column].dtype\n",
    "\n",
    "    # Prepare a string to print\n",
    "    output = f\"Column Name: {column}\\n\"\n",
    "    output += f\"Data Type: {data_type}\\n\"\n",
    "    output += f\"Unique Values: {unique_values}\\n\"\n",
    "    output += \"-\" * 50  # separator\n",
    "\n",
    "    # Print the output\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common SegmentCityPair and Flight Number pairings:\n",
      "  SegmentCityPair Flight Number  Count\n",
      "0          PNHSIN        TR 203   1309\n",
      "1          SINPNH        TR 202   1251\n"
     ]
    }
   ],
   "source": [
    "# Group by SegmentCityPair and Flight Number and count occurrences\n",
    "pairing_counts = filtered_data.groupby(['SegmentCityPair', 'Flight Number']).size().reset_index(name='Count')\n",
    "\n",
    "# Sort the results by count in descending order\n",
    "sorted_pairing_counts = pairing_counts.sort_values(by='Count', ascending=False)\n",
    "\n",
    "# Print the most common pairings\n",
    "print(\"Most common SegmentCityPair and Flight Number pairings:\")\n",
    "print(sorted_pairing_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Cleaning** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2, 2.2, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.333333333333334, 3.333333333333334, 3.7, 3.8876, 4.2, 4.2, 4.2, 4.2, 4.39565, 4.591299999999999, 4.5913, 4.9388, 4.9388, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.283333333333333, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.5752, 5.6425, 5.6425, 5.6425, 5.6425, 5.6425, 5.6425, 5.642500000000001, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 5.7, 6.3247, 6.372666666666667, 6.4349, 6.532933333333334, 6.7, 6.7, 6.865, 6.952540000000002, 7.2, 7.35, 7.412700000000001, 7.431866666666668, 7.5429, 7.594100000000001, 7.761533333333333, 8.0348, 8.112433333333334, 8.1988, 8.1988, 8.1988, 8.1988, 8.1988, 8.1988, 8.1988, 8.2978, 8.2978, 8.2978, 8.487414285714285, 8.598742857142858, 8.633333333333335, 8.9202, 8.961566666666668, 8.996609090909091, 9.0, 9.018650000000001, 9.059000000000001, 9.125309090909091, 9.2, 10.1553, 10.1766, 10.4944, 10.4944, 10.4944, 10.4944, 10.4944, 10.4944, 10.4944, 10.4944, 10.5458, 10.6202, 10.6202, 10.6202, 10.6202, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.6211, 10.680275, 10.68685, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 10.7, 11.36893333333333, 11.5407, 11.7415, 11.74962, 11.9063, 12.06856, 12.24346666666667, 12.24346666666667, 12.24346666666667, 12.31919, 12.4621, 12.79005, 12.9, 13.118, 13.118, 13.118, 13.118, 13.118, 13.2752, 13.2752, 13.2764, 13.2764, 13.2764, 13.2764, 13.2764, 13.2764, 13.27645, 13.54906666666667, 13.9379, 14.0, 14.0972, 14.10188, 14.31428571428571, 14.5458, 14.62874285714286, 14.75775, 14.96423333333333, 15.02617142857143, 15.05405, 15.08573333333333, 15.15, 15.36666666666667, 15.4137, 15.5485, 15.61128, 15.70159999999999, 15.8236, 15.85, 15.9264, 15.95, 16.04511999999999, 16.0458, 16.22, 16.22375, 16.2829, 16.34397727272727, 16.36666666666666, 16.397525, 16.5941, 16.7968, 16.8988, 17.09059, 17.21636363636363, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.3814, 17.386, 17.44512, 17.4503, 17.4503, 17.4503, 17.4503, 17.4503, 17.4876, 17.50884, 17.5407, 17.5407, 17.5407, 17.5407, 17.56345714285714, 17.57256, 17.57256, 17.57515, 17.5896, 17.5896, 17.5896, 17.5896, 17.5896, 17.5896, 17.5896, 17.5896, 17.5896, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5912, 17.5938, 17.5938, 17.5977, 17.60012, 17.6063625, 17.61676666666667, 17.6456, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.7, 17.97843333333333, 18.026475, 18.1575, 18.1575, 18.36, 18.44326666666667, 18.44823571428571, 18.525, 18.5292, 18.5292, 18.60265, 18.659825, 18.7275, 18.8, 18.8, 18.84285714285715, 18.9118, 18.9185, 18.93606666666667, 19.0, 19.08461538461538, 19.10422857142857, 19.1907, 19.21788, 19.22515, 19.35, 19.35, 19.44744, 19.4908875, 19.677, 19.677, 19.677, 19.677, 19.677, 19.677, 19.677, 19.677, 19.7, 19.755, 19.840975, 19.9128, 19.9128, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 19.9146, 20.03312222222222, 20.1, 20.175, 20.2429, 20.24832, 20.3385, 20.3385, 20.40688571428571, 20.5, 20.51512222222222, 20.58869090909091, 20.7, 20.7, 20.70017142857143, 20.70175, 20.8626, 20.9933, 21.0, 21.0, 21.0, 21.09813333333333, 21.17622857142857, 21.185, 21.2137, 21.33106666666666, 21.33116363636363, 21.50417142857142, 21.52146, 21.52857142857143, 21.59122857142857, 21.60263529411765, 21.66666666666667, 21.66923076923077, 21.677075, 21.7, 21.7, 21.90605, 22.02, 22.07206, 22.1402, 22.1402, 22.14285714285714, 22.1913, 22.24142, 22.59576, 22.63022727272728, 22.67142857142857, 22.710575, 22.710575, 22.710575, 22.73124, 22.76, 22.77411, 22.8, 22.84285714285714, 22.9565, 22.965, 22.97256, 23.06586666666666, 23.1885, 23.2, 23.33108, 23.35, 23.373125, 23.5635, 23.60186666666667, 23.7, 23.7084, 23.7764, 23.957, 24.1528, 24.17088571428571, 24.42345, 24.4382, 24.4699, 24.59316666666667, 24.69936666666667, 24.71175, 24.71428571428571, 24.7826, 24.81333333333333, 24.93595, 25.0, 25.0302, 25.03333333333333, 25.03333333333333, 25.03453333333333, 25.14, 25.16055, 25.2, 25.2425, 25.2522, 25.54533333333333, 25.56, 25.6715875, 25.69233333333333, 25.89697142857143, 25.9878, 26.01736666666666, 26.02566666666667, 26.05405, 26.0712, 26.1205, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236, 26.236025, 26.3392, 26.3392, 26.3392, 26.3392, 26.34, 26.34, 26.34, 26.39066666666666, 26.39066666666666, 26.4258, 26.4451875, 26.45946666666667, 26.484, 26.52, 26.54533333333333, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5504, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.5528, 26.56396153846153, 26.5955, 26.65093333333333, 26.68, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7, 26.7375, 26.8344, 26.89028571428571, 26.8919, 26.8919, 26.8919, 26.9162125, 26.94875, 27.1125, 27.163125, 27.178925, 27.2166, 27.2166, 27.23333333333333, 27.293, 27.32916666666667, 27.36, 27.456, 27.4654, 27.567, 27.6385, 27.65916666666667, 27.7, 27.7, 27.7, 27.7145, 27.78874, 27.8, 27.87575, 28.02, 28.02, 28.02, 28.032, 28.03975, 28.03975, 28.04683333333334, 28.04999999999999, 28.10775, 28.16494285714286, 28.16666666666666, 28.4072, 28.4319, 28.44942857142857, 28.4521, 28.53166666666667, 28.5407, 28.60512, 28.63686666666666, 28.65775, 28.68, 28.695625, 28.7733, 28.8, 28.81277142857143, 28.89169999999999, 28.9, 28.9, 29.0472, 29.05555555555556, 29.06720000000001, 29.085, 29.1125, 29.14375, 29.30326, 29.33331111111111, 29.5155, 29.5155, 29.5155, 29.58123333333333, 29.63249999999999, 29.6325, 29.6325, 29.6325, 29.7, 29.70589999999999, 29.83333333333333, 29.86919999999999, 29.86919999999999, 29.8692, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 29.8719, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.00464285714286, 30.06666666666667, 30.13613333333333, 30.20688333333333, 30.2868, 30.45, 30.55, 30.8375, 30.85, 30.98816, 31.1, 31.1, 31.1132, 31.169, 31.19537777777778, 31.27876, 31.28470588235294, 31.28785999999999, 31.62028, 31.69873333333333, 31.7, 31.7, 31.7, 31.81119999999999, 31.8112, 32.08325, 32.1211125, 32.18722857142857, 32.1924, 32.1953, 32.28343333333333, 32.3507, 32.43116999999999, 32.45465714285714, 32.489, 32.5, 32.5242, 32.5242, 32.60832, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.7, 32.795, 32.795, 32.82182857142857, 32.8354, 32.8445, 32.92505, 33.025, 33.0276, 33.12857142857143, 33.191, 33.191, 33.2, 33.2, 33.30343333333333, 33.3416, 33.35, 33.36666666666666, 33.36666666666666, 33.57142857142857, 33.65785, 33.7, 33.91333333333333, 33.9687, 34.03333333333333, 34.03333333333334, 34.2, 34.2, 34.2, 34.2, 34.3, 34.473, 34.475, 34.56666666666667, 34.6, 34.61625, 34.8942, 35.0, 35.1517, 35.2572, 35.58333333333334, 35.63099999999999, 35.95693333333333, 36.00617142857143, 36.06756666666666, 36.14, 36.2, 36.21753333333334, 36.39876666666667, 36.54533333333333, 36.5592, 36.7, 36.7, 37.0046, 37.0584, 37.0584, 37.0584, 37.1885, 37.2, 37.3365, 37.3399, 37.42035, 37.44545454545454, 37.5024, 37.5024, 37.5058, 37.565075, 37.6775, 37.7, 37.7, 37.86376666666666, 37.95, 37.95, 37.95, 38.36666666666667, 38.41428571428571, 38.43, 38.6869, 38.6981, 38.6981, 38.6981, 38.6981, 38.6981, 38.83346666666666, 38.85154, 39.1618, 39.1654, 39.19004999999999, 39.2, 39.22171875, 39.35, 39.354, 39.46666666666666, 39.55714285714286, 39.639, 39.7, 39.7, 39.7, 39.7, 39.7, 39.7587, 39.8292, 39.9, 40.1398, 40.2094, 40.5552, 40.5674, 40.5674, 40.5674, 40.66241, 40.79783333333334, 40.95, 40.98820833333333, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 40.9938, 41.005, 41.13504, 41.155, 41.155, 41.155, 41.155, 41.155, 41.15629999999999, 41.15629999999999, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.1563, 41.27628, 41.292225, 41.3091, 41.34690000000001, 41.34690000000001, 41.34690000000001, 41.34690000000001, 41.42815, 41.4646, 41.485, 41.485, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.4888, 41.51876666666667, 41.52345, 41.5374625, 41.54188571428572, 41.55876, 41.564075, 41.5925, 41.59439999999999, 41.61552, 41.6296, 41.67359999999999, 41.68338749999999, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.7, 41.88653846153846, 41.9, 42.08696666666666, 42.08696666666666, 42.15310909090908, 42.17142857142857, 42.20158, 42.24390000000001, 42.264, 42.36, 42.39999999999999, 42.63355, 42.68308, 42.73345, 42.778, 42.78286000000001, 42.79966363636363, 42.79999999999999, 42.8, 42.8, 42.8, 42.80255, 42.80255, 42.80255, 42.8678, 42.90665714285715, 42.93, 42.938475, 43.0, 43.02, 43.03333333333333, 43.0744, 43.2141, 43.27959999999999, 43.29783333333334, 43.30458181818182, 43.33522, 43.35, 43.35, 43.35, 43.39048571428572, 43.44871428571429, 43.625675, 43.63371428571428, 43.6443, 43.67999999999999, 43.85, 43.85014545454545, 43.9, 43.9, 43.9, 43.9232125, 43.95, 43.99845, 44.024, 44.1052, 44.16678571428571, 44.175, 44.2461125, 44.2733, 44.2733, 44.2733, 44.2733, 44.2733, 44.2733, 44.2733, 44.2733, 44.2733, 44.36391428571428, 44.44827999999999, 44.4488, 44.4488, 44.4488, 44.4488, 44.689, 44.70932000000001, 44.72316666666666, 44.8038, 44.8038, 44.8038, 44.8079, 44.8079, 44.8079, 44.8079, 44.8079, 44.8079, 44.8079, 44.8079, 44.8079, 44.84690000000001, 44.85294999999999, 44.8603625, 44.9198625, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.013025, 45.17593333333334, 45.36666666666667, 45.36666666666667, 45.36666666666667, 45.41752, 45.60114545454545, 45.6093, 45.6366, 45.7, 45.7, 45.74227142857142, 45.913, 45.93034, 45.97085555555555, 46.0936, 46.1, 46.1, 46.25714285714286, 46.33565, 46.35, 46.35, 46.36, 46.36666666666667, 46.3862, 46.40765555555555, 46.4674, 46.49952500000001, 46.58888888888888, 46.7, 46.7, 46.7, 46.7, 46.7, 46.7, 46.7, 46.7152, 46.792225, 46.8584, 46.914375, 47.0813, 47.0813, 47.2, 47.2972, 47.297225, 47.4588, 47.4588, 47.4588, 47.48782857142857, 47.52500000000001, 47.5261, 47.5528, 47.65676, 47.7, 47.7, 47.7, 47.7, 47.7, 47.7, 47.7, 47.70000000000001, 47.7398, 47.7398, 47.74126666666667, 47.7882, 47.93465999999999, 47.97429999999999, 48.02499999999999, 48.02500000000001, 48.04197499999999, 48.09003636363636, 48.127, 48.127, 48.188, 48.22666666666668, 48.36666666666667, 48.36666666666667, 48.564375, 48.59391666666667, 48.66168333333334, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.7, 48.70000000000001, 48.70000000000001, 48.70000000000001, 48.70000000000001, 48.8488, 48.90735714285714, 49.03333333333333, 49.03333333333334, 49.03333333333334, 49.03333333333334, 49.03333333333334, 49.03661875, 49.05018, 49.31538461538461, 49.37143333333334, 49.3875, 49.58333333333334, 49.65940000000001, 49.7, 49.7, 49.782, 49.7865, 49.82250000000001, 49.96784444444445, 50.002, 50.44575999999999, 50.45448999999999, 50.5, 50.5006, 50.56666666666666, 50.70152, 50.84896666666666, 50.86076, 50.86586666666667, 50.95000000000001, 50.95555555555555, 51.03379999999999, 51.14253999999999, 51.1922, 51.23333333333333, 51.23333333333333, 51.26953333333334, 51.3, 51.34690000000001, 51.4461, 51.44906666666667, 51.59999999999999, 51.65215000000001, 51.67999999999999, 51.68888888888888, 51.7, 51.70000000000001, 51.711, 51.81999999999999, 51.8299, 51.96333333333333, 51.976575, 52.0, 52.0, 52.1099, 52.20189090909093, 52.21422222222222, 52.45612222222222, 52.47203333333334, 52.52499999999999, 52.54233333333332, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.67025085562248, 52.7, 52.7, 52.7, 52.7, 52.7, 52.7, 52.7, 52.70000000000001, 52.7511, 52.7511, 52.77, 52.881975, 53.32478, 53.34999999999999, 53.35, 53.3726, 53.46215, 53.5296, 53.70000000000001, 53.70511818181819, 53.93119999999999, 54.03333333333334, 54.0744, 54.14101999999999, 54.22878000000001, 54.23125, 54.36405384615383, 54.3952, 54.5732, 54.9, 54.93361111111111, 55.01111111111111, 55.03333333333333, 55.03333333333333, 55.03333333333334, 55.03333333333334, 55.605, 55.68084999999999, 55.78394285714286, 55.90833333333333, 55.95714285714286, 55.98571428571428, 55.98571428571428, 56.04769999999999, 56.05505714285715, 56.10223846153845, 56.35616, 56.36666666666667, 56.36666666666667, 56.497, 56.55776666666667, 56.56738333333334, 56.69792727272727, 56.93803846153847, 57.02780000000001, 57.03333333333334, 57.1, 57.2545, 57.27500000000001, 57.38361428571428, 57.77500000000001, 57.92941176470588, 58.0008, 58.00553333333334, 58.02999999999999, 58.32228, 58.61855, 58.8174, 58.98, 59.0746, 59.08, 59.175, 59.3, 59.3488, 59.35, 59.4648, 59.6234, 59.8852, 60.13333333333334, 60.14303333333334, 60.34, 60.35, 60.41875000000001, 60.6708, 60.6708, 60.6708, 60.6708, 60.6708, 60.6708, 60.6708, 60.67080000000001, 60.67080000000001, 60.67080000000001, 60.7482, 60.79944999999999, 60.9094, 60.9094, 60.9094, 60.9094, 60.9113, 60.9113, 60.9113, 60.9113, 60.9113, 60.9113, 60.9113, 60.9113, 61.17419999999998, 61.289075, 61.28925714285714, 61.383, 61.3978, 61.3978, 61.3978, 61.3978, 61.4034, 61.4034, 61.4034, 61.4034, 61.4034, 61.4034, 61.4034, 61.4034, 61.4034, 61.5698, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.7, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.70000000000001, 61.81249999999999, 61.93076923076924, 61.97709999999999, 62.0088, 62.04557142857142, 62.05768571428571, 62.2717, 62.3105, 62.3105, 62.3276, 62.4154, 62.4336, 62.4501, 62.525, 62.5346, 62.5448, 62.55714285714286, 62.5575, 62.55752, 62.55755, 62.55755, 62.7, 62.7829, 62.8, 62.80445, 62.82515, 62.9519, 63.02, 63.02, 63.02307692307693, 63.0572, 63.0572, 63.0572, 63.0572, 63.06289999999998, 63.0629, 63.0629, 63.06295, 63.06849999999999, 63.20228, 63.2944, 63.35, 63.35, 63.35, 63.380675, 63.58571428571429, 63.62604285714286, 63.62882857142857, 63.67999999999999, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.7, 63.70000000000001, 63.70000000000001, 63.70000000000001, 63.9, 63.9, 63.9503, 63.9503, 63.9503, 64.03333333333333, 64.06405, 64.14444444444445, 64.14444444444445, 64.175, 64.2038, 64.2038, 64.25293333333333, 64.34, 64.40285, 64.7, 64.7166, 64.7225, 64.7225, 64.7225, 64.824, 64.8697625, 64.9271625, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.04346666666666, 65.046, 65.046, 65.1, 65.5608, 65.6805, 65.6805, 65.7, 65.7, 65.7, 65.9705, 65.9879, 65.9879, 65.9879, 66.03333333333333, 66.4, 66.5, 66.55006, 66.770775, 66.84285714285714, 66.9, 66.95555555555556, 66.95555555555556, 67.0, 67.014, 67.0293888888889, 67.11428571428571, 67.2, 67.2, 67.2, 67.2894, 67.34433846153846, 67.35, 67.4962875, 67.7, 67.7, 67.7, 67.7, 67.89, 67.89, 68.0354, 68.0416, 68.09375, 68.10000000000001, 68.1125, 68.2, 68.2, 68.46249999999999, 68.4819, 68.7, 69.03333333333335, 69.03333333333335, 69.42999999999999, 69.45925, 69.47179999999999, 69.58333333333333, 69.675, 69.7, 69.70000000000002, 70.08, 70.17066666666666, 71.05565, 71.13333333333333, 71.16, 71.29056666666668, 71.3703, 71.42307692307693, 71.4395, 71.82000000000001, 71.99045625, 72.1, 72.118, 72.30565, 72.30565, 72.36363636363636, 72.52728461538462, 72.7, 72.7, 72.7, 72.7, 72.7, 72.7, 72.84285714285714, 72.84285714285717, 73.2, 73.39090909090909, 73.62222222222222, 73.809, 73.91666666666667, 74.04035999999999, 74.11512, 74.1854, 74.23948333333333, 74.27142857142857, 74.27845, 74.35, 74.48656666666666, 74.7, 74.7, 74.70000000000002, 75.06666666666666, 75.12, 75.13333333333334, 75.15620909090909, 75.216, 75.35, 75.39000000000001, 75.39000000000004, 75.39486, 75.44166666666666, 75.50346666666667, 75.7188, 75.96226666666668, 75.9691, 76.33705454545454, 76.6055, 76.70084444444446, 76.79500833333333, 77.7, 77.7, 77.7579, 77.76888, 77.85000000000001, 77.86250000000001, 78.11386666666665, 78.23333333333333, 78.34444444444445, 78.555375, 78.7, 78.7, 79.00666666666669, 79.03333333333333, 79.03333333333335, 79.03333333333335, 80.31046666666667, 80.3478, 80.5652, 80.6638, 80.9, 81.1348, 81.36666666666667, 81.5304, 81.84925, 81.9875, 81.9875, 82.31, 82.3125, 82.47715, 82.5, 82.5615, 82.66666666666667, 82.82000000000001, 82.86250000000001, 82.97, 82.97, 82.97, 82.97, 82.97, 82.97, 82.9775, 82.9775, 83.19375000000001, 83.6273, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7, 83.7923076923077, 83.94334285714287, 84.15113000000001, 84.2318, 84.46355833333335, 84.54545454545456, 84.63380000000001, 84.6371, 85.04424999999999, 85.14, 85.51818181818182, 85.80000000000001, 85.98290999999999, 86.2509, 86.2509, 86.2745, 86.41538461538462, 86.58333333333336, 86.5901, 86.5901, 86.5928, 86.5928, 86.5928, 86.5928, 86.5928, 86.73393333333333, 87.0, 87.0, 87.0, 87.0, 87.209, 87.2923, 87.2923, 87.2923, 87.39655714285716, 87.51546666666667, 87.5641, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.7, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000002, 87.70000000000003, 87.896, 88.02194999999999, 88.03000000000002, 88.12325, 88.239, 88.239, 88.27364, 88.34876666666666, 88.34999999999998, 88.35, 88.3998, 88.51338333333332, 88.525, 88.5465, 88.5465, 88.57712000000001, 88.75454545454546, 88.8, 88.8975, 88.8975, 88.8975, 88.8975, 89.34981111111112, 89.35, 89.6157, 89.7, 89.89999999999999, 90.175, 90.45000000000002, 90.7, 90.94072, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.275, 91.7, 91.89662, 92.1, 92.1, 92.1, 92.10000000000002, 92.199, 92.5164, 92.66363636363639, 92.75999999999999, 92.837725, 92.938125, 92.94, 93.01666666666667, 93.08216666666665, 93.2, 93.2, 93.2, 93.20000000000002, 93.46211111111113, 93.4714, 93.56666666666668, 93.62325, 93.7298, 93.81663636363638, 94.02499999999999, 94.42993333333334, 94.46466666666667, 94.47513333333335, 94.49476666666668, 94.65792857142857, 94.71333333333335, 94.92727272727274, 94.96, 95.03333333333335, 95.03333333333335, 95.695775, 95.71457142857142, 95.9133, 96.0706, 96.09926666666667, 96.1076625, 96.13333333333333, 96.15328, 96.47984285714286, 96.5, 96.53125, 97.3715, 97.70000000000003, 97.9046, 97.9135, 98.22626666666667, 98.34000000000002, 98.7, 98.7, 99.54285714285713, 99.69092222222224, 99.75, 99.8, 100.35, 100.42125, 100.750525, 100.9714285714286, 101.0333333333333, 101.4721444444445, 101.6428571428571, 102.0644, 102.0785714285714, 102.0785714285715, 102.7333333333333, 102.89065, 103.1846153846154, 103.6464, 103.9232, 104.2, 104.2, 105.0833333333333, 105.3, 105.56218, 105.6666666666667, 106.36, 106.4, 106.5571428571429, 106.7451, 107.0903125, 107.37545, 108.3232666666667, 108.325, 108.4166666666667, 108.8566, 108.8665, 108.9142857142857, 109.2195363636364, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 109.7, 110.0503333333333, 110.2, 110.381075, 110.754, 110.93325, 111.2714285714286, 111.5727272727273, 111.75, 112.2743, 112.45, 113.0, 113.0, 113.0, 113.3666666666667, 113.86735, 114.072125, 114.3, 115.0932, 115.2, 115.2, 115.7, 115.8769230769231, 116.0523, 119.1885, 119.1885, 119.847, 119.8472857142857, 119.8888, 120.1406, 120.38325, 120.6638625, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.7, 120.9138333333333, 121.8225, 121.8225, 121.8225, 121.8225, 121.8428571428572, 123.8024, 123.942, 124.0, 124.0, 124.0, 124.0, 125.9488461538462, 126.2, 127.3571428571429, 128.21845, 129.8656285714286, 129.88915, 129.95, 130.02, 130.257125, 130.6912916666667, 131.0256666666667, 131.1, 131.6125, 131.7, 131.860375, 133.9, 134.5220625, 135.074825, 135.16, 135.45, 137.1527, 139.69925, 140.2605, 140.5855, 141.7128, 142.7, 142.7, 142.7, 142.7, 142.7, 142.7, 142.7, 147.3411625, 147.3666666666666, 147.44336, 150.015, 150.08315, 152.6833333333334, 156.2, 157.165975, 158.6985, 158.6985, 159.69925, 160.7, 160.7, 160.7, 160.7, 160.7, 160.7, 160.7, 160.7, 161.36, 162.9, 164.0, 166.2, 176.0119666666667, 176.5493, 179.9897, 180.0998, 181.5384, 182.7, 182.7, 183.08, 184.044, 189.76, 198.2085, 198.2085, 200.7, 200.77125, 205.7, 211.5, 222.7, 224.2, 224.21925, 231.6, 250.7, 252.0374, 257.45, 278.1307692307693, 279.4666666666666, 320.7, 342.7, 345.15, 382.8463333333333]\n"
     ]
    }
   ],
   "source": [
    "df = filtered_data.drop(columns=['SegmentCityPair', 'Seat Capacity'])\n",
    "\n",
    "# Calculate the average of the column, excluding negative and zero values\n",
    "average_fare = df.loc[df[\"AverageFare (SGD)\"] > 0, \"AverageFare (SGD)\"].mean()\n",
    "\n",
    "# Replace negative and zero values with the calculated average\n",
    "df[\"AverageFare (SGD)\"] = df[\"AverageFare (SGD)\"].apply(lambda x: average_fare if x <= 0 else x)\n",
    "\n",
    "# Print the updated column\n",
    "print(df[\"AverageFare (SGD)\"].sort_values().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Seats Sold': 'SeatsSold'}, inplace=True)\n",
    "df.rename(columns={'Flight Number': 'FlightNumber'}, inplace=True)\n",
    "df.rename(columns={'AverageFare (SGD)': 'AverageFare(SGD)'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookingDate</th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>2</td>\n",
       "      <td>41.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>46.7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>60.9113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>8</td>\n",
       "      <td>26.7375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)\n",
       "0     2018-08-03    2019-06-25       TR 202          1            3.7000\n",
       "1     2018-08-03    2019-06-29       TR 203          1            6.4349\n",
       "2     2018-08-06    2019-06-11       TR 202          2           41.7000\n",
       "3     2018-08-09    2019-06-11       TR 202          1           63.7000\n",
       "4     2018-09-26    2019-06-09       TR 202          1           46.7152\n",
       "...          ...           ...          ...        ...               ...\n",
       "2555  2019-06-28    2019-06-30       TR 203          1          198.2085\n",
       "2556  2019-06-29    2019-06-29       TR 203          1           60.9113\n",
       "2557  2019-06-29    2019-06-30       TR 202          8           26.7375\n",
       "2558  2019-06-29    2019-06-30       TR 203          1          198.2085\n",
       "2559  2019-06-30    2019-06-30       TR 202          1           41.7000\n",
       "\n",
       "[2560 rows x 5 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for FlightNumber TR 202:\n",
      "  BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)\n",
      "0  2018-08-03    2019-06-25       TR 202          1            3.7000\n",
      "2  2018-08-06    2019-06-11       TR 202          2           41.7000\n",
      "3  2018-08-09    2019-06-11       TR 202          1           63.7000\n",
      "4  2018-09-26    2019-06-09       TR 202          1           46.7152\n",
      "5  2018-10-11    2019-06-10       TR 202          2           46.7000\n",
      "\n",
      "DataFrame for FlightNumber TR 203:\n",
      "   BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)\n",
      "1   2018-08-03    2019-06-29       TR 203          1            6.4349\n",
      "6   2018-10-11    2019-06-15       TR 203          2           46.7000\n",
      "7   2018-10-12    2019-06-27       TR 203          1           22.1402\n",
      "8   2018-10-13    2019-06-29       TR 203          3           22.1402\n",
      "10  2018-10-14    2019-06-06       TR 203          6           46.7000\n"
     ]
    }
   ],
   "source": [
    "df_TR202 = df[df['FlightNumber'] == 'TR 202']\n",
    "df_TR203 = df[df['FlightNumber'] == 'TR 203']\n",
    "\n",
    "# Display the first few rows of each DataFrame to verify\n",
    "print(\"DataFrame for FlightNumber TR 202:\")\n",
    "print(df_TR202.head())\n",
    "\n",
    "print(\"\\nDataFrame for FlightNumber TR 203:\")\n",
    "print(df_TR203.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame for FlightNumber TR 202:\n",
      "     BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)  \\\n",
      "0     2018-08-03    2019-06-25       TR 202          1            3.7000   \n",
      "1     2018-08-06    2019-06-11       TR 202          2           41.7000   \n",
      "2     2018-08-09    2019-06-11       TR 202          1           63.7000   \n",
      "3     2018-09-26    2019-06-09       TR 202          1           46.7152   \n",
      "4     2018-10-11    2019-06-10       TR 202          2           46.7000   \n",
      "...          ...           ...          ...        ...               ...   \n",
      "1246  2019-06-28    2019-06-28       TR 202          5           71.1600   \n",
      "1247  2019-06-28    2019-06-29       TR 202         10           82.8200   \n",
      "1248  2019-06-28    2019-06-30       TR 202          6           28.9000   \n",
      "1249  2019-06-29    2019-06-30       TR 202          8           26.7375   \n",
      "1250  2019-06-30    2019-06-30       TR 202          1           41.7000   \n",
      "\n",
      "      WeightedAverageFare(SGD)  TotalSeatsSold  \n",
      "0                    45.012600             170  \n",
      "1                    92.305012             180  \n",
      "2                    92.305012             180  \n",
      "3                   105.195083             180  \n",
      "4                   102.394362             180  \n",
      "...                        ...             ...  \n",
      "1246                 48.506099             171  \n",
      "1247                 59.287623             168  \n",
      "1248                 25.572143             160  \n",
      "1249                 25.572143             160  \n",
      "1250                 25.572143             160  \n",
      "\n",
      "[1251 rows x 7 columns]\n",
      "\n",
      "Updated DataFrame for FlightNumber TR 203:\n",
      "     BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)  \\\n",
      "0     2018-08-03    2019-06-29       TR 203          1            6.4349   \n",
      "1     2018-10-11    2019-06-15       TR 203          2           46.7000   \n",
      "2     2018-10-12    2019-06-27       TR 203          1           22.1402   \n",
      "3     2018-10-13    2019-06-29       TR 203          3           22.1402   \n",
      "4     2018-10-14    2019-06-06       TR 203          6           46.7000   \n",
      "...          ...           ...          ...        ...               ...   \n",
      "1304  2019-06-28    2019-06-28       TR 203          1           86.5928   \n",
      "1305  2019-06-28    2019-06-29       TR 203          5           61.5698   \n",
      "1306  2019-06-28    2019-06-30       TR 203          1          198.2085   \n",
      "1307  2019-06-29    2019-06-29       TR 203          1           60.9113   \n",
      "1308  2019-06-29    2019-06-30       TR 203          1          198.2085   \n",
      "\n",
      "      WeightedAverageFare(SGD)  TotalSeatsSold  \n",
      "0                    45.923806             159  \n",
      "1                    36.652606             144  \n",
      "2                    28.037459             169  \n",
      "3                    45.923806             159  \n",
      "4                    33.050272             174  \n",
      "...                        ...             ...  \n",
      "1304                 40.269855             154  \n",
      "1305                 45.923806             159  \n",
      "1306                 85.649748             180  \n",
      "1307                 45.923806             159  \n",
      "1308                 85.649748             180  \n",
      "\n",
      "[1309 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate total fare by multiplying AverageFare(SGD) by SeatsSold\n",
    "df_TR202['TotalFare'] = df_TR202['AverageFare(SGD)'] * df_TR202['SeatsSold']\n",
    "df_TR203['TotalFare'] = df_TR203['AverageFare(SGD)'] * df_TR203['SeatsSold']\n",
    "\n",
    "# Group by DepartureDate and calculate the sum of TotalFare and SeatsSold\n",
    "grouped_TR202 = df_TR202.groupby('DepartureDate').agg({'TotalFare': 'sum', 'SeatsSold': 'sum'}).reset_index()\n",
    "grouped_TR203 = df_TR203.groupby('DepartureDate').agg({'TotalFare': 'sum', 'SeatsSold': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the weighted average fare\n",
    "grouped_TR202['WeightedAverageFare(SGD)'] = grouped_TR202['TotalFare'] / grouped_TR202['SeatsSold']\n",
    "grouped_TR203['WeightedAverageFare(SGD)'] = grouped_TR203['TotalFare'] / grouped_TR203['SeatsSold']\n",
    "\n",
    "# Rename columns for clarity\n",
    "grouped_TR202.rename(columns={'SeatsSold': 'TotalSeatsSold'}, inplace=True)\n",
    "grouped_TR203.rename(columns={'SeatsSold': 'TotalSeatsSold'}, inplace=True)\n",
    "\n",
    "# Merge the new columns back into the original DataFrames\n",
    "df_TR202 = df_TR202.merge(grouped_TR202[['DepartureDate', 'WeightedAverageFare(SGD)', 'TotalSeatsSold']], on='DepartureDate', how='left')\n",
    "df_TR203 = df_TR203.merge(grouped_TR203[['DepartureDate', 'WeightedAverageFare(SGD)', 'TotalSeatsSold']], on='DepartureDate', how='left')\n",
    "df_TR202.drop(columns=['TotalFare'], inplace=True)\n",
    "df_TR203.drop(columns=['TotalFare'], inplace=True)\n",
    "\n",
    "# Display the updated DataFrames\n",
    "print(\"Updated DataFrame for FlightNumber TR 202:\")\n",
    "print(df_TR202)\n",
    "\n",
    "print(\"\\nUpdated DataFrame for FlightNumber TR 203:\")\n",
    "print(df_TR203)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookingDate</th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>45.012600</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>2</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>92.305012</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>92.305012</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>1</td>\n",
       "      <td>46.7152</td>\n",
       "      <td>105.195083</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>2019-06-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>2</td>\n",
       "      <td>46.7000</td>\n",
       "      <td>102.394362</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5928</td>\n",
       "      <td>40.269855</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>5</td>\n",
       "      <td>61.5698</td>\n",
       "      <td>45.923806</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>85.649748</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>60.9113</td>\n",
       "      <td>45.923806</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>85.649748</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookingDate DepartureDate FlightNumber  SeatsSold  AverageFare(SGD)  \\\n",
       "0     2018-08-03    2019-06-25       TR 202          1            3.7000   \n",
       "1     2018-08-06    2019-06-11       TR 202          2           41.7000   \n",
       "2     2018-08-09    2019-06-11       TR 202          1           63.7000   \n",
       "3     2018-09-26    2019-06-09       TR 202          1           46.7152   \n",
       "4     2018-10-11    2019-06-10       TR 202          2           46.7000   \n",
       "...          ...           ...          ...        ...               ...   \n",
       "2555  2019-06-28    2019-06-28       TR 203          1           86.5928   \n",
       "2556  2019-06-28    2019-06-29       TR 203          5           61.5698   \n",
       "2557  2019-06-28    2019-06-30       TR 203          1          198.2085   \n",
       "2558  2019-06-29    2019-06-29       TR 203          1           60.9113   \n",
       "2559  2019-06-29    2019-06-30       TR 203          1          198.2085   \n",
       "\n",
       "      WeightedAverageFare(SGD)  TotalSeatsSold  \n",
       "0                    45.012600             170  \n",
       "1                    92.305012             180  \n",
       "2                    92.305012             180  \n",
       "3                   105.195083             180  \n",
       "4                   102.394362             180  \n",
       "...                        ...             ...  \n",
       "2555                 40.269855             154  \n",
       "2556                 45.923806             159  \n",
       "2557                 85.649748             180  \n",
       "2558                 45.923806             159  \n",
       "2559                 85.649748             180  \n",
       "\n",
       "[2560 rows x 7 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_TR202 and df_TR203 into a new DataFrame df_zerd\n",
    "df_zerd = pd.concat([df_TR202, df_TR203], ignore_index=True)\n",
    "\n",
    "df_zerd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Engineering** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>BookingDate</th>\n",
       "      <th>BookingDay</th>\n",
       "      <th>BookingDayOfWeek</th>\n",
       "      <th>BookingMonth</th>\n",
       "      <th>BookingYear</th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>DepartureDay</th>\n",
       "      <th>DepartureDayOfWeek</th>\n",
       "      <th>DepartureMonth</th>\n",
       "      <th>...</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>IsBookingDateHoliday</th>\n",
       "      <th>IsBookingDateWeekend</th>\n",
       "      <th>IsDepartureDateHoliday</th>\n",
       "      <th>IsDepartureDateWeekend</th>\n",
       "      <th>LeadTime(Days_to_DepartureDate)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.7000</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>170</td>\n",
       "      <td>45.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.7000</td>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4349</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.7000</td>\n",
       "      <td>2018-08-06</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>83.4000</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.7152</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>105.195083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.7000</td>\n",
       "      <td>2018-09-26</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>46.7152</td>\n",
       "      <td>180</td>\n",
       "      <td>102.394362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>86.5928</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>154</td>\n",
       "      <td>40.269855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>61.5698</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.9113</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>213.9000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>60.9113</td>\n",
       "      <td>2019-06-29</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AverageFare(SGD) BookingDate  BookingDay  BookingDayOfWeek  \\\n",
       "0               3.7000  2018-08-03           3                 4   \n",
       "1              41.7000  2018-08-03           3                 4   \n",
       "2              63.7000  2018-08-06           6                 0   \n",
       "3              46.7152  2018-08-09           9                 3   \n",
       "4              46.7000  2018-09-26          26                 2   \n",
       "...                ...         ...         ...               ...   \n",
       "2555           86.5928  2019-06-28          28                 4   \n",
       "2556           61.5698  2019-06-29          29                 5   \n",
       "2557          198.2085  2019-06-29          29                 5   \n",
       "2558           60.9113  2019-06-29          29                 5   \n",
       "2559          198.2085  2019-06-30          30                 6   \n",
       "\n",
       "      BookingMonth  BookingYear DepartureDate  DepartureDay  \\\n",
       "0                8         2018    2019-06-25            25   \n",
       "1                8         2018    2019-06-29            29   \n",
       "2                8         2018    2019-06-11            11   \n",
       "3                8         2018    2019-06-11            11   \n",
       "4                9         2018    2019-06-09             9   \n",
       "...            ...          ...           ...           ...   \n",
       "2555             6         2019    2019-06-30            30   \n",
       "2556             6         2019    2019-06-29            29   \n",
       "2557             6         2019    2019-06-30            30   \n",
       "2558             6         2019    2019-06-30            30   \n",
       "2559             6         2019    2019-06-30            30   \n",
       "\n",
       "      DepartureDayOfWeek  DepartureMonth  ...  FlightNumber  \\\n",
       "0                      1               6  ...        TR 202   \n",
       "1                      5               6  ...        TR 202   \n",
       "2                      1               6  ...        TR 202   \n",
       "3                      1               6  ...        TR 202   \n",
       "4                      6               6  ...        TR 202   \n",
       "...                  ...             ...  ...           ...   \n",
       "2555                   6               6  ...        TR 203   \n",
       "2556                   5               6  ...        TR 203   \n",
       "2557                   6               6  ...        TR 203   \n",
       "2558                   6               6  ...        TR 203   \n",
       "2559                   6               6  ...        TR 203   \n",
       "\n",
       "     IsBookingDateHoliday  IsBookingDateWeekend  IsDepartureDateHoliday  \\\n",
       "0                   False                 False                   False   \n",
       "1                   False                 False                   False   \n",
       "2                   False                 False                   False   \n",
       "3                   False                 False                   False   \n",
       "4                   False                 False                   False   \n",
       "...                   ...                   ...                     ...   \n",
       "2555                False                 False                   False   \n",
       "2556                False                  True                   False   \n",
       "2557                False                  True                   False   \n",
       "2558                False                  True                   False   \n",
       "2559                False                  True                   False   \n",
       "\n",
       "      IsDepartureDateWeekend  LeadTime(Days_to_DepartureDate)  SeatsSold  \\\n",
       "0                      False                              326          1   \n",
       "1                       True                              330          2   \n",
       "2                      False                              309          1   \n",
       "3                      False                              306          1   \n",
       "4                       True                              256          2   \n",
       "...                      ...                              ...        ...   \n",
       "2555                    True                                2          1   \n",
       "2556                    True                                0          5   \n",
       "2557                    True                                1          1   \n",
       "2558                    True                                1          1   \n",
       "2559                    True                                0          1   \n",
       "\n",
       "      Total Revenue  TotalSeatsSold  WeightedAverageFare(SGD)  \n",
       "0            3.7000             170                 45.012600  \n",
       "1            6.4349             180                 92.305012  \n",
       "2           83.4000             180                 92.305012  \n",
       "3           63.7000             180                105.195083  \n",
       "4           46.7152             180                102.394362  \n",
       "...             ...             ...                       ...  \n",
       "2555       198.2085             154                 40.269855  \n",
       "2556        60.9113             159                 45.923806  \n",
       "2557       213.9000             180                 85.649748  \n",
       "2558       198.2085             159                 45.923806  \n",
       "2559        41.7000             180                 85.649748  \n",
       "\n",
       "[2560 rows x 21 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fe = df_zerd.copy()\n",
    "\n",
    "# Define holidays in Malaysia and Singapore for the year 2019\n",
    "malaysia_holidays_2019 = [\n",
    "    '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-05', '2019-06-06', '2019-06-21',\n",
    "]\n",
    "singapore_holidays_2019 = [\n",
    "    '2019-01-01', '2019-02-05', '2019-02-06', '2019-04-19', '2019-05-01', '2019-05-19',\n",
    "    '2019-05-20', '2019-06-05', '2019-08-09', '2019-08-11', '2019-08-12', '2019-10-27',\n",
    "    '2019-10-28', '2019-12-25'\n",
    "]\n",
    "\n",
    "# Combine holidays into a single list\n",
    "holidays_2019 = malaysia_holidays_2019 + singapore_holidays_2019\n",
    "holidays_2019 = pd.to_datetime(holidays_2019)\n",
    "\n",
    "# Convert dates to datetime format\n",
    "df_fe['BookingDate'] = pd.to_datetime(df['BookingDate'])\n",
    "df_fe['DepartureDate'] = pd.to_datetime(df['DepartureDate'])\n",
    "\n",
    "# Determine if the booking date and departure date are holidays\n",
    "df_fe['IsBookingDateHoliday'] = df['BookingDate'].isin(holidays_2019)\n",
    "df_fe['IsDepartureDateHoliday'] = df['DepartureDate'].isin(holidays_2019)\n",
    "\n",
    "# Calculate lead time in days\n",
    "df_fe['LeadTime(Days_to_DepartureDate)'] = (df['DepartureDate'] - df['BookingDate']).dt.days\n",
    "\n",
    "# Calculate total revenue\n",
    "df_fe['Total Revenue'] = df['SeatsSold'] * df['AverageFare(SGD)']\n",
    "\n",
    "# Extract features from BookingDate\n",
    "df_fe['BookingYear'] = df['BookingDate'].dt.year\n",
    "df_fe['BookingMonth'] = df['BookingDate'].dt.month\n",
    "df_fe['BookingDay'] = df['BookingDate'].dt.day\n",
    "df_fe['BookingDayOfWeek'] = df['BookingDate'].dt.dayofweek\n",
    "df_fe['IsBookingDateWeekend'] = df_fe['BookingDayOfWeek'].isin([5, 6])\n",
    "\n",
    "# Extract features from DepartureDate\n",
    "df_fe['DepartureYear'] = df['DepartureDate'].dt.year\n",
    "df_fe['DepartureMonth'] = df['DepartureDate'].dt.month\n",
    "df_fe['DepartureDay'] = df['DepartureDate'].dt.day\n",
    "df_fe['DepartureDayOfWeek'] = df['DepartureDate'].dt.dayofweek\n",
    "df_fe['IsDepartureDateWeekend'] = df_fe['DepartureDayOfWeek'].isin([5, 6])\n",
    "\n",
    "df_fe = df_fe[sorted(df_fe.columns)]\n",
    "df_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_TR_202', 'df_TR_203']\n"
     ]
    }
   ],
   "source": [
    "# Separate the DataFrame according to Flight Number\n",
    "flight_number_groups = {flight_number: group for flight_number, group in df_fe.groupby('FlightNumber')}\n",
    "\n",
    "# List to store the names of the DataFrames\n",
    "df_names = []\n",
    "\n",
    "# Create individual DataFrames for each Flight Number\n",
    "for flight_number, group in flight_number_groups.items():\n",
    "    sanitized_flight_number = flight_number.replace(' ', '_')\n",
    "    df_name = f'df_{sanitized_flight_number}'\n",
    "    globals()[df_name] = group\n",
    "    df_names.append(df_name)\n",
    "\n",
    "# Print the names of the DataFrames\n",
    "print(df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Transformation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>BookingDay</th>\n",
       "      <th>BookingDayOfWeek</th>\n",
       "      <th>BookingMonth</th>\n",
       "      <th>BookingYear</th>\n",
       "      <th>DepartureDay</th>\n",
       "      <th>DepartureDayOfWeek</th>\n",
       "      <th>DepartureMonth</th>\n",
       "      <th>DepartureYear</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>IsBookingDateHoliday</th>\n",
       "      <th>IsBookingDateWeekend</th>\n",
       "      <th>IsDepartureDateHoliday</th>\n",
       "      <th>IsDepartureDateWeekend</th>\n",
       "      <th>LeadTime(Days_to_DepartureDate)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>170</td>\n",
       "      <td>45.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4349</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.7000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>83.4000</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.7152</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>105.195083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.7000</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>46.7152</td>\n",
       "      <td>180</td>\n",
       "      <td>102.394362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>86.5928</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>154</td>\n",
       "      <td>40.269855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>61.5698</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.9113</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>213.9000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>60.9113</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AverageFare(SGD)  BookingDay  BookingDayOfWeek  BookingMonth  \\\n",
       "0               3.7000           3                 4             8   \n",
       "1              41.7000           3                 4             8   \n",
       "2              63.7000           6                 0             8   \n",
       "3              46.7152           9                 3             8   \n",
       "4              46.7000          26                 2             9   \n",
       "...                ...         ...               ...           ...   \n",
       "2555           86.5928          28                 4             6   \n",
       "2556           61.5698          29                 5             6   \n",
       "2557          198.2085          29                 5             6   \n",
       "2558           60.9113          29                 5             6   \n",
       "2559          198.2085          30                 6             6   \n",
       "\n",
       "      BookingYear  DepartureDay  DepartureDayOfWeek  DepartureMonth  \\\n",
       "0            2018            25                   1               6   \n",
       "1            2018            29                   5               6   \n",
       "2            2018            11                   1               6   \n",
       "3            2018            11                   1               6   \n",
       "4            2018             9                   6               6   \n",
       "...           ...           ...                 ...             ...   \n",
       "2555         2019            30                   6               6   \n",
       "2556         2019            29                   5               6   \n",
       "2557         2019            30                   6               6   \n",
       "2558         2019            30                   6               6   \n",
       "2559         2019            30                   6               6   \n",
       "\n",
       "      DepartureYear FlightNumber  IsBookingDateHoliday  IsBookingDateWeekend  \\\n",
       "0              2019       TR 202                 False                 False   \n",
       "1              2019       TR 202                 False                 False   \n",
       "2              2019       TR 202                 False                 False   \n",
       "3              2019       TR 202                 False                 False   \n",
       "4              2019       TR 202                 False                 False   \n",
       "...             ...          ...                   ...                   ...   \n",
       "2555           2019       TR 203                 False                 False   \n",
       "2556           2019       TR 203                 False                  True   \n",
       "2557           2019       TR 203                 False                  True   \n",
       "2558           2019       TR 203                 False                  True   \n",
       "2559           2019       TR 203                 False                  True   \n",
       "\n",
       "      IsDepartureDateHoliday  IsDepartureDateWeekend  \\\n",
       "0                      False                   False   \n",
       "1                      False                    True   \n",
       "2                      False                   False   \n",
       "3                      False                   False   \n",
       "4                      False                    True   \n",
       "...                      ...                     ...   \n",
       "2555                   False                    True   \n",
       "2556                   False                    True   \n",
       "2557                   False                    True   \n",
       "2558                   False                    True   \n",
       "2559                   False                    True   \n",
       "\n",
       "      LeadTime(Days_to_DepartureDate)  SeatsSold  Total Revenue  \\\n",
       "0                                 326          1         3.7000   \n",
       "1                                 330          2         6.4349   \n",
       "2                                 309          1        83.4000   \n",
       "3                                 306          1        63.7000   \n",
       "4                                 256          2        46.7152   \n",
       "...                               ...        ...            ...   \n",
       "2555                                2          1       198.2085   \n",
       "2556                                0          5        60.9113   \n",
       "2557                                1          1       213.9000   \n",
       "2558                                1          1       198.2085   \n",
       "2559                                0          1        41.7000   \n",
       "\n",
       "      TotalSeatsSold  WeightedAverageFare(SGD)  \n",
       "0                170                 45.012600  \n",
       "1                180                 92.305012  \n",
       "2                180                 92.305012  \n",
       "3                180                105.195083  \n",
       "4                180                102.394362  \n",
       "...              ...                       ...  \n",
       "2555             154                 40.269855  \n",
       "2556             159                 45.923806  \n",
       "2557             180                 85.649748  \n",
       "2558             159                 45.923806  \n",
       "2559             180                 85.649748  \n",
       "\n",
       "[2560 rows x 19 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt = df_fe.drop(columns=['BookingDate','DepartureDate']) \n",
    "\n",
    "df_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to Become Numerical\n",
    "\n",
    "- **FlightNumber**: Since flight numbers are categorical and there is no natural ordering, one-hot encoding is appropriate.\n",
    "- **IsBookingDateHoliday**: This is a binary column, but you can encode it.\n",
    "- **IsBookingDateWeekend**: Similar to `IsBookingDateHoliday`, you can encode this binary column.\n",
    "- **IsDepartureDateHoliday**: Encode.\n",
    "- **IsDepartureDateWeekend**: Encode.\n",
    "\n",
    "Columns that Donâ€™t Need to Become Numerical\n",
    "The following columns are already numeric or can be used directly without any further encoding:\n",
    "\n",
    "- **AverageFare(SGD)**\n",
    "- **BookingDay**: Already numeric.\n",
    "- **BookingMonth**: Already numeric.\n",
    "- **BookingYear**: Already numeric.\n",
    "- **DepartureDay**: Already numeric.\n",
    "- **DepartureMonth**: Already numeric.\n",
    "- **DepartureYear**: Already numeric.\n",
    "- **LeadTime(Days_to_DepartureDate)**: This is a numeric column that represents the difference between the booking date and the departure date.\n",
    "- **SeatsSold**: This is the target variable when predicting the number of seats sold.\n",
    "- **Total Revenue**: This could be derived from `AverageFare(SGD)` and `SeatsSold`.\n",
    "- **BookingDayOfWeek**: Already numeric.\n",
    "- **DepartureDayOfWeek**: Already numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>BookingDay</th>\n",
       "      <th>BookingDayOfWeek</th>\n",
       "      <th>BookingMonth</th>\n",
       "      <th>BookingYear</th>\n",
       "      <th>DepartureDay</th>\n",
       "      <th>DepartureDayOfWeek</th>\n",
       "      <th>DepartureMonth</th>\n",
       "      <th>DepartureYear</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>IsBookingDateHoliday</th>\n",
       "      <th>IsBookingDateWeekend</th>\n",
       "      <th>IsDepartureDateHoliday</th>\n",
       "      <th>IsDepartureDateWeekend</th>\n",
       "      <th>LeadTime(Days_to_DepartureDate)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>3.7000</td>\n",
       "      <td>170</td>\n",
       "      <td>45.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.7000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>2</td>\n",
       "      <td>6.4349</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.7000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>309</td>\n",
       "      <td>1</td>\n",
       "      <td>83.4000</td>\n",
       "      <td>180</td>\n",
       "      <td>92.305012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.7152</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>1</td>\n",
       "      <td>63.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>105.195083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.7000</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>46.7152</td>\n",
       "      <td>180</td>\n",
       "      <td>102.394362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>86.5928</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>154</td>\n",
       "      <td>40.269855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>61.5698</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>60.9113</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>213.9000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>60.9113</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>198.2085</td>\n",
       "      <td>159</td>\n",
       "      <td>45.923806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>198.2085</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41.7000</td>\n",
       "      <td>180</td>\n",
       "      <td>85.649748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AverageFare(SGD)  BookingDay  BookingDayOfWeek  BookingMonth  \\\n",
       "0               3.7000           3                 4             8   \n",
       "1              41.7000           3                 4             8   \n",
       "2              63.7000           6                 0             8   \n",
       "3              46.7152           9                 3             8   \n",
       "4              46.7000          26                 2             9   \n",
       "...                ...         ...               ...           ...   \n",
       "2555           86.5928          28                 4             6   \n",
       "2556           61.5698          29                 5             6   \n",
       "2557          198.2085          29                 5             6   \n",
       "2558           60.9113          29                 5             6   \n",
       "2559          198.2085          30                 6             6   \n",
       "\n",
       "      BookingYear  DepartureDay  DepartureDayOfWeek  DepartureMonth  \\\n",
       "0            2018            25                   1               6   \n",
       "1            2018            29                   5               6   \n",
       "2            2018            11                   1               6   \n",
       "3            2018            11                   1               6   \n",
       "4            2018             9                   6               6   \n",
       "...           ...           ...                 ...             ...   \n",
       "2555         2019            30                   6               6   \n",
       "2556         2019            29                   5               6   \n",
       "2557         2019            30                   6               6   \n",
       "2558         2019            30                   6               6   \n",
       "2559         2019            30                   6               6   \n",
       "\n",
       "      DepartureYear  FlightNumber  IsBookingDateHoliday  IsBookingDateWeekend  \\\n",
       "0              2019             1                     1                     1   \n",
       "1              2019             1                     1                     1   \n",
       "2              2019             1                     1                     1   \n",
       "3              2019             1                     1                     1   \n",
       "4              2019             1                     1                     1   \n",
       "...             ...           ...                   ...                   ...   \n",
       "2555           2019             2                     1                     1   \n",
       "2556           2019             2                     1                     2   \n",
       "2557           2019             2                     1                     2   \n",
       "2558           2019             2                     1                     2   \n",
       "2559           2019             2                     1                     2   \n",
       "\n",
       "      IsDepartureDateHoliday  IsDepartureDateWeekend  \\\n",
       "0                          1                       1   \n",
       "1                          1                       2   \n",
       "2                          1                       1   \n",
       "3                          1                       1   \n",
       "4                          1                       2   \n",
       "...                      ...                     ...   \n",
       "2555                       1                       2   \n",
       "2556                       1                       2   \n",
       "2557                       1                       2   \n",
       "2558                       1                       2   \n",
       "2559                       1                       2   \n",
       "\n",
       "      LeadTime(Days_to_DepartureDate)  SeatsSold  Total Revenue  \\\n",
       "0                                 326          1         3.7000   \n",
       "1                                 330          2         6.4349   \n",
       "2                                 309          1        83.4000   \n",
       "3                                 306          1        63.7000   \n",
       "4                                 256          2        46.7152   \n",
       "...                               ...        ...            ...   \n",
       "2555                                2          1       198.2085   \n",
       "2556                                0          5        60.9113   \n",
       "2557                                1          1       213.9000   \n",
       "2558                                1          1       198.2085   \n",
       "2559                                0          1        41.7000   \n",
       "\n",
       "      TotalSeatsSold  WeightedAverageFare(SGD)  \n",
       "0                170                 45.012600  \n",
       "1                180                 92.305012  \n",
       "2                180                 92.305012  \n",
       "3                180                105.195083  \n",
       "4                180                102.394362  \n",
       "...              ...                       ...  \n",
       "2555             154                 40.269855  \n",
       "2556             159                 45.923806  \n",
       "2557             180                 85.649748  \n",
       "2558             159                 45.923806  \n",
       "2559             180                 85.649748  \n",
       "\n",
       "[2560 rows x 19 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = df_dt.copy()\n",
    "\n",
    "# Mapping dictionary to convert True/False to 1/2\n",
    "bool_mapping = {False: 1, True: 2}\n",
    "bool_mapping_FlightNumber ={\"TR 202\": 1, \"TR 203\": 2}\n",
    "\n",
    "# Apply the mapping to the specified columns\n",
    "df_encoded['FlightNumber'] = df_encoded['FlightNumber'].map(bool_mapping_FlightNumber)\n",
    "df_encoded['IsBookingDateHoliday'] = df_encoded['IsBookingDateHoliday'].map(bool_mapping)\n",
    "df_encoded['IsBookingDateWeekend'] = df_encoded['IsBookingDateWeekend'].map(bool_mapping)\n",
    "df_encoded['IsDepartureDateHoliday'] = df_encoded['IsDepartureDateHoliday'].map(bool_mapping)\n",
    "df_encoded['IsDepartureDateWeekend'] = df_encoded['IsDepartureDateWeekend'].map(bool_mapping)\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to Apply StandardScaler or Normalization\n",
    "- **AverageFare(SGD)**: This is a continuous numerical variable representing the fare, which can have a wide range of values.\n",
    "- **LeadTime(Days_to_DepartureDate)**: This is a continuous numerical variable representing the lead time in days, which could vary significantly.\n",
    "- **SeatsSold**: This is a continuous numerical variable that might also vary across different ranges.\n",
    "- **Total Revenue**: This is a continuous numerical variable derived from SeatsSold and AverageFare(SGD), and can have a large range of values.\n",
    "\n",
    "Columns that Typically Do Not Need Scaling\n",
    "- **BookingDay, BookingDayOfWeek, BookingMonth, BookingYear**: These are categorical variables encoded as numbers, so they typically do not require scaling.\n",
    "- **DepartureDay, DepartureDayOfWeek, DepartureMonth, DepartureYear**: Similar to booking date columns, these are categorical variables that represent discrete time components.\n",
    "- **FlightNumber**: This has already been one-hot encoded, so it doesnâ€™t need scaling.\n",
    "- **IsBookingDateHoliday, IsBookingDateWeekend, IsDepartureDateHoliday, IsDepartureDateWeekend**: These are binary variables that have been encoded as 1 and 2, so they don't need scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>BookingDay</th>\n",
       "      <th>BookingDayOfWeek</th>\n",
       "      <th>BookingMonth</th>\n",
       "      <th>BookingYear</th>\n",
       "      <th>DepartureDay</th>\n",
       "      <th>DepartureDayOfWeek</th>\n",
       "      <th>DepartureMonth</th>\n",
       "      <th>DepartureYear</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>IsBookingDateHoliday</th>\n",
       "      <th>IsBookingDateWeekend</th>\n",
       "      <th>IsDepartureDateHoliday</th>\n",
       "      <th>IsDepartureDateWeekend</th>\n",
       "      <th>LeadTime(Days_to_DepartureDate)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.346315</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.243759</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.769210</td>\n",
       "      <td>-0.074925</td>\n",
       "      <td>-0.403676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.301600</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7.345133</td>\n",
       "      <td>-0.595552</td>\n",
       "      <td>-0.759358</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.703136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303235</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.812922</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.482115</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.703136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163719</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.736892</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.553078</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>2.277371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164137</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.469723</td>\n",
       "      <td>-0.595552</td>\n",
       "      <td>-0.614261</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>2.152603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.932616</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.967493</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.068553</td>\n",
       "      <td>-1.302008</td>\n",
       "      <td>-0.614959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.244671</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.018180</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-0.563124</td>\n",
       "      <td>-0.918544</td>\n",
       "      <td>-0.363083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>4.001212</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.992836</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.012029</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.406653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.226567</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.992836</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.068553</td>\n",
       "      <td>-0.918544</td>\n",
       "      <td>-0.363083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>4.001212</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.018180</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.632327</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.406653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AverageFare(SGD)  BookingDay  BookingDayOfWeek  BookingMonth  \\\n",
       "0            -1.346315           3                 4             8   \n",
       "1            -0.301600           3                 4             8   \n",
       "2             0.303235           6                 0             8   \n",
       "3            -0.163719           9                 3             8   \n",
       "4            -0.164137          26                 2             9   \n",
       "...                ...         ...               ...           ...   \n",
       "2555          0.932616          28                 4             6   \n",
       "2556          0.244671          29                 5             6   \n",
       "2557          4.001212          29                 5             6   \n",
       "2558          0.226567          29                 5             6   \n",
       "2559          4.001212          30                 6             6   \n",
       "\n",
       "      BookingYear  DepartureDay  DepartureDayOfWeek  DepartureMonth  \\\n",
       "0            2018            25                   1               6   \n",
       "1            2018            29                   5               6   \n",
       "2            2018            11                   1               6   \n",
       "3            2018            11                   1               6   \n",
       "4            2018             9                   6               6   \n",
       "...           ...           ...                 ...             ...   \n",
       "2555         2019            30                   6               6   \n",
       "2556         2019            29                   5               6   \n",
       "2557         2019            30                   6               6   \n",
       "2558         2019            30                   6               6   \n",
       "2559         2019            30                   6               6   \n",
       "\n",
       "      DepartureYear  FlightNumber  IsBookingDateHoliday  IsBookingDateWeekend  \\\n",
       "0              2019             1                     1                     1   \n",
       "1              2019             1                     1                     1   \n",
       "2              2019             1                     1                     1   \n",
       "3              2019             1                     1                     1   \n",
       "4              2019             1                     1                     1   \n",
       "...             ...           ...                   ...                   ...   \n",
       "2555           2019             2                     1                     1   \n",
       "2556           2019             2                     1                     2   \n",
       "2557           2019             2                     1                     2   \n",
       "2558           2019             2                     1                     2   \n",
       "2559           2019             2                     1                     2   \n",
       "\n",
       "      IsDepartureDateHoliday  IsDepartureDateWeekend  \\\n",
       "0                          1                       1   \n",
       "1                          1                       2   \n",
       "2                          1                       1   \n",
       "3                          1                       1   \n",
       "4                          1                       2   \n",
       "...                      ...                     ...   \n",
       "2555                       1                       2   \n",
       "2556                       1                       2   \n",
       "2557                       1                       2   \n",
       "2558                       1                       2   \n",
       "2559                       1                       2   \n",
       "\n",
       "      LeadTime(Days_to_DepartureDate)  SeatsSold  Total Revenue  \\\n",
       "0                            7.243759  -0.894495      -0.769210   \n",
       "1                            7.345133  -0.595552      -0.759358   \n",
       "2                            6.812922  -0.894495      -0.482115   \n",
       "3                            6.736892  -0.894495      -0.553078   \n",
       "4                            5.469723  -0.595552      -0.614261   \n",
       "...                               ...        ...            ...   \n",
       "2555                        -0.967493  -0.894495      -0.068553   \n",
       "2556                        -1.018180   0.301279      -0.563124   \n",
       "2557                        -0.992836  -0.894495      -0.012029   \n",
       "2558                        -0.992836  -0.894495      -0.068553   \n",
       "2559                        -1.018180  -0.894495      -0.632327   \n",
       "\n",
       "      TotalSeatsSold  WeightedAverageFare(SGD)  \n",
       "0          -0.074925                 -0.403676  \n",
       "1           0.692001                  1.703136  \n",
       "2           0.692001                  1.703136  \n",
       "3           0.692001                  2.277371  \n",
       "4           0.692001                  2.152603  \n",
       "...              ...                       ...  \n",
       "2555       -1.302008                 -0.614959  \n",
       "2556       -0.918544                 -0.363083  \n",
       "2557        0.692001                  1.406653  \n",
       "2558       -0.918544                 -0.363083  \n",
       "2559        0.692001                  1.406653  \n",
       "\n",
       "[2560 rows x 19 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate scalers for each feature\n",
    "fare_scaler = StandardScaler()\n",
    "leadtime_scaler = StandardScaler()\n",
    "seats_scaler = StandardScaler()\n",
    "revenue_scaler = StandardScaler()\n",
    "weighted_fare_scaler = StandardScaler()\n",
    "total_seats_scaler = StandardScaler()\n",
    "\n",
    "# Scale each feature separately\n",
    "df_encoded['AverageFare(SGD)'] = fare_scaler.fit_transform(df_encoded[['AverageFare(SGD)']])\n",
    "df_encoded['LeadTime(Days_to_DepartureDate)'] = leadtime_scaler.fit_transform(df_encoded[['LeadTime(Days_to_DepartureDate)']])\n",
    "df_encoded['SeatsSold'] = seats_scaler.fit_transform(df_encoded[['SeatsSold']])\n",
    "df_encoded['Total Revenue'] = revenue_scaler.fit_transform(df_encoded[['Total Revenue']])\n",
    "df_encoded['WeightedAverageFare(SGD)'] = weighted_fare_scaler.fit_transform(df_encoded[['WeightedAverageFare(SGD)']])\n",
    "df_encoded['TotalSeatsSold'] = total_seats_scaler.fit_transform(df_encoded[['TotalSeatsSold']])\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns That Needs One-Hot Encoding\n",
    "\n",
    "One-hot encoding is appropriate for categorical variables with no intrinsic order, it needs one-hot encoding to prevent unintended weightage in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>LeadTime(Days_to_DepartureDate)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "      <th>BookingDay_1</th>\n",
       "      <th>BookingDay_2</th>\n",
       "      <th>BookingDay_3</th>\n",
       "      <th>BookingDay_4</th>\n",
       "      <th>...</th>\n",
       "      <th>FlightNumber_1</th>\n",
       "      <th>FlightNumber_2</th>\n",
       "      <th>IsBookingDateHoliday_1</th>\n",
       "      <th>IsBookingDateHoliday_2</th>\n",
       "      <th>IsBookingDateWeekend_1</th>\n",
       "      <th>IsBookingDateWeekend_2</th>\n",
       "      <th>IsDepartureDateHoliday_1</th>\n",
       "      <th>IsDepartureDateHoliday_2</th>\n",
       "      <th>IsDepartureDateWeekend_1</th>\n",
       "      <th>IsDepartureDateWeekend_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.346315</td>\n",
       "      <td>7.243759</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.769210</td>\n",
       "      <td>-0.074925</td>\n",
       "      <td>-0.403676</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.301600</td>\n",
       "      <td>7.345133</td>\n",
       "      <td>-0.595552</td>\n",
       "      <td>-0.759358</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.703136</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303235</td>\n",
       "      <td>6.812922</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.482115</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.703136</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.163719</td>\n",
       "      <td>6.736892</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.553078</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>2.277371</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.164137</td>\n",
       "      <td>5.469723</td>\n",
       "      <td>-0.595552</td>\n",
       "      <td>-0.614261</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>2.152603</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>0.932616</td>\n",
       "      <td>-0.967493</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.068553</td>\n",
       "      <td>-1.302008</td>\n",
       "      <td>-0.614959</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>0.244671</td>\n",
       "      <td>-1.018180</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>-0.563124</td>\n",
       "      <td>-0.918544</td>\n",
       "      <td>-0.363083</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>4.001212</td>\n",
       "      <td>-0.992836</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.012029</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.406653</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>0.226567</td>\n",
       "      <td>-0.992836</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.068553</td>\n",
       "      <td>-0.918544</td>\n",
       "      <td>-0.363083</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>4.001212</td>\n",
       "      <td>-1.018180</td>\n",
       "      <td>-0.894495</td>\n",
       "      <td>-0.632327</td>\n",
       "      <td>0.692001</td>\n",
       "      <td>1.406653</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AverageFare(SGD)  LeadTime(Days_to_DepartureDate)  SeatsSold  \\\n",
       "0            -1.346315                         7.243759  -0.894495   \n",
       "1            -0.301600                         7.345133  -0.595552   \n",
       "2             0.303235                         6.812922  -0.894495   \n",
       "3            -0.163719                         6.736892  -0.894495   \n",
       "4            -0.164137                         5.469723  -0.595552   \n",
       "...                ...                              ...        ...   \n",
       "2555          0.932616                        -0.967493  -0.894495   \n",
       "2556          0.244671                        -1.018180   0.301279   \n",
       "2557          4.001212                        -0.992836  -0.894495   \n",
       "2558          0.226567                        -0.992836  -0.894495   \n",
       "2559          4.001212                        -1.018180  -0.894495   \n",
       "\n",
       "      Total Revenue  TotalSeatsSold  WeightedAverageFare(SGD)  BookingDay_1  \\\n",
       "0         -0.769210       -0.074925                 -0.403676         False   \n",
       "1         -0.759358        0.692001                  1.703136         False   \n",
       "2         -0.482115        0.692001                  1.703136         False   \n",
       "3         -0.553078        0.692001                  2.277371         False   \n",
       "4         -0.614261        0.692001                  2.152603         False   \n",
       "...             ...             ...                       ...           ...   \n",
       "2555      -0.068553       -1.302008                 -0.614959         False   \n",
       "2556      -0.563124       -0.918544                 -0.363083         False   \n",
       "2557      -0.012029        0.692001                  1.406653         False   \n",
       "2558      -0.068553       -0.918544                 -0.363083         False   \n",
       "2559      -0.632327        0.692001                  1.406653         False   \n",
       "\n",
       "      BookingDay_2  BookingDay_3  BookingDay_4  ...  FlightNumber_1  \\\n",
       "0            False          True         False  ...            True   \n",
       "1            False          True         False  ...            True   \n",
       "2            False         False         False  ...            True   \n",
       "3            False         False         False  ...            True   \n",
       "4            False         False         False  ...            True   \n",
       "...            ...           ...           ...  ...             ...   \n",
       "2555         False         False         False  ...           False   \n",
       "2556         False         False         False  ...           False   \n",
       "2557         False         False         False  ...           False   \n",
       "2558         False         False         False  ...           False   \n",
       "2559         False         False         False  ...           False   \n",
       "\n",
       "      FlightNumber_2  IsBookingDateHoliday_1  IsBookingDateHoliday_2  \\\n",
       "0              False                    True                   False   \n",
       "1              False                    True                   False   \n",
       "2              False                    True                   False   \n",
       "3              False                    True                   False   \n",
       "4              False                    True                   False   \n",
       "...              ...                     ...                     ...   \n",
       "2555            True                    True                   False   \n",
       "2556            True                    True                   False   \n",
       "2557            True                    True                   False   \n",
       "2558            True                    True                   False   \n",
       "2559            True                    True                   False   \n",
       "\n",
       "      IsBookingDateWeekend_1  IsBookingDateWeekend_2  \\\n",
       "0                       True                   False   \n",
       "1                       True                   False   \n",
       "2                       True                   False   \n",
       "3                       True                   False   \n",
       "4                       True                   False   \n",
       "...                      ...                     ...   \n",
       "2555                    True                   False   \n",
       "2556                   False                    True   \n",
       "2557                   False                    True   \n",
       "2558                   False                    True   \n",
       "2559                   False                    True   \n",
       "\n",
       "      IsDepartureDateHoliday_1  IsDepartureDateHoliday_2  \\\n",
       "0                         True                     False   \n",
       "1                         True                     False   \n",
       "2                         True                     False   \n",
       "3                         True                     False   \n",
       "4                         True                     False   \n",
       "...                        ...                       ...   \n",
       "2555                      True                     False   \n",
       "2556                      True                     False   \n",
       "2557                      True                     False   \n",
       "2558                      True                     False   \n",
       "2559                      True                     False   \n",
       "\n",
       "      IsDepartureDateWeekend_1  IsDepartureDateWeekend_2  \n",
       "0                         True                     False  \n",
       "1                        False                      True  \n",
       "2                         True                     False  \n",
       "3                         True                     False  \n",
       "4                        False                      True  \n",
       "...                        ...                       ...  \n",
       "2555                     False                      True  \n",
       "2556                     False                      True  \n",
       "2557                     False                      True  \n",
       "2558                     False                      True  \n",
       "2559                     False                      True  \n",
       "\n",
       "[2560 rows x 106 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-Hot Encode the specified columns\n",
    "df_encoded = pd.get_dummies(df_encoded, columns=[\n",
    "    'BookingDay', 'BookingDayOfWeek', 'BookingMonth', 'BookingYear',\n",
    "    'DepartureDay', 'DepartureDayOfWeek', 'DepartureMonth', 'DepartureYear',\n",
    "    'FlightNumber', 'IsBookingDateHoliday', 'IsBookingDateWeekend',\n",
    "    'IsDepartureDateHoliday', 'IsDepartureDateWeekend'\n",
    "])\n",
    "\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AverageFare(SGD)  LeadTime(Days_to_DepartureDate)  SeatsSold  \\\n",
      "0         -1.346315                         7.243759  -0.894495   \n",
      "1         -0.301600                         7.345133  -0.595552   \n",
      "2          0.303235                         6.812922  -0.894495   \n",
      "3         -0.163719                         6.736892  -0.894495   \n",
      "4         -0.164137                         5.469723  -0.595552   \n",
      "\n",
      "   Total Revenue  TotalSeatsSold  WeightedAverageFare(SGD)  BookingDay_1  \\\n",
      "0      -0.769210       -0.074925                 -0.403676         False   \n",
      "1      -0.759358        0.692001                  1.703136         False   \n",
      "2      -0.482115        0.692001                  1.703136         False   \n",
      "3      -0.553078        0.692001                  2.277371         False   \n",
      "4      -0.614261        0.692001                  2.152603         False   \n",
      "\n",
      "   BookingDay_2  BookingDay_3  BookingDay_4  BookingDay_5  BookingDay_6  \\\n",
      "0         False          True         False         False         False   \n",
      "1         False          True         False         False         False   \n",
      "2         False         False         False         False          True   \n",
      "3         False         False         False         False         False   \n",
      "4         False         False         False         False         False   \n",
      "\n",
      "   BookingDay_7  BookingDay_8  BookingDay_9  BookingDay_10  BookingDay_11  \\\n",
      "0         False         False         False          False          False   \n",
      "1         False         False         False          False          False   \n",
      "2         False         False         False          False          False   \n",
      "3         False         False          True          False          False   \n",
      "4         False         False         False          False          False   \n",
      "\n",
      "   BookingDay_12  BookingDay_13  BookingDay_14  BookingDay_15  BookingDay_16  \\\n",
      "0          False          False          False          False          False   \n",
      "1          False          False          False          False          False   \n",
      "2          False          False          False          False          False   \n",
      "3          False          False          False          False          False   \n",
      "4          False          False          False          False          False   \n",
      "\n",
      "   BookingDay_17  BookingDay_18  BookingDay_19  BookingDay_20  BookingDay_21  \\\n",
      "0          False          False          False          False          False   \n",
      "1          False          False          False          False          False   \n",
      "2          False          False          False          False          False   \n",
      "3          False          False          False          False          False   \n",
      "4          False          False          False          False          False   \n",
      "\n",
      "   BookingDay_22  BookingDay_23  BookingDay_24  BookingDay_25  BookingDay_26  \\\n",
      "0          False          False          False          False          False   \n",
      "1          False          False          False          False          False   \n",
      "2          False          False          False          False          False   \n",
      "3          False          False          False          False          False   \n",
      "4          False          False          False          False           True   \n",
      "\n",
      "   BookingDay_27  BookingDay_28  BookingDay_29  BookingDay_30  BookingDay_31  \\\n",
      "0          False          False          False          False          False   \n",
      "1          False          False          False          False          False   \n",
      "2          False          False          False          False          False   \n",
      "3          False          False          False          False          False   \n",
      "4          False          False          False          False          False   \n",
      "\n",
      "   BookingDayOfWeek_0  BookingDayOfWeek_1  BookingDayOfWeek_2  \\\n",
      "0               False               False               False   \n",
      "1               False               False               False   \n",
      "2                True               False               False   \n",
      "3               False               False               False   \n",
      "4               False               False                True   \n",
      "\n",
      "   BookingDayOfWeek_3  BookingDayOfWeek_4  BookingDayOfWeek_5  \\\n",
      "0               False                True               False   \n",
      "1               False                True               False   \n",
      "2               False               False               False   \n",
      "3                True               False               False   \n",
      "4               False               False               False   \n",
      "\n",
      "   BookingDayOfWeek_6  BookingMonth_1  BookingMonth_2  BookingMonth_3  \\\n",
      "0               False           False           False           False   \n",
      "1               False           False           False           False   \n",
      "2               False           False           False           False   \n",
      "3               False           False           False           False   \n",
      "4               False           False           False           False   \n",
      "\n",
      "   BookingMonth_4  BookingMonth_5  BookingMonth_6  BookingMonth_8  \\\n",
      "0           False           False           False            True   \n",
      "1           False           False           False            True   \n",
      "2           False           False           False            True   \n",
      "3           False           False           False            True   \n",
      "4           False           False           False           False   \n",
      "\n",
      "   BookingMonth_9  BookingMonth_10  BookingMonth_11  BookingMonth_12  \\\n",
      "0           False            False            False            False   \n",
      "1           False            False            False            False   \n",
      "2           False            False            False            False   \n",
      "3           False            False            False            False   \n",
      "4            True            False            False            False   \n",
      "\n",
      "   BookingYear_2018  BookingYear_2019  DepartureDay_1  DepartureDay_2  \\\n",
      "0              True             False           False           False   \n",
      "1              True             False           False           False   \n",
      "2              True             False           False           False   \n",
      "3              True             False           False           False   \n",
      "4              True             False           False           False   \n",
      "\n",
      "   DepartureDay_3  DepartureDay_4  DepartureDay_5  DepartureDay_6  \\\n",
      "0           False           False           False           False   \n",
      "1           False           False           False           False   \n",
      "2           False           False           False           False   \n",
      "3           False           False           False           False   \n",
      "4           False           False           False           False   \n",
      "\n",
      "   DepartureDay_7  DepartureDay_8  DepartureDay_9  DepartureDay_10  \\\n",
      "0           False           False           False            False   \n",
      "1           False           False           False            False   \n",
      "2           False           False           False            False   \n",
      "3           False           False           False            False   \n",
      "4           False           False            True            False   \n",
      "\n",
      "   DepartureDay_11  DepartureDay_12  DepartureDay_13  DepartureDay_14  \\\n",
      "0            False            False            False            False   \n",
      "1            False            False            False            False   \n",
      "2             True            False            False            False   \n",
      "3             True            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   DepartureDay_15  DepartureDay_16  DepartureDay_17  DepartureDay_18  \\\n",
      "0            False            False            False            False   \n",
      "1            False            False            False            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   DepartureDay_19  DepartureDay_20  DepartureDay_21  DepartureDay_22  \\\n",
      "0            False            False            False            False   \n",
      "1            False            False            False            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   DepartureDay_23  DepartureDay_24  DepartureDay_25  DepartureDay_26  \\\n",
      "0            False            False             True            False   \n",
      "1            False            False            False            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   DepartureDay_27  DepartureDay_28  DepartureDay_29  DepartureDay_30  \\\n",
      "0            False            False            False            False   \n",
      "1            False            False             True            False   \n",
      "2            False            False            False            False   \n",
      "3            False            False            False            False   \n",
      "4            False            False            False            False   \n",
      "\n",
      "   DepartureDayOfWeek_0  DepartureDayOfWeek_1  DepartureDayOfWeek_2  \\\n",
      "0                 False                  True                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                  True                 False   \n",
      "3                 False                  True                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   DepartureDayOfWeek_3  DepartureDayOfWeek_4  DepartureDayOfWeek_5  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                  True   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   DepartureDayOfWeek_6  DepartureMonth_6  DepartureYear_2019  FlightNumber_1  \\\n",
      "0                 False              True                True            True   \n",
      "1                 False              True                True            True   \n",
      "2                 False              True                True            True   \n",
      "3                 False              True                True            True   \n",
      "4                  True              True                True            True   \n",
      "\n",
      "   FlightNumber_2  IsBookingDateHoliday_1  IsBookingDateHoliday_2  \\\n",
      "0           False                    True                   False   \n",
      "1           False                    True                   False   \n",
      "2           False                    True                   False   \n",
      "3           False                    True                   False   \n",
      "4           False                    True                   False   \n",
      "\n",
      "   IsBookingDateWeekend_1  IsBookingDateWeekend_2  IsDepartureDateHoliday_1  \\\n",
      "0                    True                   False                      True   \n",
      "1                    True                   False                      True   \n",
      "2                    True                   False                      True   \n",
      "3                    True                   False                      True   \n",
      "4                    True                   False                      True   \n",
      "\n",
      "   IsDepartureDateHoliday_2  IsDepartureDateWeekend_1  \\\n",
      "0                     False                      True   \n",
      "1                     False                     False   \n",
      "2                     False                      True   \n",
      "3                     False                      True   \n",
      "4                     False                     False   \n",
      "\n",
      "   IsDepartureDateWeekend_2  \n",
      "0                     False  \n",
      "1                      True  \n",
      "2                     False  \n",
      "3                     False  \n",
      "4                      True  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "print(df_encoded.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regression Method**\n",
    "\n",
    "In this section, an input date and input flight number was used to trigger the regression model to provide two versions of predicted AverageFare(SGD) and SeatsSold. \n",
    "\n",
    "While the regression model used provides a reasonable estimate based on the available data, the predictions might not accurately reflect the reality of seat sales in August 2019 due to its limitations in handling time-dependent factors. Additionally, the limited dataset (only June 2019) further constrains the model's ability to make accurate predictions.\n",
    "\n",
    "**Key Points**\n",
    "- **Model Limitation**: The model might struggle with time-dependent factors, which are crucial in the airline industry due to fluctuating demand.\n",
    "- **Data Limitation**: The predictions are based on a limited dataset (June 2019), which may not capture the full seasonality or trends affecting sales in August 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_08283_row8_col1, #T_08283_row12_col1, #T_08283_row14_col1, #T_08283_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_08283\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_08283_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_08283_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_08283_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_08283_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_08283_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_08283_row1_col1\" class=\"data row1 col1\" >AverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_08283_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_08283_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_08283_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_08283_row3_col1\" class=\"data row3 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_08283_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_08283_row4_col1\" class=\"data row4 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_08283_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_08283_row5_col1\" class=\"data row5 col1\" >(1792, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_08283_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_08283_row6_col1\" class=\"data row6 col1\" >(768, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_08283_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_08283_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_08283_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_08283_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_08283_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_08283_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_08283_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_08283_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_08283_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_08283_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_08283_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_08283_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_08283_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_08283_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_08283_row14_col0\" class=\"data row14 col0\" >Transform target</td>\n",
       "      <td id=\"T_08283_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_08283_row15_col0\" class=\"data row15 col0\" >Transform target method</td>\n",
       "      <td id=\"T_08283_row15_col1\" class=\"data row15 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_08283_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_08283_row16_col1\" class=\"data row16 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_08283_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_08283_row17_col1\" class=\"data row17 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_08283_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_08283_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_08283_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_08283_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_08283_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_08283_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_08283_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_08283_row21_col1\" class=\"data row21 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_08283_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_08283_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_08283_row22_col1\" class=\"data row22 col1\" >9a83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc76c4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.regression import setup, compare_models, create_model, tune_model, finalize_model, predict_model, load_model, save_model\n",
    "\n",
    "# Setup PyCaret for AverageFare(SGD)\n",
    "s_fare = setup(\n",
    "    data=df_encoded,\n",
    "    target='AverageFare(SGD)',\n",
    "    use_gpu=True,\n",
    "    session_id=123,\n",
    "    normalize=True,  # Normalize the data\n",
    "    transform_target=True  # Apply log transformation to the target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b8436 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b8436_row0_col0, #T_b8436_row0_col5, #T_b8436_row0_col6, #T_b8436_row1_col0, #T_b8436_row1_col1, #T_b8436_row1_col2, #T_b8436_row1_col3, #T_b8436_row1_col4, #T_b8436_row1_col5, #T_b8436_row1_col6, #T_b8436_row2_col0, #T_b8436_row2_col1, #T_b8436_row2_col2, #T_b8436_row2_col3, #T_b8436_row2_col4, #T_b8436_row2_col6, #T_b8436_row3_col0, #T_b8436_row3_col1, #T_b8436_row3_col2, #T_b8436_row3_col3, #T_b8436_row3_col4, #T_b8436_row3_col5, #T_b8436_row3_col6, #T_b8436_row4_col0, #T_b8436_row4_col1, #T_b8436_row4_col2, #T_b8436_row4_col3, #T_b8436_row4_col4, #T_b8436_row4_col5, #T_b8436_row4_col6, #T_b8436_row5_col0, #T_b8436_row5_col1, #T_b8436_row5_col2, #T_b8436_row5_col3, #T_b8436_row5_col4, #T_b8436_row5_col5, #T_b8436_row5_col6, #T_b8436_row6_col0, #T_b8436_row6_col1, #T_b8436_row6_col2, #T_b8436_row6_col3, #T_b8436_row6_col4, #T_b8436_row6_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_b8436_row0_col1, #T_b8436_row0_col2, #T_b8436_row0_col3, #T_b8436_row0_col4, #T_b8436_row2_col5, #T_b8436_row6_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_b8436_row0_col7, #T_b8436_row1_col7, #T_b8436_row2_col7, #T_b8436_row3_col7, #T_b8436_row4_col7, #T_b8436_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_b8436_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b8436\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b8436_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_b8436_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_b8436_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_b8436_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_b8436_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_b8436_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_b8436_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_b8436_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_b8436_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_b8436_row0_col1\" class=\"data row0 col1\" >0.4898</td>\n",
       "      <td id=\"T_b8436_row0_col2\" class=\"data row0 col2\" >0.5936</td>\n",
       "      <td id=\"T_b8436_row0_col3\" class=\"data row0 col3\" >0.7669</td>\n",
       "      <td id=\"T_b8436_row0_col4\" class=\"data row0 col4\" >0.4021</td>\n",
       "      <td id=\"T_b8436_row0_col5\" class=\"data row0 col5\" >0.3149</td>\n",
       "      <td id=\"T_b8436_row0_col6\" class=\"data row0 col6\" >2.5900</td>\n",
       "      <td id=\"T_b8436_row0_col7\" class=\"data row0 col7\" >0.4540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_b8436_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_b8436_row1_col1\" class=\"data row1 col1\" >0.4997</td>\n",
       "      <td id=\"T_b8436_row1_col2\" class=\"data row1 col2\" >0.5946</td>\n",
       "      <td id=\"T_b8436_row1_col3\" class=\"data row1 col3\" >0.7681</td>\n",
       "      <td id=\"T_b8436_row1_col4\" class=\"data row1 col4\" >0.3987</td>\n",
       "      <td id=\"T_b8436_row1_col5\" class=\"data row1 col5\" >0.3175</td>\n",
       "      <td id=\"T_b8436_row1_col6\" class=\"data row1 col6\" >2.1552</td>\n",
       "      <td id=\"T_b8436_row1_col7\" class=\"data row1 col7\" >1.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_b8436_row2_col0\" class=\"data row2 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_b8436_row2_col1\" class=\"data row2 col1\" >0.5059</td>\n",
       "      <td id=\"T_b8436_row2_col2\" class=\"data row2 col2\" >0.6126</td>\n",
       "      <td id=\"T_b8436_row2_col3\" class=\"data row2 col3\" >0.7783</td>\n",
       "      <td id=\"T_b8436_row2_col4\" class=\"data row2 col4\" >0.3848</td>\n",
       "      <td id=\"T_b8436_row2_col5\" class=\"data row2 col5\" >0.3140</td>\n",
       "      <td id=\"T_b8436_row2_col6\" class=\"data row2 col6\" >3.3524</td>\n",
       "      <td id=\"T_b8436_row2_col7\" class=\"data row2 col7\" >0.4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row3\" class=\"row_heading level0 row3\" >gbr</th>\n",
       "      <td id=\"T_b8436_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_b8436_row3_col1\" class=\"data row3 col1\" >0.5001</td>\n",
       "      <td id=\"T_b8436_row3_col2\" class=\"data row3 col2\" >0.6096</td>\n",
       "      <td id=\"T_b8436_row3_col3\" class=\"data row3 col3\" >0.7778</td>\n",
       "      <td id=\"T_b8436_row3_col4\" class=\"data row3 col4\" >0.3845</td>\n",
       "      <td id=\"T_b8436_row3_col5\" class=\"data row3 col5\" >0.3187</td>\n",
       "      <td id=\"T_b8436_row3_col6\" class=\"data row3 col6\" >2.4443</td>\n",
       "      <td id=\"T_b8436_row3_col7\" class=\"data row3 col7\" >0.3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_b8436_row4_col0\" class=\"data row4 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_b8436_row4_col1\" class=\"data row4 col1\" >0.5869</td>\n",
       "      <td id=\"T_b8436_row4_col2\" class=\"data row4 col2\" >0.7805</td>\n",
       "      <td id=\"T_b8436_row4_col3\" class=\"data row4 col3\" >0.8791</td>\n",
       "      <td id=\"T_b8436_row4_col4\" class=\"data row4 col4\" >0.2166</td>\n",
       "      <td id=\"T_b8436_row4_col5\" class=\"data row4 col5\" >0.3936</td>\n",
       "      <td id=\"T_b8436_row4_col6\" class=\"data row4 col6\" >2.3812</td>\n",
       "      <td id=\"T_b8436_row4_col7\" class=\"data row4 col7\" >0.2380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_b8436_row5_col0\" class=\"data row5 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_b8436_row5_col1\" class=\"data row5 col1\" >0.6565</td>\n",
       "      <td id=\"T_b8436_row5_col2\" class=\"data row5 col2\" >0.8956</td>\n",
       "      <td id=\"T_b8436_row5_col3\" class=\"data row5 col3\" >0.9431</td>\n",
       "      <td id=\"T_b8436_row5_col4\" class=\"data row5 col4\" >0.0951</td>\n",
       "      <td id=\"T_b8436_row5_col5\" class=\"data row5 col5\" >0.3950</td>\n",
       "      <td id=\"T_b8436_row5_col6\" class=\"data row5 col6\" >2.8118</td>\n",
       "      <td id=\"T_b8436_row5_col7\" class=\"data row5 col7\" >0.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b8436_level0_row6\" class=\"row_heading level0 row6\" >lasso</th>\n",
       "      <td id=\"T_b8436_row6_col0\" class=\"data row6 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_b8436_row6_col1\" class=\"data row6 col1\" >0.7107</td>\n",
       "      <td id=\"T_b8436_row6_col2\" class=\"data row6 col2\" >1.0396</td>\n",
       "      <td id=\"T_b8436_row6_col3\" class=\"data row6 col3\" >1.0159</td>\n",
       "      <td id=\"T_b8436_row6_col4\" class=\"data row6 col4\" >-0.0478</td>\n",
       "      <td id=\"T_b8436_row6_col5\" class=\"data row6 col5\" >0.4396</td>\n",
       "      <td id=\"T_b8436_row6_col6\" class=\"data row6 col6\" >1.7793</td>\n",
       "      <td id=\"T_b8436_row6_col7\" class=\"data row6 col7\" >0.0580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc14195d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4ea3_row10_col0, #T_e4ea3_row10_col1, #T_e4ea3_row10_col2, #T_e4ea3_row10_col3, #T_e4ea3_row10_col4, #T_e4ea3_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4ea3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4ea3_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_e4ea3_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_e4ea3_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_e4ea3_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_e4ea3_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_e4ea3_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e4ea3_row0_col0\" class=\"data row0 col0\" >0.5014</td>\n",
       "      <td id=\"T_e4ea3_row0_col1\" class=\"data row0 col1\" >0.5336</td>\n",
       "      <td id=\"T_e4ea3_row0_col2\" class=\"data row0 col2\" >0.7305</td>\n",
       "      <td id=\"T_e4ea3_row0_col3\" class=\"data row0 col3\" >0.3985</td>\n",
       "      <td id=\"T_e4ea3_row0_col4\" class=\"data row0 col4\" >0.3284</td>\n",
       "      <td id=\"T_e4ea3_row0_col5\" class=\"data row0 col5\" >2.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e4ea3_row1_col0\" class=\"data row1 col0\" >0.4776</td>\n",
       "      <td id=\"T_e4ea3_row1_col1\" class=\"data row1 col1\" >0.5088</td>\n",
       "      <td id=\"T_e4ea3_row1_col2\" class=\"data row1 col2\" >0.7133</td>\n",
       "      <td id=\"T_e4ea3_row1_col3\" class=\"data row1 col3\" >0.4018</td>\n",
       "      <td id=\"T_e4ea3_row1_col4\" class=\"data row1 col4\" >0.2897</td>\n",
       "      <td id=\"T_e4ea3_row1_col5\" class=\"data row1 col5\" >2.6800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e4ea3_row2_col0\" class=\"data row2 col0\" >0.5192</td>\n",
       "      <td id=\"T_e4ea3_row2_col1\" class=\"data row2 col1\" >0.5706</td>\n",
       "      <td id=\"T_e4ea3_row2_col2\" class=\"data row2 col2\" >0.7554</td>\n",
       "      <td id=\"T_e4ea3_row2_col3\" class=\"data row2 col3\" >0.3984</td>\n",
       "      <td id=\"T_e4ea3_row2_col4\" class=\"data row2 col4\" >0.3327</td>\n",
       "      <td id=\"T_e4ea3_row2_col5\" class=\"data row2 col5\" >1.3318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e4ea3_row3_col0\" class=\"data row3 col0\" >0.4489</td>\n",
       "      <td id=\"T_e4ea3_row3_col1\" class=\"data row3 col1\" >0.6189</td>\n",
       "      <td id=\"T_e4ea3_row3_col2\" class=\"data row3 col2\" >0.7867</td>\n",
       "      <td id=\"T_e4ea3_row3_col3\" class=\"data row3 col3\" >0.3412</td>\n",
       "      <td id=\"T_e4ea3_row3_col4\" class=\"data row3 col4\" >0.3072</td>\n",
       "      <td id=\"T_e4ea3_row3_col5\" class=\"data row3 col5\" >2.9323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e4ea3_row4_col0\" class=\"data row4 col0\" >0.4534</td>\n",
       "      <td id=\"T_e4ea3_row4_col1\" class=\"data row4 col1\" >0.4281</td>\n",
       "      <td id=\"T_e4ea3_row4_col2\" class=\"data row4 col2\" >0.6543</td>\n",
       "      <td id=\"T_e4ea3_row4_col3\" class=\"data row4 col3\" >0.4367</td>\n",
       "      <td id=\"T_e4ea3_row4_col4\" class=\"data row4 col4\" >0.3025</td>\n",
       "      <td id=\"T_e4ea3_row4_col5\" class=\"data row4 col5\" >1.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e4ea3_row5_col0\" class=\"data row5 col0\" >0.5215</td>\n",
       "      <td id=\"T_e4ea3_row5_col1\" class=\"data row5 col1\" >0.6340</td>\n",
       "      <td id=\"T_e4ea3_row5_col2\" class=\"data row5 col2\" >0.7962</td>\n",
       "      <td id=\"T_e4ea3_row5_col3\" class=\"data row5 col3\" >0.3155</td>\n",
       "      <td id=\"T_e4ea3_row5_col4\" class=\"data row5 col4\" >0.3392</td>\n",
       "      <td id=\"T_e4ea3_row5_col5\" class=\"data row5 col5\" >1.3974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e4ea3_row6_col0\" class=\"data row6 col0\" >0.5010</td>\n",
       "      <td id=\"T_e4ea3_row6_col1\" class=\"data row6 col1\" >0.8434</td>\n",
       "      <td id=\"T_e4ea3_row6_col2\" class=\"data row6 col2\" >0.9183</td>\n",
       "      <td id=\"T_e4ea3_row6_col3\" class=\"data row6 col3\" >0.3995</td>\n",
       "      <td id=\"T_e4ea3_row6_col4\" class=\"data row6 col4\" >0.3361</td>\n",
       "      <td id=\"T_e4ea3_row6_col5\" class=\"data row6 col5\" >7.7747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e4ea3_row7_col0\" class=\"data row7 col0\" >0.4988</td>\n",
       "      <td id=\"T_e4ea3_row7_col1\" class=\"data row7 col1\" >0.5057</td>\n",
       "      <td id=\"T_e4ea3_row7_col2\" class=\"data row7 col2\" >0.7112</td>\n",
       "      <td id=\"T_e4ea3_row7_col3\" class=\"data row7 col3\" >0.4951</td>\n",
       "      <td id=\"T_e4ea3_row7_col4\" class=\"data row7 col4\" >0.2948</td>\n",
       "      <td id=\"T_e4ea3_row7_col5\" class=\"data row7 col5\" >0.9191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e4ea3_row8_col0\" class=\"data row8 col0\" >0.4807</td>\n",
       "      <td id=\"T_e4ea3_row8_col1\" class=\"data row8 col1\" >0.7474</td>\n",
       "      <td id=\"T_e4ea3_row8_col2\" class=\"data row8 col2\" >0.8645</td>\n",
       "      <td id=\"T_e4ea3_row8_col3\" class=\"data row8 col3\" >0.3707</td>\n",
       "      <td id=\"T_e4ea3_row8_col4\" class=\"data row8 col4\" >0.3140</td>\n",
       "      <td id=\"T_e4ea3_row8_col5\" class=\"data row8 col5\" >1.0920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e4ea3_row9_col0\" class=\"data row9 col0\" >0.4952</td>\n",
       "      <td id=\"T_e4ea3_row9_col1\" class=\"data row9 col1\" >0.5453</td>\n",
       "      <td id=\"T_e4ea3_row9_col2\" class=\"data row9 col2\" >0.7384</td>\n",
       "      <td id=\"T_e4ea3_row9_col3\" class=\"data row9 col3\" >0.4638</td>\n",
       "      <td id=\"T_e4ea3_row9_col4\" class=\"data row9 col4\" >0.3042</td>\n",
       "      <td id=\"T_e4ea3_row9_col5\" class=\"data row9 col5\" >3.8048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_e4ea3_row10_col0\" class=\"data row10 col0\" >0.4898</td>\n",
       "      <td id=\"T_e4ea3_row10_col1\" class=\"data row10 col1\" >0.5936</td>\n",
       "      <td id=\"T_e4ea3_row10_col2\" class=\"data row10 col2\" >0.7669</td>\n",
       "      <td id=\"T_e4ea3_row10_col3\" class=\"data row10 col3\" >0.4021</td>\n",
       "      <td id=\"T_e4ea3_row10_col4\" class=\"data row10 col4\" >0.3149</td>\n",
       "      <td id=\"T_e4ea3_row10_col5\" class=\"data row10 col5\" >2.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4ea3_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_e4ea3_row11_col0\" class=\"data row11 col0\" >0.0234</td>\n",
       "      <td id=\"T_e4ea3_row11_col1\" class=\"data row11 col1\" >0.1171</td>\n",
       "      <td id=\"T_e4ea3_row11_col2\" class=\"data row11 col2\" >0.0739</td>\n",
       "      <td id=\"T_e4ea3_row11_col3\" class=\"data row11 col3\" >0.0509</td>\n",
       "      <td id=\"T_e4ea3_row11_col4\" class=\"data row11 col4\" >0.0171</td>\n",
       "      <td id=\"T_e4ea3_row11_col5\" class=\"data row11 col5\" >1.9688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc734a7a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5a5ce_row10_col0, #T_5a5ce_row10_col1, #T_5a5ce_row10_col2, #T_5a5ce_row10_col3, #T_5a5ce_row10_col4, #T_5a5ce_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5a5ce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5a5ce_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_5a5ce_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_5a5ce_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_5a5ce_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_5a5ce_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_5a5ce_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5a5ce_row0_col0\" class=\"data row0 col0\" >0.5303</td>\n",
       "      <td id=\"T_5a5ce_row0_col1\" class=\"data row0 col1\" >0.5843</td>\n",
       "      <td id=\"T_5a5ce_row0_col2\" class=\"data row0 col2\" >0.7644</td>\n",
       "      <td id=\"T_5a5ce_row0_col3\" class=\"data row0 col3\" >0.3413</td>\n",
       "      <td id=\"T_5a5ce_row0_col4\" class=\"data row0 col4\" >0.3685</td>\n",
       "      <td id=\"T_5a5ce_row0_col5\" class=\"data row0 col5\" >1.7665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5a5ce_row1_col0\" class=\"data row1 col0\" >0.5407</td>\n",
       "      <td id=\"T_5a5ce_row1_col1\" class=\"data row1 col1\" >0.6194</td>\n",
       "      <td id=\"T_5a5ce_row1_col2\" class=\"data row1 col2\" >0.7870</td>\n",
       "      <td id=\"T_5a5ce_row1_col3\" class=\"data row1 col3\" >0.2717</td>\n",
       "      <td id=\"T_5a5ce_row1_col4\" class=\"data row1 col4\" >0.3707</td>\n",
       "      <td id=\"T_5a5ce_row1_col5\" class=\"data row1 col5\" >1.4734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5a5ce_row2_col0\" class=\"data row2 col0\" >0.5492</td>\n",
       "      <td id=\"T_5a5ce_row2_col1\" class=\"data row2 col1\" >0.6039</td>\n",
       "      <td id=\"T_5a5ce_row2_col2\" class=\"data row2 col2\" >0.7771</td>\n",
       "      <td id=\"T_5a5ce_row2_col3\" class=\"data row2 col3\" >0.3632</td>\n",
       "      <td id=\"T_5a5ce_row2_col4\" class=\"data row2 col4\" >0.3641</td>\n",
       "      <td id=\"T_5a5ce_row2_col5\" class=\"data row2 col5\" >1.3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5a5ce_row3_col0\" class=\"data row3 col0\" >0.5019</td>\n",
       "      <td id=\"T_5a5ce_row3_col1\" class=\"data row3 col1\" >0.6891</td>\n",
       "      <td id=\"T_5a5ce_row3_col2\" class=\"data row3 col2\" >0.8302</td>\n",
       "      <td id=\"T_5a5ce_row3_col3\" class=\"data row3 col3\" >0.2664</td>\n",
       "      <td id=\"T_5a5ce_row3_col4\" class=\"data row3 col4\" >0.3437</td>\n",
       "      <td id=\"T_5a5ce_row3_col5\" class=\"data row3 col5\" >2.7646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5a5ce_row4_col0\" class=\"data row4 col0\" >0.4893</td>\n",
       "      <td id=\"T_5a5ce_row4_col1\" class=\"data row4 col1\" >0.4701</td>\n",
       "      <td id=\"T_5a5ce_row4_col2\" class=\"data row4 col2\" >0.6857</td>\n",
       "      <td id=\"T_5a5ce_row4_col3\" class=\"data row4 col3\" >0.3814</td>\n",
       "      <td id=\"T_5a5ce_row4_col4\" class=\"data row4 col4\" >0.3404</td>\n",
       "      <td id=\"T_5a5ce_row4_col5\" class=\"data row4 col5\" >1.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5a5ce_row5_col0\" class=\"data row5 col0\" >0.5663</td>\n",
       "      <td id=\"T_5a5ce_row5_col1\" class=\"data row5 col1\" >0.6742</td>\n",
       "      <td id=\"T_5a5ce_row5_col2\" class=\"data row5 col2\" >0.8211</td>\n",
       "      <td id=\"T_5a5ce_row5_col3\" class=\"data row5 col3\" >0.2721</td>\n",
       "      <td id=\"T_5a5ce_row5_col4\" class=\"data row5 col4\" >0.3837</td>\n",
       "      <td id=\"T_5a5ce_row5_col5\" class=\"data row5 col5\" >1.1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5a5ce_row6_col0\" class=\"data row6 col0\" >0.5609</td>\n",
       "      <td id=\"T_5a5ce_row6_col1\" class=\"data row6 col1\" >1.0046</td>\n",
       "      <td id=\"T_5a5ce_row6_col2\" class=\"data row6 col2\" >1.0023</td>\n",
       "      <td id=\"T_5a5ce_row6_col3\" class=\"data row6 col3\" >0.2847</td>\n",
       "      <td id=\"T_5a5ce_row6_col4\" class=\"data row6 col4\" >0.3896</td>\n",
       "      <td id=\"T_5a5ce_row6_col5\" class=\"data row6 col5\" >5.9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5a5ce_row7_col0\" class=\"data row7 col0\" >0.5628</td>\n",
       "      <td id=\"T_5a5ce_row7_col1\" class=\"data row7 col1\" >0.6499</td>\n",
       "      <td id=\"T_5a5ce_row7_col2\" class=\"data row7 col2\" >0.8062</td>\n",
       "      <td id=\"T_5a5ce_row7_col3\" class=\"data row7 col3\" >0.3512</td>\n",
       "      <td id=\"T_5a5ce_row7_col4\" class=\"data row7 col4\" >0.3578</td>\n",
       "      <td id=\"T_5a5ce_row7_col5\" class=\"data row7 col5\" >0.8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5a5ce_row8_col0\" class=\"data row8 col0\" >0.5263</td>\n",
       "      <td id=\"T_5a5ce_row8_col1\" class=\"data row8 col1\" >0.9001</td>\n",
       "      <td id=\"T_5a5ce_row8_col2\" class=\"data row8 col2\" >0.9488</td>\n",
       "      <td id=\"T_5a5ce_row8_col3\" class=\"data row8 col3\" >0.2421</td>\n",
       "      <td id=\"T_5a5ce_row8_col4\" class=\"data row8 col4\" >0.3628</td>\n",
       "      <td id=\"T_5a5ce_row8_col5\" class=\"data row8 col5\" >1.4617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5a5ce_row9_col0\" class=\"data row9 col0\" >0.5371</td>\n",
       "      <td id=\"T_5a5ce_row9_col1\" class=\"data row9 col1\" >0.6850</td>\n",
       "      <td id=\"T_5a5ce_row9_col2\" class=\"data row9 col2\" >0.8277</td>\n",
       "      <td id=\"T_5a5ce_row9_col3\" class=\"data row9 col3\" >0.3264</td>\n",
       "      <td id=\"T_5a5ce_row9_col4\" class=\"data row9 col4\" >0.3575</td>\n",
       "      <td id=\"T_5a5ce_row9_col5\" class=\"data row9 col5\" >2.4176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_5a5ce_row10_col0\" class=\"data row10 col0\" >0.5365</td>\n",
       "      <td id=\"T_5a5ce_row10_col1\" class=\"data row10 col1\" >0.6881</td>\n",
       "      <td id=\"T_5a5ce_row10_col2\" class=\"data row10 col2\" >0.8250</td>\n",
       "      <td id=\"T_5a5ce_row10_col3\" class=\"data row10 col3\" >0.3100</td>\n",
       "      <td id=\"T_5a5ce_row10_col4\" class=\"data row10 col4\" >0.3639</td>\n",
       "      <td id=\"T_5a5ce_row10_col5\" class=\"data row10 col5\" >2.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a5ce_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_5a5ce_row11_col0\" class=\"data row11 col0\" >0.0243</td>\n",
       "      <td id=\"T_5a5ce_row11_col1\" class=\"data row11 col1\" >0.1473</td>\n",
       "      <td id=\"T_5a5ce_row11_col2\" class=\"data row11 col2\" >0.0860</td>\n",
       "      <td id=\"T_5a5ce_row11_col3\" class=\"data row11 col3\" >0.0458</td>\n",
       "      <td id=\"T_5a5ce_row11_col4\" class=\"data row11 col4\" >0.0147</td>\n",
       "      <td id=\"T_5a5ce_row11_col5\" class=\"data row11 col5\" >1.4237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca1862950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('target_transformation',\n",
       "                  TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(include=['LeadTime(Days_to_DepartureDate)',\n",
       "                                              'SeatsSold', 'Total Revenue',\n",
       "                                              'TotalSeatsSold',\n",
       "                                              'WeightedAverageFare(SGD)'],\n",
       "                                     transformer=SimpleImputer())),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWrapper(include=[],\n",
       "                                     transformer=SimpleImputer(strategy='most_frequent'))),\n",
       "                 ('normalize', TransformerWrapper(transformer=StandardScaler())),\n",
       "                 ('clean_column_names',\n",
       "                  TransformerWrapper(transformer=CleanColumnNames())),\n",
       "                 ('actual_estimator',\n",
       "                  RandomForestRegressor(n_jobs=-1, random_state=123))]),\n",
       " 'final_model_fare.pkl')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for AverageFare(SGD)\n",
    "best_model_fare = compare_models(include=['gbr', 'lightgbm', 'rf', 'et', 'ada', 'knn', 'lasso'])\n",
    "final_model_fare = finalize_model(tune_model(create_model(best_model_fare)))\n",
    "save_model(final_model_fare, 'final_model_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4ab66_row8_col1, #T_4ab66_row12_col1, #T_4ab66_row14_col1, #T_4ab66_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4ab66\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4ab66_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_4ab66_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4ab66_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_4ab66_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4ab66_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_4ab66_row1_col1\" class=\"data row1 col1\" >SeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4ab66_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_4ab66_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4ab66_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_4ab66_row3_col1\" class=\"data row3 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4ab66_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_4ab66_row4_col1\" class=\"data row4 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4ab66_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_4ab66_row5_col1\" class=\"data row5 col1\" >(1792, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4ab66_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_4ab66_row6_col1\" class=\"data row6 col1\" >(768, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4ab66_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_4ab66_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4ab66_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_4ab66_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4ab66_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_4ab66_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_4ab66_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_4ab66_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_4ab66_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_4ab66_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_4ab66_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_4ab66_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_4ab66_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_4ab66_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_4ab66_row14_col0\" class=\"data row14 col0\" >Transform target</td>\n",
       "      <td id=\"T_4ab66_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_4ab66_row15_col0\" class=\"data row15 col0\" >Transform target method</td>\n",
       "      <td id=\"T_4ab66_row15_col1\" class=\"data row15 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_4ab66_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_4ab66_row16_col1\" class=\"data row16 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_4ab66_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_4ab66_row17_col1\" class=\"data row17 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_4ab66_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_4ab66_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_4ab66_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_4ab66_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_4ab66_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_4ab66_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_4ab66_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_4ab66_row21_col1\" class=\"data row21 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ab66_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_4ab66_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_4ab66_row22_col1\" class=\"data row22 col1\" >b2ee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca1b456c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# Setup PyCaret for SeatsSold\n",
    "s_seats = setup(\n",
    "    data=df_encoded,\n",
    "    target='SeatsSold',\n",
    "    use_gpu=True,\n",
    "    session_id=123,\n",
    "    normalize=True,  # Normalize the data\n",
    "    transform_target=True  # Apply log transformation to the target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9003f th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9003f_row0_col0, #T_9003f_row0_col1, #T_9003f_row0_col5, #T_9003f_row0_col6, #T_9003f_row1_col0, #T_9003f_row1_col2, #T_9003f_row1_col3, #T_9003f_row1_col4, #T_9003f_row1_col5, #T_9003f_row1_col6, #T_9003f_row2_col0, #T_9003f_row2_col1, #T_9003f_row2_col2, #T_9003f_row2_col3, #T_9003f_row2_col4, #T_9003f_row2_col5, #T_9003f_row2_col6, #T_9003f_row3_col0, #T_9003f_row3_col1, #T_9003f_row3_col2, #T_9003f_row3_col3, #T_9003f_row3_col4, #T_9003f_row3_col5, #T_9003f_row4_col0, #T_9003f_row4_col1, #T_9003f_row4_col2, #T_9003f_row4_col3, #T_9003f_row4_col4, #T_9003f_row4_col6, #T_9003f_row5_col0, #T_9003f_row5_col1, #T_9003f_row5_col2, #T_9003f_row5_col3, #T_9003f_row5_col4, #T_9003f_row5_col5, #T_9003f_row5_col6, #T_9003f_row6_col0, #T_9003f_row6_col1, #T_9003f_row6_col2, #T_9003f_row6_col3, #T_9003f_row6_col4, #T_9003f_row6_col5, #T_9003f_row6_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9003f_row0_col2, #T_9003f_row0_col3, #T_9003f_row0_col4, #T_9003f_row1_col1, #T_9003f_row3_col6, #T_9003f_row4_col5 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_9003f_row0_col7, #T_9003f_row1_col7, #T_9003f_row2_col7, #T_9003f_row3_col7, #T_9003f_row5_col7, #T_9003f_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_9003f_row4_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9003f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9003f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9003f_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_9003f_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_9003f_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_9003f_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_9003f_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_9003f_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_9003f_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_9003f_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_9003f_row0_col1\" class=\"data row0 col1\" >0.6803</td>\n",
       "      <td id=\"T_9003f_row0_col2\" class=\"data row0 col2\" >0.9915</td>\n",
       "      <td id=\"T_9003f_row0_col3\" class=\"data row0 col3\" >0.9908</td>\n",
       "      <td id=\"T_9003f_row0_col4\" class=\"data row0 col4\" >0.0125</td>\n",
       "      <td id=\"T_9003f_row0_col5\" class=\"data row0 col5\" >0.4082</td>\n",
       "      <td id=\"T_9003f_row0_col6\" class=\"data row0 col6\" >20.3851</td>\n",
       "      <td id=\"T_9003f_row0_col7\" class=\"data row0 col7\" >1.3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row1\" class=\"row_heading level0 row1\" >gbr</th>\n",
       "      <td id=\"T_9003f_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_9003f_row1_col1\" class=\"data row1 col1\" >0.6679</td>\n",
       "      <td id=\"T_9003f_row1_col2\" class=\"data row1 col2\" >1.0012</td>\n",
       "      <td id=\"T_9003f_row1_col3\" class=\"data row1 col3\" >0.9955</td>\n",
       "      <td id=\"T_9003f_row1_col4\" class=\"data row1 col4\" >0.0047</td>\n",
       "      <td id=\"T_9003f_row1_col5\" class=\"data row1 col5\" >0.4297</td>\n",
       "      <td id=\"T_9003f_row1_col6\" class=\"data row1 col6\" >16.1585</td>\n",
       "      <td id=\"T_9003f_row1_col7\" class=\"data row1 col7\" >0.4450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_9003f_row2_col0\" class=\"data row2 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_9003f_row2_col1\" class=\"data row2 col1\" >0.6772</td>\n",
       "      <td id=\"T_9003f_row2_col2\" class=\"data row2 col2\" >1.0002</td>\n",
       "      <td id=\"T_9003f_row2_col3\" class=\"data row2 col3\" >0.9957</td>\n",
       "      <td id=\"T_9003f_row2_col4\" class=\"data row2 col4\" >0.0033</td>\n",
       "      <td id=\"T_9003f_row2_col5\" class=\"data row2 col5\" >0.4233</td>\n",
       "      <td id=\"T_9003f_row2_col6\" class=\"data row2 col6\" >18.8984</td>\n",
       "      <td id=\"T_9003f_row2_col7\" class=\"data row2 col7\" >0.3620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row3\" class=\"row_heading level0 row3\" >ada</th>\n",
       "      <td id=\"T_9003f_row3_col0\" class=\"data row3 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_9003f_row3_col1\" class=\"data row3 col1\" >0.6935</td>\n",
       "      <td id=\"T_9003f_row3_col2\" class=\"data row3 col2\" >1.0395</td>\n",
       "      <td id=\"T_9003f_row3_col3\" class=\"data row3 col3\" >1.0151</td>\n",
       "      <td id=\"T_9003f_row3_col4\" class=\"data row3 col4\" >-0.0355</td>\n",
       "      <td id=\"T_9003f_row3_col5\" class=\"data row3 col5\" >0.4391</td>\n",
       "      <td id=\"T_9003f_row3_col6\" class=\"data row3 col6\" >13.0227</td>\n",
       "      <td id=\"T_9003f_row3_col7\" class=\"data row3 col7\" >0.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row4\" class=\"row_heading level0 row4\" >lasso</th>\n",
       "      <td id=\"T_9003f_row4_col0\" class=\"data row4 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_9003f_row4_col1\" class=\"data row4 col1\" >0.6962</td>\n",
       "      <td id=\"T_9003f_row4_col2\" class=\"data row4 col2\" >1.0865</td>\n",
       "      <td id=\"T_9003f_row4_col3\" class=\"data row4 col3\" >1.0377</td>\n",
       "      <td id=\"T_9003f_row4_col4\" class=\"data row4 col4\" >-0.0823</td>\n",
       "      <td id=\"T_9003f_row4_col5\" class=\"data row4 col5\" >0.4055</td>\n",
       "      <td id=\"T_9003f_row4_col6\" class=\"data row4 col6\" >15.0153</td>\n",
       "      <td id=\"T_9003f_row4_col7\" class=\"data row4 col7\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_9003f_row5_col0\" class=\"data row5 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_9003f_row5_col1\" class=\"data row5 col1\" >0.7296</td>\n",
       "      <td id=\"T_9003f_row5_col2\" class=\"data row5 col2\" >1.1217</td>\n",
       "      <td id=\"T_9003f_row5_col3\" class=\"data row5 col3\" >1.0543</td>\n",
       "      <td id=\"T_9003f_row5_col4\" class=\"data row5 col4\" >-0.1178</td>\n",
       "      <td id=\"T_9003f_row5_col5\" class=\"data row5 col5\" >0.4214</td>\n",
       "      <td id=\"T_9003f_row5_col6\" class=\"data row5 col6\" >19.7562</td>\n",
       "      <td id=\"T_9003f_row5_col7\" class=\"data row5 col7\" >0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9003f_level0_row6\" class=\"row_heading level0 row6\" >et</th>\n",
       "      <td id=\"T_9003f_row6_col0\" class=\"data row6 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_9003f_row6_col1\" class=\"data row6 col1\" >0.7426</td>\n",
       "      <td id=\"T_9003f_row6_col2\" class=\"data row6 col2\" >1.1368</td>\n",
       "      <td id=\"T_9003f_row6_col3\" class=\"data row6 col3\" >1.0623</td>\n",
       "      <td id=\"T_9003f_row6_col4\" class=\"data row6 col4\" >-0.1408</td>\n",
       "      <td id=\"T_9003f_row6_col5\" class=\"data row6 col5\" >0.4094</td>\n",
       "      <td id=\"T_9003f_row6_col6\" class=\"data row6 col6\" >24.1155</td>\n",
       "      <td id=\"T_9003f_row6_col7\" class=\"data row6 col7\" >0.3680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc73dc370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ca148_row10_col0, #T_ca148_row10_col1, #T_ca148_row10_col2, #T_ca148_row10_col3, #T_ca148_row10_col4, #T_ca148_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ca148\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca148_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_ca148_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_ca148_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_ca148_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_ca148_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_ca148_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca148_row0_col0\" class=\"data row0 col0\" >0.6691</td>\n",
       "      <td id=\"T_ca148_row0_col1\" class=\"data row0 col1\" >0.7538</td>\n",
       "      <td id=\"T_ca148_row0_col2\" class=\"data row0 col2\" >0.8682</td>\n",
       "      <td id=\"T_ca148_row0_col3\" class=\"data row0 col3\" >0.0368</td>\n",
       "      <td id=\"T_ca148_row0_col4\" class=\"data row0 col4\" >0.3820</td>\n",
       "      <td id=\"T_ca148_row0_col5\" class=\"data row0 col5\" >18.8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ca148_row1_col0\" class=\"data row1 col0\" >0.6373</td>\n",
       "      <td id=\"T_ca148_row1_col1\" class=\"data row1 col1\" >0.7879</td>\n",
       "      <td id=\"T_ca148_row1_col2\" class=\"data row1 col2\" >0.8876</td>\n",
       "      <td id=\"T_ca148_row1_col3\" class=\"data row1 col3\" >0.0876</td>\n",
       "      <td id=\"T_ca148_row1_col4\" class=\"data row1 col4\" >0.3889</td>\n",
       "      <td id=\"T_ca148_row1_col5\" class=\"data row1 col5\" >20.3773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ca148_row2_col0\" class=\"data row2 col0\" >0.6497</td>\n",
       "      <td id=\"T_ca148_row2_col1\" class=\"data row2 col1\" >0.8446</td>\n",
       "      <td id=\"T_ca148_row2_col2\" class=\"data row2 col2\" >0.9190</td>\n",
       "      <td id=\"T_ca148_row2_col3\" class=\"data row2 col3\" >0.1269</td>\n",
       "      <td id=\"T_ca148_row2_col4\" class=\"data row2 col4\" >0.3922</td>\n",
       "      <td id=\"T_ca148_row2_col5\" class=\"data row2 col5\" >14.2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ca148_row3_col0\" class=\"data row3 col0\" >0.6828</td>\n",
       "      <td id=\"T_ca148_row3_col1\" class=\"data row3 col1\" >0.9352</td>\n",
       "      <td id=\"T_ca148_row3_col2\" class=\"data row3 col2\" >0.9671</td>\n",
       "      <td id=\"T_ca148_row3_col3\" class=\"data row3 col3\" >0.0538</td>\n",
       "      <td id=\"T_ca148_row3_col4\" class=\"data row3 col4\" >0.4122</td>\n",
       "      <td id=\"T_ca148_row3_col5\" class=\"data row3 col5\" >25.2837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ca148_row4_col0\" class=\"data row4 col0\" >0.5727</td>\n",
       "      <td id=\"T_ca148_row4_col1\" class=\"data row4 col1\" >0.7839</td>\n",
       "      <td id=\"T_ca148_row4_col2\" class=\"data row4 col2\" >0.8854</td>\n",
       "      <td id=\"T_ca148_row4_col3\" class=\"data row4 col3\" >-0.0122</td>\n",
       "      <td id=\"T_ca148_row4_col4\" class=\"data row4 col4\" >0.3670</td>\n",
       "      <td id=\"T_ca148_row4_col5\" class=\"data row4 col5\" >24.2667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ca148_row5_col0\" class=\"data row5 col0\" >0.6884</td>\n",
       "      <td id=\"T_ca148_row5_col1\" class=\"data row5 col1\" >1.1827</td>\n",
       "      <td id=\"T_ca148_row5_col2\" class=\"data row5 col2\" >1.0875</td>\n",
       "      <td id=\"T_ca148_row5_col3\" class=\"data row5 col3\" >-0.0173</td>\n",
       "      <td id=\"T_ca148_row5_col4\" class=\"data row5 col4\" >0.4280</td>\n",
       "      <td id=\"T_ca148_row5_col5\" class=\"data row5 col5\" >23.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ca148_row6_col0\" class=\"data row6 col0\" >0.7426</td>\n",
       "      <td id=\"T_ca148_row6_col1\" class=\"data row6 col1\" >1.0806</td>\n",
       "      <td id=\"T_ca148_row6_col2\" class=\"data row6 col2\" >1.0395</td>\n",
       "      <td id=\"T_ca148_row6_col3\" class=\"data row6 col3\" >-0.0246</td>\n",
       "      <td id=\"T_ca148_row6_col4\" class=\"data row6 col4\" >0.4541</td>\n",
       "      <td id=\"T_ca148_row6_col5\" class=\"data row6 col5\" >25.2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ca148_row7_col0\" class=\"data row7 col0\" >0.6531</td>\n",
       "      <td id=\"T_ca148_row7_col1\" class=\"data row7 col1\" >0.9450</td>\n",
       "      <td id=\"T_ca148_row7_col2\" class=\"data row7 col2\" >0.9721</td>\n",
       "      <td id=\"T_ca148_row7_col3\" class=\"data row7 col3\" >-0.0460</td>\n",
       "      <td id=\"T_ca148_row7_col4\" class=\"data row7 col4\" >0.3921</td>\n",
       "      <td id=\"T_ca148_row7_col5\" class=\"data row7 col5\" >21.0816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ca148_row8_col0\" class=\"data row8 col0\" >0.7439</td>\n",
       "      <td id=\"T_ca148_row8_col1\" class=\"data row8 col1\" >1.2757</td>\n",
       "      <td id=\"T_ca148_row8_col2\" class=\"data row8 col2\" >1.1295</td>\n",
       "      <td id=\"T_ca148_row8_col3\" class=\"data row8 col3\" >0.0498</td>\n",
       "      <td id=\"T_ca148_row8_col4\" class=\"data row8 col4\" >0.4446</td>\n",
       "      <td id=\"T_ca148_row8_col5\" class=\"data row8 col5\" >11.8724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ca148_row9_col0\" class=\"data row9 col0\" >0.7619</td>\n",
       "      <td id=\"T_ca148_row9_col1\" class=\"data row9 col1\" >1.3224</td>\n",
       "      <td id=\"T_ca148_row9_col2\" class=\"data row9 col2\" >1.1499</td>\n",
       "      <td id=\"T_ca148_row9_col3\" class=\"data row9 col3\" >-0.1249</td>\n",
       "      <td id=\"T_ca148_row9_col4\" class=\"data row9 col4\" >0.4220</td>\n",
       "      <td id=\"T_ca148_row9_col5\" class=\"data row9 col5\" >18.8045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_ca148_row10_col0\" class=\"data row10 col0\" >0.6802</td>\n",
       "      <td id=\"T_ca148_row10_col1\" class=\"data row10 col1\" >0.9912</td>\n",
       "      <td id=\"T_ca148_row10_col2\" class=\"data row10 col2\" >0.9906</td>\n",
       "      <td id=\"T_ca148_row10_col3\" class=\"data row10 col3\" >0.0130</td>\n",
       "      <td id=\"T_ca148_row10_col4\" class=\"data row10 col4\" >0.4083</td>\n",
       "      <td id=\"T_ca148_row10_col5\" class=\"data row10 col5\" >20.3834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca148_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_ca148_row11_col0\" class=\"data row11 col0\" >0.0547</td>\n",
       "      <td id=\"T_ca148_row11_col1\" class=\"data row11 col1\" >0.2007</td>\n",
       "      <td id=\"T_ca148_row11_col2\" class=\"data row11 col2\" >0.0996</td>\n",
       "      <td id=\"T_ca148_row11_col3\" class=\"data row11 col3\" >0.0690</td>\n",
       "      <td id=\"T_ca148_row11_col4\" class=\"data row11 col4\" >0.0270</td>\n",
       "      <td id=\"T_ca148_row11_col5\" class=\"data row11 col5\" >4.3660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab5d01f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_15dcc_row10_col0, #T_15dcc_row10_col1, #T_15dcc_row10_col2, #T_15dcc_row10_col3, #T_15dcc_row10_col4, #T_15dcc_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_15dcc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_15dcc_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_15dcc_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_15dcc_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_15dcc_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_15dcc_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_15dcc_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_15dcc_row0_col0\" class=\"data row0 col0\" >0.6369</td>\n",
       "      <td id=\"T_15dcc_row0_col1\" class=\"data row0 col1\" >0.7455</td>\n",
       "      <td id=\"T_15dcc_row0_col2\" class=\"data row0 col2\" >0.8634</td>\n",
       "      <td id=\"T_15dcc_row0_col3\" class=\"data row0 col3\" >0.0473</td>\n",
       "      <td id=\"T_15dcc_row0_col4\" class=\"data row0 col4\" >0.3912</td>\n",
       "      <td id=\"T_15dcc_row0_col5\" class=\"data row0 col5\" >14.5194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_15dcc_row1_col0\" class=\"data row1 col0\" >0.6272</td>\n",
       "      <td id=\"T_15dcc_row1_col1\" class=\"data row1 col1\" >0.7652</td>\n",
       "      <td id=\"T_15dcc_row1_col2\" class=\"data row1 col2\" >0.8748</td>\n",
       "      <td id=\"T_15dcc_row1_col3\" class=\"data row1 col3\" >0.1138</td>\n",
       "      <td id=\"T_15dcc_row1_col4\" class=\"data row1 col4\" >0.4162</td>\n",
       "      <td id=\"T_15dcc_row1_col5\" class=\"data row1 col5\" >18.9805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_15dcc_row2_col0\" class=\"data row2 col0\" >0.6774</td>\n",
       "      <td id=\"T_15dcc_row2_col1\" class=\"data row2 col1\" >0.8897</td>\n",
       "      <td id=\"T_15dcc_row2_col2\" class=\"data row2 col2\" >0.9432</td>\n",
       "      <td id=\"T_15dcc_row2_col3\" class=\"data row2 col3\" >0.0802</td>\n",
       "      <td id=\"T_15dcc_row2_col4\" class=\"data row2 col4\" >0.4235</td>\n",
       "      <td id=\"T_15dcc_row2_col5\" class=\"data row2 col5\" >14.3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_15dcc_row3_col0\" class=\"data row3 col0\" >0.6786</td>\n",
       "      <td id=\"T_15dcc_row3_col1\" class=\"data row3 col1\" >0.9656</td>\n",
       "      <td id=\"T_15dcc_row3_col2\" class=\"data row3 col2\" >0.9827</td>\n",
       "      <td id=\"T_15dcc_row3_col3\" class=\"data row3 col3\" >0.0230</td>\n",
       "      <td id=\"T_15dcc_row3_col4\" class=\"data row3 col4\" >0.4270</td>\n",
       "      <td id=\"T_15dcc_row3_col5\" class=\"data row3 col5\" >21.2679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_15dcc_row4_col0\" class=\"data row4 col0\" >0.5643</td>\n",
       "      <td id=\"T_15dcc_row4_col1\" class=\"data row4 col1\" >0.7774</td>\n",
       "      <td id=\"T_15dcc_row4_col2\" class=\"data row4 col2\" >0.8817</td>\n",
       "      <td id=\"T_15dcc_row4_col3\" class=\"data row4 col3\" >-0.0038</td>\n",
       "      <td id=\"T_15dcc_row4_col4\" class=\"data row4 col4\" >0.3663</td>\n",
       "      <td id=\"T_15dcc_row4_col5\" class=\"data row4 col5\" >23.4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_15dcc_row5_col0\" class=\"data row5 col0\" >0.6824</td>\n",
       "      <td id=\"T_15dcc_row5_col1\" class=\"data row5 col1\" >1.1574</td>\n",
       "      <td id=\"T_15dcc_row5_col2\" class=\"data row5 col2\" >1.0758</td>\n",
       "      <td id=\"T_15dcc_row5_col3\" class=\"data row5 col3\" >0.0044</td>\n",
       "      <td id=\"T_15dcc_row5_col4\" class=\"data row5 col4\" >0.4376</td>\n",
       "      <td id=\"T_15dcc_row5_col5\" class=\"data row5 col5\" >20.1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_15dcc_row6_col0\" class=\"data row6 col0\" >0.6915</td>\n",
       "      <td id=\"T_15dcc_row6_col1\" class=\"data row6 col1\" >1.0230</td>\n",
       "      <td id=\"T_15dcc_row6_col2\" class=\"data row6 col2\" >1.0115</td>\n",
       "      <td id=\"T_15dcc_row6_col3\" class=\"data row6 col3\" >0.0299</td>\n",
       "      <td id=\"T_15dcc_row6_col4\" class=\"data row6 col4\" >0.4613</td>\n",
       "      <td id=\"T_15dcc_row6_col5\" class=\"data row6 col5\" >21.3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_15dcc_row7_col0\" class=\"data row7 col0\" >0.6336</td>\n",
       "      <td id=\"T_15dcc_row7_col1\" class=\"data row7 col1\" >0.9180</td>\n",
       "      <td id=\"T_15dcc_row7_col2\" class=\"data row7 col2\" >0.9581</td>\n",
       "      <td id=\"T_15dcc_row7_col3\" class=\"data row7 col3\" >-0.0161</td>\n",
       "      <td id=\"T_15dcc_row7_col4\" class=\"data row7 col4\" >0.4033</td>\n",
       "      <td id=\"T_15dcc_row7_col5\" class=\"data row7 col5\" >18.2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_15dcc_row8_col0\" class=\"data row8 col0\" >0.7637</td>\n",
       "      <td id=\"T_15dcc_row8_col1\" class=\"data row8 col1\" >1.3353</td>\n",
       "      <td id=\"T_15dcc_row8_col2\" class=\"data row8 col2\" >1.1555</td>\n",
       "      <td id=\"T_15dcc_row8_col3\" class=\"data row8 col3\" >0.0055</td>\n",
       "      <td id=\"T_15dcc_row8_col4\" class=\"data row8 col4\" >0.4706</td>\n",
       "      <td id=\"T_15dcc_row8_col5\" class=\"data row8 col5\" >11.1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_15dcc_row9_col0\" class=\"data row9 col0\" >0.7166</td>\n",
       "      <td id=\"T_15dcc_row9_col1\" class=\"data row9 col1\" >1.2159</td>\n",
       "      <td id=\"T_15dcc_row9_col2\" class=\"data row9 col2\" >1.1027</td>\n",
       "      <td id=\"T_15dcc_row9_col3\" class=\"data row9 col3\" >-0.0344</td>\n",
       "      <td id=\"T_15dcc_row9_col4\" class=\"data row9 col4\" >0.4280</td>\n",
       "      <td id=\"T_15dcc_row9_col5\" class=\"data row9 col5\" >13.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_15dcc_row10_col0\" class=\"data row10 col0\" >0.6672</td>\n",
       "      <td id=\"T_15dcc_row10_col1\" class=\"data row10 col1\" >0.9793</td>\n",
       "      <td id=\"T_15dcc_row10_col2\" class=\"data row10 col2\" >0.9849</td>\n",
       "      <td id=\"T_15dcc_row10_col3\" class=\"data row10 col3\" >0.0250</td>\n",
       "      <td id=\"T_15dcc_row10_col4\" class=\"data row10 col4\" >0.4225</td>\n",
       "      <td id=\"T_15dcc_row10_col5\" class=\"data row10 col5\" >17.7376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_15dcc_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_15dcc_row11_col0\" class=\"data row11 col0\" >0.0520</td>\n",
       "      <td id=\"T_15dcc_row11_col1\" class=\"data row11 col1\" >0.1922</td>\n",
       "      <td id=\"T_15dcc_row11_col2\" class=\"data row11 col2\" >0.0959</td>\n",
       "      <td id=\"T_15dcc_row11_col3\" class=\"data row11 col3\" >0.0428</td>\n",
       "      <td id=\"T_15dcc_row11_col4\" class=\"data row11 col4\" >0.0294</td>\n",
       "      <td id=\"T_15dcc_row11_col5\" class=\"data row11 col5\" >3.8152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23c9e6b3400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004804 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.005008 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001078 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003838 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001801 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002000 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001541 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001446 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001969 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002094 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001444 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001740 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001490 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001318 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001411 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001463 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001653 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001439 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001769 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001759 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001989 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001404 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001371 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001861 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001375 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001798 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001928 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001516 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001404 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001541 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001465 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001792 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001759 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001438 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001287 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001557 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001594 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001311 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001277 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001307 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001383 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001494 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001488 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002038 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002108 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003270 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001927 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001439 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001494 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001743 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001557 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001377 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001461 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001450 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001532 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001290 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001318 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001337 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001280 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000913 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001095 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001105 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001150 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000900 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001312 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001012 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001123 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000919 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001065 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001297 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001037 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000959 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001859 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001218 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002340 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001344 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001779 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001523 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001271 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001731 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001584 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001516 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002046 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003471 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001754 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001382 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001780 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002232 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002435 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002168 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001654 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.008007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001339 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001359 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.016566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001744 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001515 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001488 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.004035 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001793 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001353 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001519 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.006282 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001426 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003263 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002029 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001490 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001885 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001613 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001932 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002094 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001806 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001498 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001977 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000973 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001149 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001045 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001077 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001115 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000988 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001075 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001142 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001067 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001348 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001333 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001152 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001370 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001714 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001099 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001082 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001854 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001541 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002314 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001603 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001804 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001717 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001822 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001772 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001411 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001789 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001823 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001787 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002546 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001533 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002335 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001410 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001713 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001450 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 102\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001293 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001396 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001349 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001119 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000956 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001306 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001750 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001683 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001741 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001432 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.004819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001928 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001557 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002385 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001671 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001435 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001261 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001119 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001019 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001060 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001209 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001217 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001004 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001077 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1011\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001693 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001933 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001384 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001348 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1010\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001295 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1013\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001639 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1012\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001808 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001673 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001431 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1011\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002426 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001733 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001143 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.000970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001222 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.000998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001626 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001956 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002117 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1009\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001940 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001845 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002177 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1012\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 99\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001154 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.003888 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001051 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001038 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.000944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 996\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 94\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001867 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001426 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001731 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001439 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001880 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001635 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 93\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001290 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001657 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001912 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001379 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001964 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001385 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001454 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001364 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001444 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001389 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001299 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001489 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001333 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001362 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001372 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001352 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001775 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001396 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001961 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001407 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001327 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001740 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001366 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001697 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001342 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 998\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 94\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001438 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001849 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001517 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001295 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001426 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001401 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001830 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001383 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001315 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001517 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001660 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001471 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001661 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001350 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001462 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001837 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001435 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001374 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001590 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001408 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001402 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001493 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001852 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001703 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 93\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001406 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001445 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001796 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001438 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001814 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001675 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001671 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001882 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001417 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001743 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002152 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001444 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001517 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 990\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 92\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001798 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001584 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001386 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001635 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001322 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001400 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002044 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002264 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001621 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001388 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001527 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001792 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001388 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001332 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001517 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001809 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 93\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001177 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001084 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001083 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001104 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002185 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001075 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001198 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001028 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001077 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001162 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001090 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001036 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001342 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001092 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002213 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001579 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001098 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.003301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002256 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001160 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001135 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000972 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001167 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001055 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001014 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001294 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001032 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000954 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000960 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001255 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001027 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001200 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001037 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 94\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001892 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001340 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001979 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001539 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.056778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.009963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001590 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001358 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001712 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001469 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001901 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001515 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003286 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.004850 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001892 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001433 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001810 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001518 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001405 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001648 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001523 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 93\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001854 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001531 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001755 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001777 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001586 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001833 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001558 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001448 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001346 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001871 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001326 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001514 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001304 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003735 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001639 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001483 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001434 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001414 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001538 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001565 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001497 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001602 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001717 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001390 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 94\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.005131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001399 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001581 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001555 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001345 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001941 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001511 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001590 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001345 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001248 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001410 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001298 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002608 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001441 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001974 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001359 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001732 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001631 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002042 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001515 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001413 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001347 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001490 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 994\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 93\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001263 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000970 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001022 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001107 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001317 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001120 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000919 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001010 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001080 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000905 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001026 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001165 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000955 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001827 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.003724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001275 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001055 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000990 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000944 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001030 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001053 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001081 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001487 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001025 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001265 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001097 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001285 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001021 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001072 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001351 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 966\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 84\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004368 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001712 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001532 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001431 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001765 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 977\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 88\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004897 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001429 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001461 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002328 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001678 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001438 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001404 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 88\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002089 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001584 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001506 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001360 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 979\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 88\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.005267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001412 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001475 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 975\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 87\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001444 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001418 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001319 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001404 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001449 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 968\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 85\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.002470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001341 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.000968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001067 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001013 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.000931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001050 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001137 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001058 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 964\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 84\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.006114 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001768 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 973\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 86\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001698 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001841 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.005273 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.006646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002811 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001688 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 985\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 91\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001914 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001493 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001366 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001380 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001742 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 976\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 87\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.002186 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001223 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001070 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001065 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001211 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001403 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001170 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001313 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1022\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1025\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001754 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1019\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 102\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1021\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1024\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 103\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001879 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002034 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001799 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001847 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001598 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001809 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002238 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001899 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001543 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001730 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002058 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001566 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001943 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001868 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001903 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001784 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001773 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001530 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002162 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002074 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001938 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002194 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001685 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002009 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001593 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001854 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002066 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001868 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001714 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001605 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001422 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001428 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001769 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001764 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001844 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001396 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001524 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001702 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001639 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001553 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002091 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001472 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001855 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001507 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001714 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001635 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002064 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001435 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001500 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001464 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001483 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001588 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001427 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001689 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001869 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002176 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001971 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001568 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001633 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001660 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001482 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001795 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001804 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001918 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001797 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003289 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001763 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001354 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001604 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002030 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001855 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001921 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001355 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001806 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001746 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001817 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001459 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001750 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001584 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001932 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001726 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001890 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001467 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001770 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001968 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001549 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001975 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001486 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001668 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001758 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001665 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001756 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001470 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001632 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002162 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001871 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001648 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001509 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001790 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001705 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001481 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001766 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001648 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001484 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001828 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002132 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001579 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001394 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001421 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001391 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001425 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001571 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001643 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001465 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001666 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001806 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001989 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001716 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001907 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001728 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001917 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001895 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001891 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001749 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001812 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001872 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001808 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001778 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001985 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002269 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002561 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001701 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001679 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001837 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001688 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001619 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001854 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002423 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001451 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001455 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001802 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002133 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001877 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001510 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001957 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001722 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001803 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001849 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001988 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001891 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001658 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001813 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001546 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002068 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002001 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001927 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001545 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001775 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001683 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002535 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001776 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001747 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002393 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001829 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001808 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001721 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001689 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001612 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.005096 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001161 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001424 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001199 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001265 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001221 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001208 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001265 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001169 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001100 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001662 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001253 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001203 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001251 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001267 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001437 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001323 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001222 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001132 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001196 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001392 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001361 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001479 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001225 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001316 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001336 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001312 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001241 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001447 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001216 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001254 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001231 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001204 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001333 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001398 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001249 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001061 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001485 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001315 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000947 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001031 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001242 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001038 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001111 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001063 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001257 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001326 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001338 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001886 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001297 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001831 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002504 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001522 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001562 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001905 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001649 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001842 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002624 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001741 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001440 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001848 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002047 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002155 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001857 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001563 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001616 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001824 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001551 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001430 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001823 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001580 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001544 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001523 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002049 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001466 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001760 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002033 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001759 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001699 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001559 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001443 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001630 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001587 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001637 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001782 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001714 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001603 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002006 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001910 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.003279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002295 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001906 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001415 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001657 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004139 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001589 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001805 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001952 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001978 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001657 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001573 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001717 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001600 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001456 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001886 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001436 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001492 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001611 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.004695 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001788 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001363 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001771 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001670 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001718 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001696 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001920 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001534 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001966 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001962 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002501 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001676 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001677 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001495 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001704 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001839 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001919 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001745 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001528 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001740 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001797 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001868 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001523 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001576 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001765 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001521 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001791 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001720 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001774 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001715 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001739 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001651 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001870 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001574 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001664 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 811\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001929 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002660 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001690 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001684 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001711 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001967 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002130 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001585 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001767 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001536 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001994 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001672 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001390 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001931 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001595 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001707 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002074 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001781 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001876 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001807 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001750 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001819 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002116 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001864 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001583 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001512 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001995 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001951 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001725 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001832 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001652 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001734 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001556 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001592 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001572 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001621 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001513 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001407 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001474 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001452 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001458 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001609 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001397 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001419 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001420 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001709 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001520 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001687 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001622 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001889 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001547 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001653 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001457 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 33\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001124 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001343 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001301 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001108 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001052 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001217 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001365 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001279 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001179 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001085 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001478 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001252 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001145 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001184 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001039 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001227 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001158 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000980 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001023 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001076 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001088 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.003367 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001172 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001175 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001266 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001246 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001140 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001250 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001376 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001127 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001153 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001311 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001228 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001537 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001606 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001243 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001182 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001270 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001190 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001395 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001334 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001247 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001480 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001186 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001260 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001257 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001122 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001112 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001172 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001141 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001079 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001121 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001347 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001164 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001281 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001101 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001128 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001329 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001340 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001166 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004174 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001691 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001846 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001741 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001686 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001834 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001582 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001694 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002131 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001499 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001491 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001762 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002069 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 35\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001564 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001560 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001516 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001453 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001540 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001505 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001708 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001998 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002171 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001898 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001569 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001628 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001577 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 35\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001753 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001548 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001617 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001610 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001597 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001620 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001780 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001640 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001794 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001926 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001473 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001641 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 829\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 38\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001942 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001636 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001866 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001700 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001965 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001808 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001526 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001591 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001542 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001599 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001575 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001525 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002129 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001570 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 35\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004336 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001614 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001692 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001680 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001698 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001821 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001508 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001601 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001416 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001729 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002195 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001409 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001674 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001618 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001634 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001138 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001310 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001324 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001308 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001357 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001232 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001241 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001378 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001157 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001369 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001144 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001274 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001106 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001039 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 36\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001468 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001625 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002554 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001567 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001615 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001825 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001596 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001719 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001550 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001645 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001682 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001529 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001659 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001761 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 826\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 37\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001775 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001607 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001639 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001627 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001675 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001667 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001578 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001737 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001858 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002263 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001669 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001982 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001496 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001590 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001763 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001656 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 34\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.004736 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001655 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001945 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001712 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001710 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001783 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001852 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001963 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001663 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.002007 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001647 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001638 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001724 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001644 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001681 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.01 MB) transferred to GPU in 0.001839 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 35\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.003245 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001646 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001062 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001801 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001323 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001207 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001134 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001173 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001020 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001629 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001206 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.002373 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.001146 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000991 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000923 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.01 MB) transferred to GPU in 0.000997 secs. 1 sparse feature groups\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1008\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.006552 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.311621\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 1612, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001623 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.305454\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1010\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002018 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.319273\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1009\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.002853 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.323215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1008\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.003976 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.320849\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1007\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001103 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.316372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001476 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.328713\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1009\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.005503 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.299214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 12 dense feature groups (0.02 MB) transferred to GPU in 0.001460 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314973\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 1009\n",
      "[LightGBM] [Info] Number of data points in the train set: 1613, number of used features: 98\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 11 dense feature groups (0.02 MB) transferred to GPU in 0.001136 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.314215\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('target_transformation',\n",
       "                  TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(include=['AverageFare(SGD)',\n",
       "                                              'LeadTime(Days_to_DepartureDate)',\n",
       "                                              'Total Revenue', 'TotalSeatsSold',\n",
       "                                              'WeightedAverageFare(SGD)'],\n",
       "                                     transform...\n",
       "                 ('normalize', TransformerWrapper(transformer=StandardScaler())),\n",
       "                 ('clean_column_names',\n",
       "                  TransformerWrapper(transformer=CleanColumnNames())),\n",
       "                 ('actual_estimator',\n",
       "                  LGBMRegressor(bagging_fraction=0.7, bagging_freq=6,\n",
       "                                device='gpu', feature_fraction=0.5,\n",
       "                                min_child_samples=66, min_split_gain=0.4,\n",
       "                                n_estimators=90, n_jobs=-1, num_leaves=90,\n",
       "                                random_state=123, reg_alpha=0.0005,\n",
       "                                reg_lambda=0.1))]),\n",
       " 'final_model_seats.pkl')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for SeatsSold\n",
    "best_model_seats = compare_models(include=['gbr', 'lightgbm', 'rf', 'et', 'ada', 'knn', 'lasso'])\n",
    "final_model_seats = finalize_model(tune_model(create_model(best_model_seats)))\n",
    "save_model(final_model_seats, 'final_model_seats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_daef3_row8_col1, #T_daef3_row12_col1, #T_daef3_row14_col1, #T_daef3_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_daef3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_daef3_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_daef3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_daef3_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_daef3_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_daef3_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_daef3_row1_col1\" class=\"data row1 col1\" >WeightedAverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_daef3_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_daef3_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_daef3_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_daef3_row3_col1\" class=\"data row3 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_daef3_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_daef3_row4_col1\" class=\"data row4 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_daef3_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_daef3_row5_col1\" class=\"data row5 col1\" >(1792, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_daef3_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_daef3_row6_col1\" class=\"data row6 col1\" >(768, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_daef3_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_daef3_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_daef3_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_daef3_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_daef3_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_daef3_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_daef3_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_daef3_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_daef3_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_daef3_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_daef3_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_daef3_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_daef3_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_daef3_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_daef3_row14_col0\" class=\"data row14 col0\" >Transform target</td>\n",
       "      <td id=\"T_daef3_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_daef3_row15_col0\" class=\"data row15 col0\" >Transform target method</td>\n",
       "      <td id=\"T_daef3_row15_col1\" class=\"data row15 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_daef3_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_daef3_row16_col1\" class=\"data row16 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_daef3_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_daef3_row17_col1\" class=\"data row17 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_daef3_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_daef3_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_daef3_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_daef3_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_daef3_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_daef3_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_daef3_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_daef3_row21_col1\" class=\"data row21 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_daef3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_daef3_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_daef3_row22_col1\" class=\"data row22 col1\" >8837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab4908e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# Setup PyCaret for WeightedAverageFare(SGD)\n",
    "s_seats = setup(\n",
    "    data=df_encoded,\n",
    "    target='WeightedAverageFare(SGD)',\n",
    "    use_gpu=True,\n",
    "    session_id=123,\n",
    "    normalize=True,  # Normalize the data\n",
    "    transform_target=True  # Apply log transformation to the target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb71d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb71d_row0_col0, #T_bb71d_row1_col0, #T_bb71d_row1_col1, #T_bb71d_row1_col2, #T_bb71d_row1_col3, #T_bb71d_row1_col4, #T_bb71d_row1_col5, #T_bb71d_row1_col6, #T_bb71d_row2_col0, #T_bb71d_row2_col1, #T_bb71d_row2_col2, #T_bb71d_row2_col3, #T_bb71d_row2_col4, #T_bb71d_row2_col5, #T_bb71d_row2_col6, #T_bb71d_row3_col0, #T_bb71d_row3_col1, #T_bb71d_row3_col2, #T_bb71d_row3_col3, #T_bb71d_row3_col4, #T_bb71d_row3_col5, #T_bb71d_row3_col6, #T_bb71d_row4_col0, #T_bb71d_row4_col1, #T_bb71d_row4_col2, #T_bb71d_row4_col3, #T_bb71d_row4_col4, #T_bb71d_row4_col5, #T_bb71d_row4_col6, #T_bb71d_row5_col0, #T_bb71d_row5_col1, #T_bb71d_row5_col2, #T_bb71d_row5_col3, #T_bb71d_row5_col4, #T_bb71d_row5_col5, #T_bb71d_row5_col6, #T_bb71d_row6_col0, #T_bb71d_row6_col1, #T_bb71d_row6_col2, #T_bb71d_row6_col3, #T_bb71d_row6_col4, #T_bb71d_row6_col5, #T_bb71d_row6_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb71d_row0_col1, #T_bb71d_row0_col2, #T_bb71d_row0_col3, #T_bb71d_row0_col4, #T_bb71d_row0_col5, #T_bb71d_row0_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_bb71d_row0_col7, #T_bb71d_row1_col7, #T_bb71d_row2_col7, #T_bb71d_row3_col7, #T_bb71d_row4_col7, #T_bb71d_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_bb71d_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb71d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb71d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bb71d_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_bb71d_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_bb71d_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_bb71d_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_bb71d_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_bb71d_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_bb71d_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_bb71d_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_bb71d_row0_col1\" class=\"data row0 col1\" >0.3147</td>\n",
       "      <td id=\"T_bb71d_row0_col2\" class=\"data row0 col2\" >0.2428</td>\n",
       "      <td id=\"T_bb71d_row0_col3\" class=\"data row0 col3\" >0.4921</td>\n",
       "      <td id=\"T_bb71d_row0_col4\" class=\"data row0 col4\" >0.7568</td>\n",
       "      <td id=\"T_bb71d_row0_col5\" class=\"data row0 col5\" >0.2212</td>\n",
       "      <td id=\"T_bb71d_row0_col6\" class=\"data row0 col6\" >0.6378</td>\n",
       "      <td id=\"T_bb71d_row0_col7\" class=\"data row0 col7\" >0.3590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_bb71d_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_bb71d_row1_col1\" class=\"data row1 col1\" >0.3530</td>\n",
       "      <td id=\"T_bb71d_row1_col2\" class=\"data row1 col2\" >0.2517</td>\n",
       "      <td id=\"T_bb71d_row1_col3\" class=\"data row1 col3\" >0.5001</td>\n",
       "      <td id=\"T_bb71d_row1_col4\" class=\"data row1 col4\" >0.7483</td>\n",
       "      <td id=\"T_bb71d_row1_col5\" class=\"data row1 col5\" >0.2340</td>\n",
       "      <td id=\"T_bb71d_row1_col6\" class=\"data row1 col6\" >0.7739</td>\n",
       "      <td id=\"T_bb71d_row1_col7\" class=\"data row1 col7\" >1.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row2\" class=\"row_heading level0 row2\" >et</th>\n",
       "      <td id=\"T_bb71d_row2_col0\" class=\"data row2 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_bb71d_row2_col1\" class=\"data row2 col1\" >0.3323</td>\n",
       "      <td id=\"T_bb71d_row2_col2\" class=\"data row2 col2\" >0.2601</td>\n",
       "      <td id=\"T_bb71d_row2_col3\" class=\"data row2 col3\" >0.5095</td>\n",
       "      <td id=\"T_bb71d_row2_col4\" class=\"data row2 col4\" >0.7391</td>\n",
       "      <td id=\"T_bb71d_row2_col5\" class=\"data row2 col5\" >0.2214</td>\n",
       "      <td id=\"T_bb71d_row2_col6\" class=\"data row2 col6\" >0.6833</td>\n",
       "      <td id=\"T_bb71d_row2_col7\" class=\"data row2 col7\" >0.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row3\" class=\"row_heading level0 row3\" >gbr</th>\n",
       "      <td id=\"T_bb71d_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_bb71d_row3_col1\" class=\"data row3 col1\" >0.3998</td>\n",
       "      <td id=\"T_bb71d_row3_col2\" class=\"data row3 col2\" >0.2883</td>\n",
       "      <td id=\"T_bb71d_row3_col3\" class=\"data row3 col3\" >0.5366</td>\n",
       "      <td id=\"T_bb71d_row3_col4\" class=\"data row3 col4\" >0.7111</td>\n",
       "      <td id=\"T_bb71d_row3_col5\" class=\"data row3 col5\" >0.2568</td>\n",
       "      <td id=\"T_bb71d_row3_col6\" class=\"data row3 col6\" >0.8902</td>\n",
       "      <td id=\"T_bb71d_row3_col7\" class=\"data row3 col7\" >0.4520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_bb71d_row4_col0\" class=\"data row4 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_bb71d_row4_col1\" class=\"data row4 col1\" >0.4954</td>\n",
       "      <td id=\"T_bb71d_row4_col2\" class=\"data row4 col2\" >0.3725</td>\n",
       "      <td id=\"T_bb71d_row4_col3\" class=\"data row4 col3\" >0.6100</td>\n",
       "      <td id=\"T_bb71d_row4_col4\" class=\"data row4 col4\" >0.6268</td>\n",
       "      <td id=\"T_bb71d_row4_col5\" class=\"data row4 col5\" >0.3138</td>\n",
       "      <td id=\"T_bb71d_row4_col6\" class=\"data row4 col6\" >1.3115</td>\n",
       "      <td id=\"T_bb71d_row4_col7\" class=\"data row4 col7\" >0.1730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_bb71d_row5_col0\" class=\"data row5 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_bb71d_row5_col1\" class=\"data row5 col1\" >0.7155</td>\n",
       "      <td id=\"T_bb71d_row5_col2\" class=\"data row5 col2\" >0.7770</td>\n",
       "      <td id=\"T_bb71d_row5_col3\" class=\"data row5 col3\" >0.8805</td>\n",
       "      <td id=\"T_bb71d_row5_col4\" class=\"data row5 col4\" >0.2222</td>\n",
       "      <td id=\"T_bb71d_row5_col5\" class=\"data row5 col5\" >0.4016</td>\n",
       "      <td id=\"T_bb71d_row5_col6\" class=\"data row5 col6\" >1.5547</td>\n",
       "      <td id=\"T_bb71d_row5_col7\" class=\"data row5 col7\" >0.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb71d_level0_row6\" class=\"row_heading level0 row6\" >lasso</th>\n",
       "      <td id=\"T_bb71d_row6_col0\" class=\"data row6 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_bb71d_row6_col1\" class=\"data row6 col1\" >0.8495</td>\n",
       "      <td id=\"T_bb71d_row6_col2\" class=\"data row6 col2\" >1.0192</td>\n",
       "      <td id=\"T_bb71d_row6_col3\" class=\"data row6 col3\" >1.0091</td>\n",
       "      <td id=\"T_bb71d_row6_col4\" class=\"data row6 col4\" >-0.0193</td>\n",
       "      <td id=\"T_bb71d_row6_col5\" class=\"data row6 col5\" >0.5653</td>\n",
       "      <td id=\"T_bb71d_row6_col6\" class=\"data row6 col6\" >1.0691</td>\n",
       "      <td id=\"T_bb71d_row6_col7\" class=\"data row6 col7\" >0.0610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23c9e7b9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6b407_row10_col0, #T_6b407_row10_col1, #T_6b407_row10_col2, #T_6b407_row10_col3, #T_6b407_row10_col4, #T_6b407_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6b407\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6b407_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_6b407_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_6b407_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_6b407_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_6b407_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_6b407_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6b407_row0_col0\" class=\"data row0 col0\" >0.3142</td>\n",
       "      <td id=\"T_6b407_row0_col1\" class=\"data row0 col1\" >0.2555</td>\n",
       "      <td id=\"T_6b407_row0_col2\" class=\"data row0 col2\" >0.5055</td>\n",
       "      <td id=\"T_6b407_row0_col3\" class=\"data row0 col3\" >0.7533</td>\n",
       "      <td id=\"T_6b407_row0_col4\" class=\"data row0 col4\" >0.2282</td>\n",
       "      <td id=\"T_6b407_row0_col5\" class=\"data row0 col5\" >0.6190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6b407_row1_col0\" class=\"data row1 col0\" >0.3270</td>\n",
       "      <td id=\"T_6b407_row1_col1\" class=\"data row1 col1\" >0.2825</td>\n",
       "      <td id=\"T_6b407_row1_col2\" class=\"data row1 col2\" >0.5315</td>\n",
       "      <td id=\"T_6b407_row1_col3\" class=\"data row1 col3\" >0.7202</td>\n",
       "      <td id=\"T_6b407_row1_col4\" class=\"data row1 col4\" >0.2439</td>\n",
       "      <td id=\"T_6b407_row1_col5\" class=\"data row1 col5\" >0.5850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6b407_row2_col0\" class=\"data row2 col0\" >0.3183</td>\n",
       "      <td id=\"T_6b407_row2_col1\" class=\"data row2 col1\" >0.2373</td>\n",
       "      <td id=\"T_6b407_row2_col2\" class=\"data row2 col2\" >0.4871</td>\n",
       "      <td id=\"T_6b407_row2_col3\" class=\"data row2 col3\" >0.7705</td>\n",
       "      <td id=\"T_6b407_row2_col4\" class=\"data row2 col4\" >0.2392</td>\n",
       "      <td id=\"T_6b407_row2_col5\" class=\"data row2 col5\" >0.6183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6b407_row3_col0\" class=\"data row3 col0\" >0.3346</td>\n",
       "      <td id=\"T_6b407_row3_col1\" class=\"data row3 col1\" >0.2746</td>\n",
       "      <td id=\"T_6b407_row3_col2\" class=\"data row3 col2\" >0.5240</td>\n",
       "      <td id=\"T_6b407_row3_col3\" class=\"data row3 col3\" >0.7325</td>\n",
       "      <td id=\"T_6b407_row3_col4\" class=\"data row3 col4\" >0.2309</td>\n",
       "      <td id=\"T_6b407_row3_col5\" class=\"data row3 col5\" >0.8042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6b407_row4_col0\" class=\"data row4 col0\" >0.3164</td>\n",
       "      <td id=\"T_6b407_row4_col1\" class=\"data row4 col1\" >0.2265</td>\n",
       "      <td id=\"T_6b407_row4_col2\" class=\"data row4 col2\" >0.4760</td>\n",
       "      <td id=\"T_6b407_row4_col3\" class=\"data row4 col3\" >0.7633</td>\n",
       "      <td id=\"T_6b407_row4_col4\" class=\"data row4 col4\" >0.1961</td>\n",
       "      <td id=\"T_6b407_row4_col5\" class=\"data row4 col5\" >0.5771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6b407_row5_col0\" class=\"data row5 col0\" >0.3171</td>\n",
       "      <td id=\"T_6b407_row5_col1\" class=\"data row5 col1\" >0.2629</td>\n",
       "      <td id=\"T_6b407_row5_col2\" class=\"data row5 col2\" >0.5128</td>\n",
       "      <td id=\"T_6b407_row5_col3\" class=\"data row5 col3\" >0.7387</td>\n",
       "      <td id=\"T_6b407_row5_col4\" class=\"data row5 col4\" >0.2128</td>\n",
       "      <td id=\"T_6b407_row5_col5\" class=\"data row5 col5\" >0.6271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6b407_row6_col0\" class=\"data row6 col0\" >0.2801</td>\n",
       "      <td id=\"T_6b407_row6_col1\" class=\"data row6 col1\" >0.1975</td>\n",
       "      <td id=\"T_6b407_row6_col2\" class=\"data row6 col2\" >0.4444</td>\n",
       "      <td id=\"T_6b407_row6_col3\" class=\"data row6 col3\" >0.8137</td>\n",
       "      <td id=\"T_6b407_row6_col4\" class=\"data row6 col4\" >0.2004</td>\n",
       "      <td id=\"T_6b407_row6_col5\" class=\"data row6 col5\" >0.4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6b407_row7_col0\" class=\"data row7 col0\" >0.3243</td>\n",
       "      <td id=\"T_6b407_row7_col1\" class=\"data row7 col1\" >0.2283</td>\n",
       "      <td id=\"T_6b407_row7_col2\" class=\"data row7 col2\" >0.4778</td>\n",
       "      <td id=\"T_6b407_row7_col3\" class=\"data row7 col3\" >0.7734</td>\n",
       "      <td id=\"T_6b407_row7_col4\" class=\"data row7 col4\" >0.2420</td>\n",
       "      <td id=\"T_6b407_row7_col5\" class=\"data row7 col5\" >0.6580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6b407_row8_col0\" class=\"data row8 col0\" >0.2852</td>\n",
       "      <td id=\"T_6b407_row8_col1\" class=\"data row8 col1\" >0.2189</td>\n",
       "      <td id=\"T_6b407_row8_col2\" class=\"data row8 col2\" >0.4679</td>\n",
       "      <td id=\"T_6b407_row8_col3\" class=\"data row8 col3\" >0.7462</td>\n",
       "      <td id=\"T_6b407_row8_col4\" class=\"data row8 col4\" >0.2021</td>\n",
       "      <td id=\"T_6b407_row8_col5\" class=\"data row8 col5\" >0.7981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6b407_row9_col0\" class=\"data row9 col0\" >0.3295</td>\n",
       "      <td id=\"T_6b407_row9_col1\" class=\"data row9 col1\" >0.2440</td>\n",
       "      <td id=\"T_6b407_row9_col2\" class=\"data row9 col2\" >0.4940</td>\n",
       "      <td id=\"T_6b407_row9_col3\" class=\"data row9 col3\" >0.7557</td>\n",
       "      <td id=\"T_6b407_row9_col4\" class=\"data row9 col4\" >0.2167</td>\n",
       "      <td id=\"T_6b407_row9_col5\" class=\"data row9 col5\" >0.6610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_6b407_row10_col0\" class=\"data row10 col0\" >0.3147</td>\n",
       "      <td id=\"T_6b407_row10_col1\" class=\"data row10 col1\" >0.2428</td>\n",
       "      <td id=\"T_6b407_row10_col2\" class=\"data row10 col2\" >0.4921</td>\n",
       "      <td id=\"T_6b407_row10_col3\" class=\"data row10 col3\" >0.7568</td>\n",
       "      <td id=\"T_6b407_row10_col4\" class=\"data row10 col4\" >0.2212</td>\n",
       "      <td id=\"T_6b407_row10_col5\" class=\"data row10 col5\" >0.6378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6b407_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_6b407_row11_col0\" class=\"data row11 col0\" >0.0172</td>\n",
       "      <td id=\"T_6b407_row11_col1\" class=\"data row11 col1\" >0.0251</td>\n",
       "      <td id=\"T_6b407_row11_col2\" class=\"data row11 col2\" >0.0256</td>\n",
       "      <td id=\"T_6b407_row11_col3\" class=\"data row11 col3\" >0.0247</td>\n",
       "      <td id=\"T_6b407_row11_col4\" class=\"data row11 col4\" >0.0171</td>\n",
       "      <td id=\"T_6b407_row11_col5\" class=\"data row11 col5\" >0.1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cb2248940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_683f9_row10_col0, #T_683f9_row10_col1, #T_683f9_row10_col2, #T_683f9_row10_col3, #T_683f9_row10_col4, #T_683f9_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_683f9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_683f9_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_683f9_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_683f9_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_683f9_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_683f9_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_683f9_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_683f9_row0_col0\" class=\"data row0 col0\" >0.4672</td>\n",
       "      <td id=\"T_683f9_row0_col1\" class=\"data row0 col1\" >0.3503</td>\n",
       "      <td id=\"T_683f9_row0_col2\" class=\"data row0 col2\" >0.5918</td>\n",
       "      <td id=\"T_683f9_row0_col3\" class=\"data row0 col3\" >0.6618</td>\n",
       "      <td id=\"T_683f9_row0_col4\" class=\"data row0 col4\" >0.2911</td>\n",
       "      <td id=\"T_683f9_row0_col5\" class=\"data row0 col5\" >0.8568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_683f9_row1_col0\" class=\"data row1 col0\" >0.5141</td>\n",
       "      <td id=\"T_683f9_row1_col1\" class=\"data row1 col1\" >0.4234</td>\n",
       "      <td id=\"T_683f9_row1_col2\" class=\"data row1 col2\" >0.6507</td>\n",
       "      <td id=\"T_683f9_row1_col3\" class=\"data row1 col3\" >0.5807</td>\n",
       "      <td id=\"T_683f9_row1_col4\" class=\"data row1 col4\" >0.3184</td>\n",
       "      <td id=\"T_683f9_row1_col5\" class=\"data row1 col5\" >0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_683f9_row2_col0\" class=\"data row2 col0\" >0.5209</td>\n",
       "      <td id=\"T_683f9_row2_col1\" class=\"data row2 col1\" >0.4111</td>\n",
       "      <td id=\"T_683f9_row2_col2\" class=\"data row2 col2\" >0.6412</td>\n",
       "      <td id=\"T_683f9_row2_col3\" class=\"data row2 col3\" >0.6024</td>\n",
       "      <td id=\"T_683f9_row2_col4\" class=\"data row2 col4\" >0.3307</td>\n",
       "      <td id=\"T_683f9_row2_col5\" class=\"data row2 col5\" >1.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_683f9_row3_col0\" class=\"data row3 col0\" >0.5234</td>\n",
       "      <td id=\"T_683f9_row3_col1\" class=\"data row3 col1\" >0.4248</td>\n",
       "      <td id=\"T_683f9_row3_col2\" class=\"data row3 col2\" >0.6517</td>\n",
       "      <td id=\"T_683f9_row3_col3\" class=\"data row3 col3\" >0.5863</td>\n",
       "      <td id=\"T_683f9_row3_col4\" class=\"data row3 col4\" >0.3243</td>\n",
       "      <td id=\"T_683f9_row3_col5\" class=\"data row3 col5\" >1.2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_683f9_row4_col0\" class=\"data row4 col0\" >0.4435</td>\n",
       "      <td id=\"T_683f9_row4_col1\" class=\"data row4 col1\" >0.3184</td>\n",
       "      <td id=\"T_683f9_row4_col2\" class=\"data row4 col2\" >0.5643</td>\n",
       "      <td id=\"T_683f9_row4_col3\" class=\"data row4 col3\" >0.6674</td>\n",
       "      <td id=\"T_683f9_row4_col4\" class=\"data row4 col4\" >0.2880</td>\n",
       "      <td id=\"T_683f9_row4_col5\" class=\"data row4 col5\" >0.9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_683f9_row5_col0\" class=\"data row5 col0\" >0.4866</td>\n",
       "      <td id=\"T_683f9_row5_col1\" class=\"data row5 col1\" >0.3725</td>\n",
       "      <td id=\"T_683f9_row5_col2\" class=\"data row5 col2\" >0.6103</td>\n",
       "      <td id=\"T_683f9_row5_col3\" class=\"data row5 col3\" >0.6298</td>\n",
       "      <td id=\"T_683f9_row5_col4\" class=\"data row5 col4\" >0.3020</td>\n",
       "      <td id=\"T_683f9_row5_col5\" class=\"data row5 col5\" >0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_683f9_row6_col0\" class=\"data row6 col0\" >0.4973</td>\n",
       "      <td id=\"T_683f9_row6_col1\" class=\"data row6 col1\" >0.3797</td>\n",
       "      <td id=\"T_683f9_row6_col2\" class=\"data row6 col2\" >0.6162</td>\n",
       "      <td id=\"T_683f9_row6_col3\" class=\"data row6 col3\" >0.6417</td>\n",
       "      <td id=\"T_683f9_row6_col4\" class=\"data row6 col4\" >0.3068</td>\n",
       "      <td id=\"T_683f9_row6_col5\" class=\"data row6 col5\" >0.8579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_683f9_row7_col0\" class=\"data row7 col0\" >0.5134</td>\n",
       "      <td id=\"T_683f9_row7_col1\" class=\"data row7 col1\" >0.4062</td>\n",
       "      <td id=\"T_683f9_row7_col2\" class=\"data row7 col2\" >0.6374</td>\n",
       "      <td id=\"T_683f9_row7_col3\" class=\"data row7 col3\" >0.5967</td>\n",
       "      <td id=\"T_683f9_row7_col4\" class=\"data row7 col4\" >0.3152</td>\n",
       "      <td id=\"T_683f9_row7_col5\" class=\"data row7 col5\" >1.4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_683f9_row8_col0\" class=\"data row8 col0\" >0.4642</td>\n",
       "      <td id=\"T_683f9_row8_col1\" class=\"data row8 col1\" >0.3314</td>\n",
       "      <td id=\"T_683f9_row8_col2\" class=\"data row8 col2\" >0.5757</td>\n",
       "      <td id=\"T_683f9_row8_col3\" class=\"data row8 col3\" >0.6157</td>\n",
       "      <td id=\"T_683f9_row8_col4\" class=\"data row8 col4\" >0.2846</td>\n",
       "      <td id=\"T_683f9_row8_col5\" class=\"data row8 col5\" >1.7536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_683f9_row9_col0\" class=\"data row9 col0\" >0.5064</td>\n",
       "      <td id=\"T_683f9_row9_col1\" class=\"data row9 col1\" >0.4101</td>\n",
       "      <td id=\"T_683f9_row9_col2\" class=\"data row9 col2\" >0.6404</td>\n",
       "      <td id=\"T_683f9_row9_col3\" class=\"data row9 col3\" >0.5894</td>\n",
       "      <td id=\"T_683f9_row9_col4\" class=\"data row9 col4\" >0.2952</td>\n",
       "      <td id=\"T_683f9_row9_col5\" class=\"data row9 col5\" >1.5501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_683f9_row10_col0\" class=\"data row10 col0\" >0.4937</td>\n",
       "      <td id=\"T_683f9_row10_col1\" class=\"data row10 col1\" >0.3828</td>\n",
       "      <td id=\"T_683f9_row10_col2\" class=\"data row10 col2\" >0.6180</td>\n",
       "      <td id=\"T_683f9_row10_col3\" class=\"data row10 col3\" >0.6172</td>\n",
       "      <td id=\"T_683f9_row10_col4\" class=\"data row10 col4\" >0.3056</td>\n",
       "      <td id=\"T_683f9_row10_col5\" class=\"data row10 col5\" >1.1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_683f9_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_683f9_row11_col0\" class=\"data row11 col0\" >0.0260</td>\n",
       "      <td id=\"T_683f9_row11_col1\" class=\"data row11 col1\" >0.0367</td>\n",
       "      <td id=\"T_683f9_row11_col2\" class=\"data row11 col2\" >0.0301</td>\n",
       "      <td id=\"T_683f9_row11_col3\" class=\"data row11 col3\" >0.0299</td>\n",
       "      <td id=\"T_683f9_row11_col4\" class=\"data row11 col4\" >0.0152</td>\n",
       "      <td id=\"T_683f9_row11_col5\" class=\"data row11 col5\" >0.2968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca10ce4a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('target_transformation',\n",
       "                  TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(include=['AverageFare(SGD)',\n",
       "                                              'LeadTime(Days_to_DepartureDate)',\n",
       "                                              'SeatsSold', 'Total Revenue',\n",
       "                                              'TotalSeatsSold'],\n",
       "                                     transformer=SimpleImputer())),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWrapper(include=[],\n",
       "                                     transformer=SimpleImputer(strategy='most_frequent'))),\n",
       "                 ('normalize', TransformerWrapper(transformer=StandardScaler())),\n",
       "                 ('clean_column_names',\n",
       "                  TransformerWrapper(transformer=CleanColumnNames())),\n",
       "                 ('actual_estimator',\n",
       "                  RandomForestRegressor(n_jobs=-1, random_state=123))]),\n",
       " 'final_model_total_fare.pkl')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for WeightedAverageFare(SGD)\n",
    "best_model_total_fare = compare_models(include=['gbr', 'lightgbm', 'rf', 'et', 'ada', 'knn', 'lasso'])\n",
    "final_model_total_fare = finalize_model(tune_model(create_model(best_model_total_fare)))\n",
    "save_model(final_model_total_fare, 'final_model_total_fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d1bf3_row8_col1, #T_d1bf3_row12_col1, #T_d1bf3_row14_col1, #T_d1bf3_row19_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d1bf3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d1bf3_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_d1bf3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d1bf3_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_d1bf3_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d1bf3_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_d1bf3_row1_col1\" class=\"data row1 col1\" >TotalSeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d1bf3_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_d1bf3_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d1bf3_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_d1bf3_row3_col1\" class=\"data row3 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d1bf3_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_d1bf3_row4_col1\" class=\"data row4 col1\" >(2560, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d1bf3_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_d1bf3_row5_col1\" class=\"data row5 col1\" >(1792, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d1bf3_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_d1bf3_row6_col1\" class=\"data row6 col1\" >(768, 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d1bf3_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_d1bf3_row7_col1\" class=\"data row7 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d1bf3_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_d1bf3_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d1bf3_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_d1bf3_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_d1bf3_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_d1bf3_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_d1bf3_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_d1bf3_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_d1bf3_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_d1bf3_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_d1bf3_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_d1bf3_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_d1bf3_row14_col0\" class=\"data row14 col0\" >Transform target</td>\n",
       "      <td id=\"T_d1bf3_row14_col1\" class=\"data row14 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_d1bf3_row15_col0\" class=\"data row15 col0\" >Transform target method</td>\n",
       "      <td id=\"T_d1bf3_row15_col1\" class=\"data row15 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_d1bf3_row16_col0\" class=\"data row16 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_d1bf3_row16_col1\" class=\"data row16 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_d1bf3_row17_col0\" class=\"data row17 col0\" >Fold Number</td>\n",
       "      <td id=\"T_d1bf3_row17_col1\" class=\"data row17 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_d1bf3_row18_col0\" class=\"data row18 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_d1bf3_row18_col1\" class=\"data row18 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_d1bf3_row19_col0\" class=\"data row19 col0\" >Use GPU</td>\n",
       "      <td id=\"T_d1bf3_row19_col1\" class=\"data row19 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_d1bf3_row20_col0\" class=\"data row20 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_d1bf3_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_d1bf3_row21_col0\" class=\"data row21 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_d1bf3_row21_col1\" class=\"data row21 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1bf3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_d1bf3_row22_col0\" class=\"data row22 col0\" >USI</td>\n",
       "      <td id=\"T_d1bf3_row22_col1\" class=\"data row22 col1\" >d4b5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca1a989d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 2080, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] Start training from score 0.500000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# Setup PyCaret for TotalSeatsSold\n",
    "s_seats = setup(\n",
    "    data=df_encoded,\n",
    "    target='TotalSeatsSold',\n",
    "    use_gpu=True,\n",
    "    session_id=123,\n",
    "    normalize=True,  # Normalize the data\n",
    "    transform_target=True  # Apply log transformation to the target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f0afa th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f0afa_row0_col0, #T_f0afa_row0_col6, #T_f0afa_row1_col0, #T_f0afa_row1_col1, #T_f0afa_row1_col2, #T_f0afa_row1_col3, #T_f0afa_row1_col4, #T_f0afa_row1_col5, #T_f0afa_row2_col0, #T_f0afa_row2_col1, #T_f0afa_row2_col2, #T_f0afa_row2_col3, #T_f0afa_row2_col4, #T_f0afa_row2_col5, #T_f0afa_row2_col6, #T_f0afa_row3_col0, #T_f0afa_row3_col1, #T_f0afa_row3_col2, #T_f0afa_row3_col3, #T_f0afa_row3_col4, #T_f0afa_row3_col5, #T_f0afa_row3_col6, #T_f0afa_row4_col0, #T_f0afa_row4_col1, #T_f0afa_row4_col2, #T_f0afa_row4_col3, #T_f0afa_row4_col4, #T_f0afa_row4_col5, #T_f0afa_row4_col6, #T_f0afa_row5_col0, #T_f0afa_row5_col1, #T_f0afa_row5_col2, #T_f0afa_row5_col3, #T_f0afa_row5_col4, #T_f0afa_row5_col5, #T_f0afa_row5_col6, #T_f0afa_row6_col0, #T_f0afa_row6_col1, #T_f0afa_row6_col2, #T_f0afa_row6_col3, #T_f0afa_row6_col4, #T_f0afa_row6_col5, #T_f0afa_row6_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f0afa_row0_col1, #T_f0afa_row0_col2, #T_f0afa_row0_col3, #T_f0afa_row0_col4, #T_f0afa_row0_col5, #T_f0afa_row1_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f0afa_row0_col7, #T_f0afa_row1_col7, #T_f0afa_row2_col7, #T_f0afa_row3_col7, #T_f0afa_row4_col7, #T_f0afa_row5_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_f0afa_row6_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f0afa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f0afa_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f0afa_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_f0afa_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_f0afa_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_f0afa_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_f0afa_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_f0afa_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_f0afa_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_f0afa_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_f0afa_row0_col1\" class=\"data row0 col1\" >0.0132</td>\n",
       "      <td id=\"T_f0afa_row0_col2\" class=\"data row0 col2\" >0.0023</td>\n",
       "      <td id=\"T_f0afa_row0_col3\" class=\"data row0 col3\" >0.0447</td>\n",
       "      <td id=\"T_f0afa_row0_col4\" class=\"data row0 col4\" >0.9977</td>\n",
       "      <td id=\"T_f0afa_row0_col5\" class=\"data row0 col5\" >0.0215</td>\n",
       "      <td id=\"T_f0afa_row0_col6\" class=\"data row0 col6\" >0.4139</td>\n",
       "      <td id=\"T_f0afa_row0_col7\" class=\"data row0 col7\" >0.2890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_f0afa_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_f0afa_row1_col1\" class=\"data row1 col1\" >0.0445</td>\n",
       "      <td id=\"T_f0afa_row1_col2\" class=\"data row1 col2\" >0.0178</td>\n",
       "      <td id=\"T_f0afa_row1_col3\" class=\"data row1 col3\" >0.1199</td>\n",
       "      <td id=\"T_f0afa_row1_col4\" class=\"data row1 col4\" >0.9825</td>\n",
       "      <td id=\"T_f0afa_row1_col5\" class=\"data row1 col5\" >0.0513</td>\n",
       "      <td id=\"T_f0afa_row1_col6\" class=\"data row1 col6\" >0.3929</td>\n",
       "      <td id=\"T_f0afa_row1_col7\" class=\"data row1 col7\" >1.1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row2\" class=\"row_heading level0 row2\" >gbr</th>\n",
       "      <td id=\"T_f0afa_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_f0afa_row2_col1\" class=\"data row2 col1\" >0.2170</td>\n",
       "      <td id=\"T_f0afa_row2_col2\" class=\"data row2 col2\" >0.1823</td>\n",
       "      <td id=\"T_f0afa_row2_col3\" class=\"data row2 col3\" >0.4252</td>\n",
       "      <td id=\"T_f0afa_row2_col4\" class=\"data row2 col4\" >0.8213</td>\n",
       "      <td id=\"T_f0afa_row2_col5\" class=\"data row2 col5\" >0.1784</td>\n",
       "      <td id=\"T_f0afa_row2_col6\" class=\"data row2 col6\" >1.9047</td>\n",
       "      <td id=\"T_f0afa_row2_col7\" class=\"data row2 col7\" >0.4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_f0afa_row3_col0\" class=\"data row3 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_f0afa_row3_col1\" class=\"data row3 col1\" >0.2280</td>\n",
       "      <td id=\"T_f0afa_row3_col2\" class=\"data row3 col2\" >0.3049</td>\n",
       "      <td id=\"T_f0afa_row3_col3\" class=\"data row3 col3\" >0.5418</td>\n",
       "      <td id=\"T_f0afa_row3_col4\" class=\"data row3 col4\" >0.7078</td>\n",
       "      <td id=\"T_f0afa_row3_col5\" class=\"data row3 col5\" >0.2237</td>\n",
       "      <td id=\"T_f0afa_row3_col6\" class=\"data row3 col6\" >1.8995</td>\n",
       "      <td id=\"T_f0afa_row3_col7\" class=\"data row3 col7\" >0.3380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_f0afa_row4_col0\" class=\"data row4 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_f0afa_row4_col1\" class=\"data row4 col1\" >0.5162</td>\n",
       "      <td id=\"T_f0afa_row4_col2\" class=\"data row4 col2\" >0.7759</td>\n",
       "      <td id=\"T_f0afa_row4_col3\" class=\"data row4 col3\" >0.8778</td>\n",
       "      <td id=\"T_f0afa_row4_col4\" class=\"data row4 col4\" >0.2381</td>\n",
       "      <td id=\"T_f0afa_row4_col5\" class=\"data row4 col5\" >0.4053</td>\n",
       "      <td id=\"T_f0afa_row4_col6\" class=\"data row4 col6\" >10.4448</td>\n",
       "      <td id=\"T_f0afa_row4_col7\" class=\"data row4 col7\" >0.1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row5\" class=\"row_heading level0 row5\" >knn</th>\n",
       "      <td id=\"T_f0afa_row5_col0\" class=\"data row5 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_f0afa_row5_col1\" class=\"data row5 col1\" >0.6966</td>\n",
       "      <td id=\"T_f0afa_row5_col2\" class=\"data row5 col2\" >1.1099</td>\n",
       "      <td id=\"T_f0afa_row5_col3\" class=\"data row5 col3\" >1.0517</td>\n",
       "      <td id=\"T_f0afa_row5_col4\" class=\"data row5 col4\" >-0.0950</td>\n",
       "      <td id=\"T_f0afa_row5_col5\" class=\"data row5 col5\" >0.4051</td>\n",
       "      <td id=\"T_f0afa_row5_col6\" class=\"data row5 col6\" >7.9292</td>\n",
       "      <td id=\"T_f0afa_row5_col7\" class=\"data row5 col7\" >0.1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f0afa_level0_row6\" class=\"row_heading level0 row6\" >lasso</th>\n",
       "      <td id=\"T_f0afa_row6_col0\" class=\"data row6 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_f0afa_row6_col1\" class=\"data row6 col1\" >0.6939</td>\n",
       "      <td id=\"T_f0afa_row6_col2\" class=\"data row6 col2\" >1.1388</td>\n",
       "      <td id=\"T_f0afa_row6_col3\" class=\"data row6 col3\" >1.0642</td>\n",
       "      <td id=\"T_f0afa_row6_col4\" class=\"data row6 col4\" >-0.1185</td>\n",
       "      <td id=\"T_f0afa_row6_col5\" class=\"data row6 col5\" >0.3740</td>\n",
       "      <td id=\"T_f0afa_row6_col6\" class=\"data row6 col6\" >7.6053</td>\n",
       "      <td id=\"T_f0afa_row6_col7\" class=\"data row6 col7\" >0.0590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc72ac520>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5bdc2_row10_col0, #T_5bdc2_row10_col1, #T_5bdc2_row10_col2, #T_5bdc2_row10_col3, #T_5bdc2_row10_col4, #T_5bdc2_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5bdc2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5bdc2_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_5bdc2_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_5bdc2_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_5bdc2_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_5bdc2_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_5bdc2_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5bdc2_row0_col0\" class=\"data row0 col0\" >0.0235</td>\n",
       "      <td id=\"T_5bdc2_row0_col1\" class=\"data row0 col1\" >0.0048</td>\n",
       "      <td id=\"T_5bdc2_row0_col2\" class=\"data row0 col2\" >0.0690</td>\n",
       "      <td id=\"T_5bdc2_row0_col3\" class=\"data row0 col3\" >0.9950</td>\n",
       "      <td id=\"T_5bdc2_row0_col4\" class=\"data row0 col4\" >0.0343</td>\n",
       "      <td id=\"T_5bdc2_row0_col5\" class=\"data row0 col5\" >0.4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5bdc2_row1_col0\" class=\"data row1 col0\" >0.0114</td>\n",
       "      <td id=\"T_5bdc2_row1_col1\" class=\"data row1 col1\" >0.0020</td>\n",
       "      <td id=\"T_5bdc2_row1_col2\" class=\"data row1 col2\" >0.0447</td>\n",
       "      <td id=\"T_5bdc2_row1_col3\" class=\"data row1 col3\" >0.9982</td>\n",
       "      <td id=\"T_5bdc2_row1_col4\" class=\"data row1 col4\" >0.0211</td>\n",
       "      <td id=\"T_5bdc2_row1_col5\" class=\"data row1 col5\" >0.1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5bdc2_row2_col0\" class=\"data row2 col0\" >0.0099</td>\n",
       "      <td id=\"T_5bdc2_row2_col1\" class=\"data row2 col1\" >0.0013</td>\n",
       "      <td id=\"T_5bdc2_row2_col2\" class=\"data row2 col2\" >0.0361</td>\n",
       "      <td id=\"T_5bdc2_row2_col3\" class=\"data row2 col3\" >0.9987</td>\n",
       "      <td id=\"T_5bdc2_row2_col4\" class=\"data row2 col4\" >0.0171</td>\n",
       "      <td id=\"T_5bdc2_row2_col5\" class=\"data row2 col5\" >0.0896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5bdc2_row3_col0\" class=\"data row3 col0\" >0.0107</td>\n",
       "      <td id=\"T_5bdc2_row3_col1\" class=\"data row3 col1\" >0.0015</td>\n",
       "      <td id=\"T_5bdc2_row3_col2\" class=\"data row3 col2\" >0.0386</td>\n",
       "      <td id=\"T_5bdc2_row3_col3\" class=\"data row3 col3\" >0.9983</td>\n",
       "      <td id=\"T_5bdc2_row3_col4\" class=\"data row3 col4\" >0.0203</td>\n",
       "      <td id=\"T_5bdc2_row3_col5\" class=\"data row3 col5\" >0.5999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5bdc2_row4_col0\" class=\"data row4 col0\" >0.0114</td>\n",
       "      <td id=\"T_5bdc2_row4_col1\" class=\"data row4 col1\" >0.0016</td>\n",
       "      <td id=\"T_5bdc2_row4_col2\" class=\"data row4 col2\" >0.0395</td>\n",
       "      <td id=\"T_5bdc2_row4_col3\" class=\"data row4 col3\" >0.9985</td>\n",
       "      <td id=\"T_5bdc2_row4_col4\" class=\"data row4 col4\" >0.0167</td>\n",
       "      <td id=\"T_5bdc2_row4_col5\" class=\"data row4 col5\" >0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5bdc2_row5_col0\" class=\"data row5 col0\" >0.0041</td>\n",
       "      <td id=\"T_5bdc2_row5_col1\" class=\"data row5 col1\" >0.0003</td>\n",
       "      <td id=\"T_5bdc2_row5_col2\" class=\"data row5 col2\" >0.0171</td>\n",
       "      <td id=\"T_5bdc2_row5_col3\" class=\"data row5 col3\" >0.9997</td>\n",
       "      <td id=\"T_5bdc2_row5_col4\" class=\"data row5 col4\" >0.0081</td>\n",
       "      <td id=\"T_5bdc2_row5_col5\" class=\"data row5 col5\" >0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5bdc2_row6_col0\" class=\"data row6 col0\" >0.0128</td>\n",
       "      <td id=\"T_5bdc2_row6_col1\" class=\"data row6 col1\" >0.0016</td>\n",
       "      <td id=\"T_5bdc2_row6_col2\" class=\"data row6 col2\" >0.0397</td>\n",
       "      <td id=\"T_5bdc2_row6_col3\" class=\"data row6 col3\" >0.9986</td>\n",
       "      <td id=\"T_5bdc2_row6_col4\" class=\"data row6 col4\" >0.0213</td>\n",
       "      <td id=\"T_5bdc2_row6_col5\" class=\"data row6 col5\" >1.0863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5bdc2_row7_col0\" class=\"data row7 col0\" >0.0155</td>\n",
       "      <td id=\"T_5bdc2_row7_col1\" class=\"data row7 col1\" >0.0022</td>\n",
       "      <td id=\"T_5bdc2_row7_col2\" class=\"data row7 col2\" >0.0465</td>\n",
       "      <td id=\"T_5bdc2_row7_col3\" class=\"data row7 col3\" >0.9984</td>\n",
       "      <td id=\"T_5bdc2_row7_col4\" class=\"data row7 col4\" >0.0221</td>\n",
       "      <td id=\"T_5bdc2_row7_col5\" class=\"data row7 col5\" >0.9147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5bdc2_row8_col0\" class=\"data row8 col0\" >0.0212</td>\n",
       "      <td id=\"T_5bdc2_row8_col1\" class=\"data row8 col1\" >0.0061</td>\n",
       "      <td id=\"T_5bdc2_row8_col2\" class=\"data row8 col2\" >0.0784</td>\n",
       "      <td id=\"T_5bdc2_row8_col3\" class=\"data row8 col3\" >0.9935</td>\n",
       "      <td id=\"T_5bdc2_row8_col4\" class=\"data row8 col4\" >0.0353</td>\n",
       "      <td id=\"T_5bdc2_row8_col5\" class=\"data row8 col5\" >0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5bdc2_row9_col0\" class=\"data row9 col0\" >0.0118</td>\n",
       "      <td id=\"T_5bdc2_row9_col1\" class=\"data row9 col1\" >0.0014</td>\n",
       "      <td id=\"T_5bdc2_row9_col2\" class=\"data row9 col2\" >0.0371</td>\n",
       "      <td id=\"T_5bdc2_row9_col3\" class=\"data row9 col3\" >0.9983</td>\n",
       "      <td id=\"T_5bdc2_row9_col4\" class=\"data row9 col4\" >0.0183</td>\n",
       "      <td id=\"T_5bdc2_row9_col5\" class=\"data row9 col5\" >0.7158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_5bdc2_row10_col0\" class=\"data row10 col0\" >0.0132</td>\n",
       "      <td id=\"T_5bdc2_row10_col1\" class=\"data row10 col1\" >0.0023</td>\n",
       "      <td id=\"T_5bdc2_row10_col2\" class=\"data row10 col2\" >0.0447</td>\n",
       "      <td id=\"T_5bdc2_row10_col3\" class=\"data row10 col3\" >0.9977</td>\n",
       "      <td id=\"T_5bdc2_row10_col4\" class=\"data row10 col4\" >0.0215</td>\n",
       "      <td id=\"T_5bdc2_row10_col5\" class=\"data row10 col5\" >0.4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5bdc2_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_5bdc2_row11_col0\" class=\"data row11 col0\" >0.0053</td>\n",
       "      <td id=\"T_5bdc2_row11_col1\" class=\"data row11 col1\" >0.0017</td>\n",
       "      <td id=\"T_5bdc2_row11_col2\" class=\"data row11 col2\" >0.0165</td>\n",
       "      <td id=\"T_5bdc2_row11_col3\" class=\"data row11 col3\" >0.0018</td>\n",
       "      <td id=\"T_5bdc2_row11_col4\" class=\"data row11 col4\" >0.0077</td>\n",
       "      <td id=\"T_5bdc2_row11_col5\" class=\"data row11 col5\" >0.3786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc1275900>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_29f5a_row10_col0, #T_29f5a_row10_col1, #T_29f5a_row10_col2, #T_29f5a_row10_col3, #T_29f5a_row10_col4, #T_29f5a_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_29f5a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_29f5a_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_29f5a_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_29f5a_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_29f5a_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_29f5a_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_29f5a_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_29f5a_row0_col0\" class=\"data row0 col0\" >0.6134</td>\n",
       "      <td id=\"T_29f5a_row0_col1\" class=\"data row0 col1\" >0.9122</td>\n",
       "      <td id=\"T_29f5a_row0_col2\" class=\"data row0 col2\" >0.9551</td>\n",
       "      <td id=\"T_29f5a_row0_col3\" class=\"data row0 col3\" >0.0421</td>\n",
       "      <td id=\"T_29f5a_row0_col4\" class=\"data row0 col4\" >0.4652</td>\n",
       "      <td id=\"T_29f5a_row0_col5\" class=\"data row0 col5\" >4.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_29f5a_row1_col0\" class=\"data row1 col0\" >0.5957</td>\n",
       "      <td id=\"T_29f5a_row1_col1\" class=\"data row1 col1\" >1.0032</td>\n",
       "      <td id=\"T_29f5a_row1_col2\" class=\"data row1 col2\" >1.0016</td>\n",
       "      <td id=\"T_29f5a_row1_col3\" class=\"data row1 col3\" >0.1002</td>\n",
       "      <td id=\"T_29f5a_row1_col4\" class=\"data row1 col4\" >0.4708</td>\n",
       "      <td id=\"T_29f5a_row1_col5\" class=\"data row1 col5\" >2.6148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_29f5a_row2_col0\" class=\"data row2 col0\" >0.5746</td>\n",
       "      <td id=\"T_29f5a_row2_col1\" class=\"data row2 col1\" >0.8976</td>\n",
       "      <td id=\"T_29f5a_row2_col2\" class=\"data row2 col2\" >0.9474</td>\n",
       "      <td id=\"T_29f5a_row2_col3\" class=\"data row2 col3\" >0.0992</td>\n",
       "      <td id=\"T_29f5a_row2_col4\" class=\"data row2 col4\" >0.4596</td>\n",
       "      <td id=\"T_29f5a_row2_col5\" class=\"data row2 col5\" >1.5909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_29f5a_row3_col0\" class=\"data row3 col0\" >0.5571</td>\n",
       "      <td id=\"T_29f5a_row3_col1\" class=\"data row3 col1\" >0.7768</td>\n",
       "      <td id=\"T_29f5a_row3_col2\" class=\"data row3 col2\" >0.8813</td>\n",
       "      <td id=\"T_29f5a_row3_col3\" class=\"data row3 col3\" >0.1165</td>\n",
       "      <td id=\"T_29f5a_row3_col4\" class=\"data row3 col4\" >0.4414</td>\n",
       "      <td id=\"T_29f5a_row3_col5\" class=\"data row3 col5\" >3.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_29f5a_row4_col0\" class=\"data row4 col0\" >0.6097</td>\n",
       "      <td id=\"T_29f5a_row4_col1\" class=\"data row4 col1\" >0.9750</td>\n",
       "      <td id=\"T_29f5a_row4_col2\" class=\"data row4 col2\" >0.9874</td>\n",
       "      <td id=\"T_29f5a_row4_col3\" class=\"data row4 col3\" >0.0868</td>\n",
       "      <td id=\"T_29f5a_row4_col4\" class=\"data row4 col4\" >0.4855</td>\n",
       "      <td id=\"T_29f5a_row4_col5\" class=\"data row4 col5\" >1.2421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_29f5a_row5_col0\" class=\"data row5 col0\" >0.6044</td>\n",
       "      <td id=\"T_29f5a_row5_col1\" class=\"data row5 col1\" >0.8597</td>\n",
       "      <td id=\"T_29f5a_row5_col2\" class=\"data row5 col2\" >0.9272</td>\n",
       "      <td id=\"T_29f5a_row5_col3\" class=\"data row5 col3\" >0.0960</td>\n",
       "      <td id=\"T_29f5a_row5_col4\" class=\"data row5 col4\" >0.4558</td>\n",
       "      <td id=\"T_29f5a_row5_col5\" class=\"data row5 col5\" >1.6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_29f5a_row6_col0\" class=\"data row6 col0\" >0.6219</td>\n",
       "      <td id=\"T_29f5a_row6_col1\" class=\"data row6 col1\" >1.0419</td>\n",
       "      <td id=\"T_29f5a_row6_col2\" class=\"data row6 col2\" >1.0207</td>\n",
       "      <td id=\"T_29f5a_row6_col3\" class=\"data row6 col3\" >0.0461</td>\n",
       "      <td id=\"T_29f5a_row6_col4\" class=\"data row6 col4\" >0.4770</td>\n",
       "      <td id=\"T_29f5a_row6_col5\" class=\"data row6 col5\" >3.9461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_29f5a_row7_col0\" class=\"data row7 col0\" >0.6751</td>\n",
       "      <td id=\"T_29f5a_row7_col1\" class=\"data row7 col1\" >1.2915</td>\n",
       "      <td id=\"T_29f5a_row7_col2\" class=\"data row7 col2\" >1.1364</td>\n",
       "      <td id=\"T_29f5a_row7_col3\" class=\"data row7 col3\" >0.0554</td>\n",
       "      <td id=\"T_29f5a_row7_col4\" class=\"data row7 col4\" >0.5200</td>\n",
       "      <td id=\"T_29f5a_row7_col5\" class=\"data row7 col5\" >2.7763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_29f5a_row8_col0\" class=\"data row8 col0\" >0.5853</td>\n",
       "      <td id=\"T_29f5a_row8_col1\" class=\"data row8 col1\" >0.8530</td>\n",
       "      <td id=\"T_29f5a_row8_col2\" class=\"data row8 col2\" >0.9236</td>\n",
       "      <td id=\"T_29f5a_row8_col3\" class=\"data row8 col3\" >0.1006</td>\n",
       "      <td id=\"T_29f5a_row8_col4\" class=\"data row8 col4\" >0.4624</td>\n",
       "      <td id=\"T_29f5a_row8_col5\" class=\"data row8 col5\" >3.0614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_29f5a_row9_col0\" class=\"data row9 col0\" >0.5102</td>\n",
       "      <td id=\"T_29f5a_row9_col1\" class=\"data row9 col1\" >0.6914</td>\n",
       "      <td id=\"T_29f5a_row9_col2\" class=\"data row9 col2\" >0.8315</td>\n",
       "      <td id=\"T_29f5a_row9_col3\" class=\"data row9 col3\" >0.1392</td>\n",
       "      <td id=\"T_29f5a_row9_col4\" class=\"data row9 col4\" >0.4266</td>\n",
       "      <td id=\"T_29f5a_row9_col5\" class=\"data row9 col5\" >4.5498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_29f5a_row10_col0\" class=\"data row10 col0\" >0.5947</td>\n",
       "      <td id=\"T_29f5a_row10_col1\" class=\"data row10 col1\" >0.9302</td>\n",
       "      <td id=\"T_29f5a_row10_col2\" class=\"data row10 col2\" >0.9612</td>\n",
       "      <td id=\"T_29f5a_row10_col3\" class=\"data row10 col3\" >0.0882</td>\n",
       "      <td id=\"T_29f5a_row10_col4\" class=\"data row10 col4\" >0.4664</td>\n",
       "      <td id=\"T_29f5a_row10_col5\" class=\"data row10 col5\" >2.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_29f5a_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_29f5a_row11_col0\" class=\"data row11 col0\" >0.0411</td>\n",
       "      <td id=\"T_29f5a_row11_col1\" class=\"data row11 col1\" >0.1560</td>\n",
       "      <td id=\"T_29f5a_row11_col2\" class=\"data row11 col2\" >0.0791</td>\n",
       "      <td id=\"T_29f5a_row11_col3\" class=\"data row11 col3\" >0.0298</td>\n",
       "      <td id=\"T_29f5a_row11_col4\" class=\"data row11 col4\" >0.0240</td>\n",
       "      <td id=\"T_29f5a_row11_col5\" class=\"data row11 col5\" >1.0758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23c9e796380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('target_transformation',\n",
       "                  TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),\n",
       "                 ('numerical_imputer',\n",
       "                  TransformerWrapper(include=['AverageFare(SGD)',\n",
       "                                              'LeadTime(Days_to_DepartureDate)',\n",
       "                                              'SeatsSold', 'Total Revenue',\n",
       "                                              'WeightedAverageFare(SGD)'],\n",
       "                                     transformer=SimpleImputer())),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWrapper(include=[],\n",
       "                                     transformer=SimpleImputer(strategy='most_frequent'))),\n",
       "                 ('normalize', TransformerWrapper(transformer=StandardScaler())),\n",
       "                 ('clean_column_names',\n",
       "                  TransformerWrapper(transformer=CleanColumnNames())),\n",
       "                 ('actual_estimator',\n",
       "                  RandomForestRegressor(n_jobs=-1, random_state=123))]),\n",
       " 'final_model_total_seats.pkl')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model for TotalSeatsSold\n",
    "best_model_total_seats = compare_models(include=['gbr', 'lightgbm', 'rf', 'et', 'ada', 'knn', 'lasso'])\n",
    "final_model_total_seats = finalize_model(tune_model(create_model(best_model_total_seats)))\n",
    "save_model(final_model_total_seats, 'final_model_total_seats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_input(start_date, end_date, flight_number, training_columns):\n",
    "    # Create a date range for the departure dates\n",
    "    date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    # Initialize an empty DataFrame with the necessary columns\n",
    "    columns = [\n",
    "        'AverageFare(SGD)', 'SeatsSold', 'Total Revenue',\n",
    "        'LeadTime(Days_to_DepartureDate)', 'BookingYear', 'BookingMonth', 'BookingDay',\n",
    "        'BookingDayOfWeek', 'IsBookingDateHoliday', 'IsBookingDateWeekend',\n",
    "        'DepartureYear', 'DepartureMonth', 'DepartureDay',\n",
    "        'DepartureDayOfWeek', 'IsDepartureDateHoliday', 'IsDepartureDateWeekend', 'FlightNumber',\n",
    "        'WeightedAverageFare(SGD)', 'TotalSeatsSold'\n",
    "    ]\n",
    "\n",
    "    input_data = pd.DataFrame(index=date_range, columns=columns)\n",
    "\n",
    "    # Fill in the necessary columns based on the departure dates\n",
    "    input_data['DepartureYear'] = input_data.index.year\n",
    "    input_data['DepartureMonth'] = input_data.index.month\n",
    "    input_data['DepartureDay'] = input_data.index.day\n",
    "    input_data['DepartureDayOfWeek'] = input_data.index.dayofweek\n",
    "    input_data['IsDepartureDateWeekend'] = input_data['DepartureDayOfWeek'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Define holidays in Malaysia and Singapore for the year 2019\n",
    "    malaysia_holidays_2019 = [\n",
    "        '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-05', '2019-06-06', '2019-06-21',\n",
    "    ]\n",
    "    singapore_holidays_2019 = [\n",
    "        '2019-01-01', '2019-02-05', '2019-02-06', '2019-04-19', '2019-05-01', '2019-05-19',\n",
    "        '2019-05-20', '2019-06-05', '2019-08-09', '2019-08-11', '2019-08-12', '2019-10-27',\n",
    "        '2019-10-28', '2019-12-25'\n",
    "    ]\n",
    "\n",
    "    # Combine holidays into a single list\n",
    "    holidays_2019 = pd.to_datetime(malaysia_holidays_2019 + singapore_holidays_2019)\n",
    "\n",
    "    # Determine if the departure date is a holiday\n",
    "    input_data['IsDepartureDateHoliday'] = input_data.index.isin(holidays_2019).astype(int)\n",
    "\n",
    "    # Set FlightNumber\n",
    "    flight_number_mapping = {\"TR 202\": 1, \"TR 203\": 2}\n",
    "    input_data['FlightNumber'] = flight_number_mapping.get(flight_number, 0)\n",
    "\n",
    "    # Set Booking related fields to 0 (since only Departure date is used)\n",
    "    input_data[['BookingYear', 'BookingMonth', 'BookingDay', 'BookingDayOfWeek',\n",
    "                'IsBookingDateHoliday', 'IsBookingDateWeekend']] = 0\n",
    "\n",
    "    # Calculate LeadTime as 0 since Booking date is not available\n",
    "    input_data['LeadTime(Days_to_DepartureDate)'] = 0\n",
    "\n",
    "    # Set targets (AverageFare, SeatsSold, Total Revenue, WeightedAverageFare, TotalSeatsSold) as 0\n",
    "    input_data[['AverageFare(SGD)', 'SeatsSold', 'Total Revenue', 'WeightedAverageFare(SGD)', 'TotalSeatsSold']] = 0\n",
    "\n",
    "    # One-Hot Encode the specified columns\n",
    "    input_data_encoded = pd.get_dummies(input_data, columns=[\n",
    "        'BookingDay', 'BookingDayOfWeek', 'BookingMonth', 'BookingYear',\n",
    "        'DepartureDay', 'DepartureDayOfWeek', 'DepartureMonth', 'DepartureYear',\n",
    "        'FlightNumber', 'IsBookingDateHoliday', 'IsBookingDateWeekend',\n",
    "        'IsDepartureDateHoliday', 'IsDepartureDateWeekend'\n",
    "    ])\n",
    "\n",
    "    # Align with training data columns\n",
    "    for col in training_columns:\n",
    "        if col not in input_data_encoded.columns:\n",
    "            input_data_encoded[col] = 0\n",
    "\n",
    "    # Standard Scaling\n",
    "    scaler = StandardScaler()\n",
    "    columns_to_scale = ['AverageFare(SGD)', 'LeadTime(Days_to_DepartureDate)', 'SeatsSold', 'Total Revenue', 'WeightedAverageFare(SGD)', 'TotalSeatsSold']\n",
    "    input_data_encoded[columns_to_scale] = scaler.fit_transform(input_data_encoded[columns_to_scale])\n",
    "\n",
    "    # Ensure the order of columns matches the training data\n",
    "    input_data_encoded = input_data_encoded[training_columns]\n",
    "\n",
    "    return input_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained models\n",
    "final_model_fare = load_model('final_model_fare')\n",
    "final_model_seats = load_model('final_model_seats')\n",
    "final_model_total_fare = load_model('final_model_total_fare')\n",
    "final_model_total_seats = load_model('final_model_total_seats')\n",
    "\n",
    "# Prepare the input data\n",
    "start_date = \"2019-08-01\"\n",
    "end_date = \"2019-08-30\"\n",
    "\n",
    "training_columns = [\n",
    "    'AverageFare(SGD)', \n",
    "    'LeadTime(Days_to_DepartureDate)', \n",
    "    'SeatsSold', \n",
    "    'Total Revenue', \n",
    "    'WeightedAverageFare(SGD)',  # Added column\n",
    "    'TotalSeatsSold',  # Added column\n",
    "    'BookingDay_1', 'BookingDay_2', 'BookingDay_3', 'BookingDay_4',\n",
    "    'BookingDay_5', 'BookingDay_6', 'BookingDay_7', 'BookingDay_8', 'BookingDay_9',\n",
    "    'BookingDay_10', 'BookingDay_11', 'BookingDay_12', 'BookingDay_13', 'BookingDay_14',\n",
    "    'BookingDay_15', 'BookingDay_16', 'BookingDay_17', 'BookingDay_18', 'BookingDay_19',\n",
    "    'BookingDay_20', 'BookingDay_21', 'BookingDay_22', 'BookingDay_23', 'BookingDay_24',\n",
    "    'BookingDay_25', 'BookingDay_26', 'BookingDay_27', 'BookingDay_28', 'BookingDay_29',\n",
    "    'BookingDay_30', 'BookingDay_31', \n",
    "    'BookingDayOfWeek_0', 'BookingDayOfWeek_1', \n",
    "    'BookingDayOfWeek_2', 'BookingDayOfWeek_3', 'BookingDayOfWeek_4',\n",
    "    'BookingDayOfWeek_5', 'BookingDayOfWeek_6', \n",
    "    'BookingMonth_1', 'BookingMonth_2', 'BookingMonth_3', 'BookingMonth_4', \n",
    "    'BookingMonth_5', 'BookingMonth_6', 'BookingMonth_8', 'BookingMonth_9', \n",
    "    'BookingMonth_10', 'BookingMonth_11', 'BookingMonth_12', \n",
    "    'BookingYear_2018', 'BookingYear_2019', \n",
    "    'DepartureDay_1', 'DepartureDay_2', 'DepartureDay_3', 'DepartureDay_4', \n",
    "    'DepartureDay_5', 'DepartureDay_6', 'DepartureDay_7', 'DepartureDay_8', \n",
    "    'DepartureDay_9', 'DepartureDay_10', 'DepartureDay_11', 'DepartureDay_12', \n",
    "    'DepartureDay_13', 'DepartureDay_14', 'DepartureDay_15', 'DepartureDay_16', \n",
    "    'DepartureDay_17', 'DepartureDay_18', 'DepartureDay_19', 'DepartureDay_20', \n",
    "    'DepartureDay_21', 'DepartureDay_22', 'DepartureDay_23', 'DepartureDay_24', \n",
    "    'DepartureDay_25', 'DepartureDay_26', 'DepartureDay_27', 'DepartureDay_28', \n",
    "    'DepartureDay_29', 'DepartureDay_30', \n",
    "    'DepartureDayOfWeek_0', 'DepartureDayOfWeek_1', \n",
    "    'DepartureDayOfWeek_2', 'DepartureDayOfWeek_3', 'DepartureDayOfWeek_4', \n",
    "    'DepartureDayOfWeek_5', 'DepartureDayOfWeek_6', \n",
    "    'DepartureMonth_6', \n",
    "    'DepartureYear_2019', \n",
    "    'FlightNumber_1', 'FlightNumber_2', \n",
    "    'IsBookingDateHoliday_1', 'IsBookingDateHoliday_2', \n",
    "    'IsBookingDateWeekend_1', 'IsBookingDateWeekend_2', \n",
    "    'IsDepartureDateHoliday_1', 'IsDepartureDateHoliday_2', \n",
    "    'IsDepartureDateWeekend_1', 'IsDepartureDateWeekend_2'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume these are the scalers you've already trained using StandardScaler()\n",
    "scalers = {\n",
    "    'fare_predictions': fare_scaler,\n",
    "    'seats_predictions': seats_scaler,\n",
    "    'total_fare_predictions': weighted_fare_scaler,\n",
    "    'total_seats_predictions': total_seats_scaler\n",
    "}\n",
    "\n",
    "# Function to generate predictions and prepare DataFrame\n",
    "def generate_predictions(flight_number, scalers):\n",
    "    # Generate input data\n",
    "    input_data = generate_prediction_input(start_date, end_date, flight_number, training_columns)\n",
    "    \n",
    "    # Fill NA values\n",
    "    input_data_filled = input_data.fillna(0)\n",
    "    \n",
    "    # Generate predictions using the pre-trained models\n",
    "    fare_predictions = predict_model(final_model_fare, data=input_data_filled)\n",
    "    seats_predictions = predict_model(final_model_seats, data=input_data_filled)\n",
    "    total_fare_predictions = predict_model(final_model_total_fare, data=input_data_filled)\n",
    "    total_seats_predictions = predict_model(final_model_seats, data=input_data_filled)\n",
    "    \n",
    "    # Create the predictions DataFrame\n",
    "    predictions_df = pd.DataFrame({\n",
    "        'DepartureDate': input_data.index,\n",
    "        'FlightNumber': flight_number,\n",
    "        'fare_predictions': fare_predictions['prediction_label'].values,\n",
    "        'seats_predictions': seats_predictions['prediction_label'].values,\n",
    "        'total_fare_predictions': total_fare_predictions['prediction_label'].values,\n",
    "        'total_seats_predictions': total_seats_predictions['prediction_label'].values\n",
    "    })\n",
    "    \n",
    "    # Inverse transform the predictions using a single set of scalers\n",
    "    for col, scaler in scalers.items():\n",
    "        predictions_df[col] = scaler.inverse_transform(predictions_df[[col]]).flatten()\n",
    "    \n",
    "    # Round the predictions\n",
    "    predictions_df['AverageFare(SGD)'] = np.ceil(predictions_df['fare_predictions']).round(0)\n",
    "    predictions_df['SeatsSold'] = np.ceil(predictions_df['seats_predictions']).astype(int)\n",
    "    predictions_df['WeightedAverageFare(SGD)'] = np.ceil(predictions_df['total_fare_predictions']).round(0)\n",
    "    predictions_df['TotalSeatsSold'] = np.ceil(predictions_df['total_seats_predictions']).astype(int)\n",
    "    \n",
    "    # Drop the intermediate columns\n",
    "    predictions_df.drop(columns=['fare_predictions', 'seats_predictions', 'total_fare_predictions', 'total_seats_predictions'], inplace=True)\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_a00a4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a00a4_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a00a4_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_a00a4_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_a00a4_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_a00a4_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_a00a4_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_a00a4_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a00a4_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a00a4_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_a00a4_row0_col1\" class=\"data row0 col1\" >0.0751</td>\n",
       "      <td id=\"T_a00a4_row0_col2\" class=\"data row0 col2\" >0.0115</td>\n",
       "      <td id=\"T_a00a4_row0_col3\" class=\"data row0 col3\" >0.1073</td>\n",
       "      <td id=\"T_a00a4_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_a00a4_row0_col5\" class=\"data row0 col5\" >0.0957</td>\n",
       "      <td id=\"T_a00a4_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc7466e00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ef89b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ef89b_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ef89b_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_ef89b_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_ef89b_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_ef89b_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_ef89b_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_ef89b_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ef89b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ef89b_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_ef89b_row0_col1\" class=\"data row0 col1\" >0.0270</td>\n",
       "      <td id=\"T_ef89b_row0_col2\" class=\"data row0 col2\" >0.0013</td>\n",
       "      <td id=\"T_ef89b_row0_col3\" class=\"data row0 col3\" >0.0356</td>\n",
       "      <td id=\"T_ef89b_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_ef89b_row0_col5\" class=\"data row0 col5\" >0.0345</td>\n",
       "      <td id=\"T_ef89b_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab61f880>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e7c5f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e7c5f_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e7c5f_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_e7c5f_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_e7c5f_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_e7c5f_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_e7c5f_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_e7c5f_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e7c5f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e7c5f_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_e7c5f_row0_col1\" class=\"data row0 col1\" >0.2663</td>\n",
       "      <td id=\"T_e7c5f_row0_col2\" class=\"data row0 col2\" >0.0711</td>\n",
       "      <td id=\"T_e7c5f_row0_col3\" class=\"data row0 col3\" >0.2667</td>\n",
       "      <td id=\"T_e7c5f_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_e7c5f_row0_col5\" class=\"data row0 col5\" >0.2363</td>\n",
       "      <td id=\"T_e7c5f_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc16ee230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_71f41\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71f41_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_71f41_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_71f41_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_71f41_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_71f41_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_71f41_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_71f41_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71f41_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_71f41_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_71f41_row0_col1\" class=\"data row0 col1\" >0.0270</td>\n",
       "      <td id=\"T_71f41_row0_col2\" class=\"data row0 col2\" >0.0013</td>\n",
       "      <td id=\"T_71f41_row0_col3\" class=\"data row0 col3\" >0.0356</td>\n",
       "      <td id=\"T_71f41_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_71f41_row0_col5\" class=\"data row0 col5\" >0.0345</td>\n",
       "      <td id=\"T_71f41_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc710e170>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_46283\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_46283_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_46283_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_46283_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_46283_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_46283_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_46283_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_46283_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_46283_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_46283_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_46283_row0_col1\" class=\"data row0 col1\" >0.0563</td>\n",
       "      <td id=\"T_46283_row0_col2\" class=\"data row0 col2\" >0.0056</td>\n",
       "      <td id=\"T_46283_row0_col3\" class=\"data row0 col3\" >0.0748</td>\n",
       "      <td id=\"T_46283_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_46283_row0_col5\" class=\"data row0 col5\" >0.0695</td>\n",
       "      <td id=\"T_46283_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab7de6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_68c90\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68c90_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_68c90_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_68c90_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_68c90_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_68c90_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_68c90_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_68c90_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68c90_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_68c90_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_68c90_row0_col1\" class=\"data row0 col1\" >0.2218</td>\n",
       "      <td id=\"T_68c90_row0_col2\" class=\"data row0 col2\" >0.0500</td>\n",
       "      <td id=\"T_68c90_row0_col3\" class=\"data row0 col3\" >0.2235</td>\n",
       "      <td id=\"T_68c90_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_68c90_row0_col5\" class=\"data row0 col5\" >0.2013</td>\n",
       "      <td id=\"T_68c90_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cb2955510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c1d08\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c1d08_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c1d08_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_c1d08_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_c1d08_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_c1d08_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_c1d08_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_c1d08_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c1d08_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c1d08_row0_col0\" class=\"data row0 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_c1d08_row0_col1\" class=\"data row0 col1\" >1.2106</td>\n",
       "      <td id=\"T_c1d08_row0_col2\" class=\"data row0 col2\" >1.4656</td>\n",
       "      <td id=\"T_c1d08_row0_col3\" class=\"data row0 col3\" >1.2106</td>\n",
       "      <td id=\"T_c1d08_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_c1d08_row0_col5\" class=\"data row0 col5\" >0.7933</td>\n",
       "      <td id=\"T_c1d08_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cb1fa0fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_60751\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_60751_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_60751_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_60751_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_60751_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_60751_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_60751_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_60751_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_60751_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_60751_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_60751_row0_col1\" class=\"data row0 col1\" >0.2218</td>\n",
       "      <td id=\"T_60751_row0_col2\" class=\"data row0 col2\" >0.0500</td>\n",
       "      <td id=\"T_60751_row0_col3\" class=\"data row0 col3\" >0.2235</td>\n",
       "      <td id=\"T_60751_row0_col4\" class=\"data row0 col4\" >0.0000</td>\n",
       "      <td id=\"T_60751_row0_col5\" class=\"data row0 col5\" >0.2013</td>\n",
       "      <td id=\"T_60751_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc11a40d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for TR 202\n",
    "predictions_202 = generate_predictions(\"TR 202\", scalers)\n",
    "\n",
    "# Generate predictions for TR 203\n",
    "predictions_203 = generate_predictions(\"TR 203\", scalers)\n",
    "\n",
    "# Combine the predictions for both flights\n",
    "predicted_regress = pd.concat([predictions_202, predictions_203])\n",
    "\n",
    "# Arrange the columns in alphabetical order\n",
    "predicted_regress = predicted_regress[sorted(predicted_regress.columns)]\n",
    "\n",
    "# Arrange the columns in the desired order\n",
    "columns_order = ['DepartureDate', 'FlightNumber'] + sorted([col for col in predicted_regress.columns if col not in ['DepartureDate', 'FlightNumber']])\n",
    "predicted_regress = predicted_regress[columns_order]\n",
    "\n",
    "predicted_regress = predicted_regress.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Results\n",
    "\n",
    "The dataframe below presents the predicted fares and seats sold for Flight TR 202 & TR 203 throughout August 2019, using various predictive metrics:\n",
    "\n",
    "1. **Fare Predictions (Based on AverageFare(SGD))**: This column represents the fare predictions, based on each entry.\n",
    "   \n",
    "2. **Seats Predictions (Based on SeatsSold)**: This column shows the predicted number of seats sold, based on each entry.\n",
    "\n",
    "3. **Fare Predictions (Based on WeightedAverageFare(SGD))**: This column uses a weighted approach to predict fares, considering the average of all the fares for that departure date's flight.\n",
    "   \n",
    "4. **Seats Predictions (Based on TotalSeatsSold)**: Similar to the SeatsSold predictions, considering total seat availability for for that departure date's flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate FlightNumber  AverageFare(SGD)  SeatsSold  TotalSeatsSold  \\\n",
       "0     2019-08-01       TR 202              57.0          5             172   \n",
       "1     2019-08-02       TR 202              54.0          4             171   \n",
       "2     2019-08-03       TR 202              55.0          5             172   \n",
       "3     2019-08-04       TR 202              57.0          5             172   \n",
       "4     2019-08-05       TR 202              55.0          5             172   \n",
       "5     2019-08-06       TR 202              51.0          5             172   \n",
       "6     2019-08-07       TR 202              55.0          5             172   \n",
       "7     2019-08-08       TR 202              59.0          5             172   \n",
       "8     2019-08-09       TR 202              56.0          4             170   \n",
       "9     2019-08-10       TR 202              56.0          4             171   \n",
       "10    2019-08-11       TR 202              55.0          4             171   \n",
       "11    2019-08-12       TR 202              53.0          4             171   \n",
       "12    2019-08-13       TR 202              53.0          5             172   \n",
       "13    2019-08-14       TR 202              54.0          4             171   \n",
       "14    2019-08-15       TR 202              56.0          5             172   \n",
       "15    2019-08-16       TR 202              55.0          4             171   \n",
       "16    2019-08-17       TR 202              53.0          5             172   \n",
       "17    2019-08-18       TR 202              54.0          5             172   \n",
       "18    2019-08-19       TR 202              54.0          5             172   \n",
       "19    2019-08-20       TR 202              68.0          5             172   \n",
       "20    2019-08-21       TR 202              55.0          5             172   \n",
       "21    2019-08-22       TR 202              57.0          5             172   \n",
       "22    2019-08-23       TR 202              58.0          4             171   \n",
       "23    2019-08-24       TR 202              55.0          5             172   \n",
       "24    2019-08-25       TR 202              55.0          5             172   \n",
       "25    2019-08-26       TR 202              59.0          5             172   \n",
       "26    2019-08-27       TR 202              54.0          5             172   \n",
       "27    2019-08-28       TR 202              53.0          5             172   \n",
       "28    2019-08-29       TR 202              57.0          4             171   \n",
       "29    2019-08-30       TR 202              55.0          4             171   \n",
       "30    2019-08-01       TR 203              53.0          4             169   \n",
       "31    2019-08-02       TR 203              51.0          4             168   \n",
       "32    2019-08-03       TR 203              49.0          4             169   \n",
       "33    2019-08-04       TR 203              52.0          4             169   \n",
       "34    2019-08-05       TR 203              52.0          4             169   \n",
       "35    2019-08-06       TR 203              50.0          4             169   \n",
       "36    2019-08-07       TR 203              51.0          4             169   \n",
       "37    2019-08-08       TR 203              54.0          4             169   \n",
       "38    2019-08-09       TR 203              53.0          3             168   \n",
       "39    2019-08-10       TR 203              54.0          4             168   \n",
       "40    2019-08-11       TR 203              52.0          4             168   \n",
       "41    2019-08-12       TR 203              52.0          4             168   \n",
       "42    2019-08-13       TR 203              49.0          4             169   \n",
       "43    2019-08-14       TR 203              51.0          4             168   \n",
       "44    2019-08-15       TR 203              54.0          4             169   \n",
       "45    2019-08-16       TR 203              50.0          4             168   \n",
       "46    2019-08-17       TR 203              50.0          4             169   \n",
       "47    2019-08-18       TR 203              51.0          4             169   \n",
       "48    2019-08-19       TR 203              50.0          4             169   \n",
       "49    2019-08-20       TR 203              63.0          4             169   \n",
       "50    2019-08-21       TR 203              52.0          4             169   \n",
       "51    2019-08-22       TR 203              53.0          4             169   \n",
       "52    2019-08-23       TR 203              55.0          4             168   \n",
       "53    2019-08-24       TR 203              51.0          4             169   \n",
       "54    2019-08-25       TR 203              51.0          4             169   \n",
       "55    2019-08-26       TR 203              56.0          4             169   \n",
       "56    2019-08-27       TR 203              51.0          4             169   \n",
       "57    2019-08-28       TR 203              50.0          4             169   \n",
       "58    2019-08-29       TR 203              52.0          4             168   \n",
       "59    2019-08-30       TR 203              51.0          4             168   \n",
       "\n",
       "    WeightedAverageFare(SGD)  \n",
       "0                       48.0  \n",
       "1                       49.0  \n",
       "2                       49.0  \n",
       "3                       49.0  \n",
       "4                       50.0  \n",
       "5                       49.0  \n",
       "6                       48.0  \n",
       "7                       49.0  \n",
       "8                       49.0  \n",
       "9                       49.0  \n",
       "10                      49.0  \n",
       "11                      49.0  \n",
       "12                      49.0  \n",
       "13                      49.0  \n",
       "14                      49.0  \n",
       "15                      49.0  \n",
       "16                      49.0  \n",
       "17                      48.0  \n",
       "18                      49.0  \n",
       "19                      48.0  \n",
       "20                      48.0  \n",
       "21                      48.0  \n",
       "22                      49.0  \n",
       "23                      49.0  \n",
       "24                      49.0  \n",
       "25                      49.0  \n",
       "26                      49.0  \n",
       "27                      48.0  \n",
       "28                      49.0  \n",
       "29                      49.0  \n",
       "30                      27.0  \n",
       "31                      27.0  \n",
       "32                      27.0  \n",
       "33                      27.0  \n",
       "34                      27.0  \n",
       "35                      27.0  \n",
       "36                      27.0  \n",
       "37                      27.0  \n",
       "38                      27.0  \n",
       "39                      27.0  \n",
       "40                      27.0  \n",
       "41                      27.0  \n",
       "42                      27.0  \n",
       "43                      27.0  \n",
       "44                      27.0  \n",
       "45                      27.0  \n",
       "46                      27.0  \n",
       "47                      27.0  \n",
       "48                      27.0  \n",
       "49                      27.0  \n",
       "50                      27.0  \n",
       "51                      27.0  \n",
       "52                      27.0  \n",
       "53                      27.0  \n",
       "54                      27.0  \n",
       "55                      27.0  \n",
       "56                      27.0  \n",
       "57                      27.0  \n",
       "58                      27.0  \n",
       "59                      27.0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Forecasting Method\n",
    "\n",
    "In this section, a time-series model was applied to the data to predict the AverageFare (SGD) and SeatsSold for specific flights throughout August 2019. Unlike regression models, time-series forecasting inherently accounts for the sequential nature of data, making it more suitable for predicting outcomes that are influenced by temporal factors.\n",
    "\n",
    "The PyCaret time-series model used here was trained on historical data, capturing trends, seasonality, and other time-dependent patterns that influence flight sales and pricing. This approach aims to provide more accurate and reliable predictions compared to traditional regression methods.\n",
    "\n",
    "**Key Points**\n",
    "- **Time Dependence**: The time-series model accounts for the sequential order of data, recognizing that past values influence future outcomes. This is critical for making accurate predictions in industries where trends and seasonality significantly impact demand.\n",
    "\n",
    "- **Seasonality and Trend Analysis**: The model captures both seasonal effects (e.g., weekly or monthly patterns) and long-term trends, providing a more comprehensive forecast that aligns with real-world behavior.\n",
    "\n",
    "- **Improved Accuracy**: By incorporating temporal patterns and using a more extensive dataset, the time-series model offers potentially more accurate predictions for seat sales and fares, especially in dynamic environments like the airline industry.\n",
    "\n",
    "- **Model Complexity**: Time-series models are typically more complex and require a deeper understanding of the underlying data. However, this complexity allows for more nuanced predictions that better reflect reality.\n",
    "\n",
    "- **Extensive Data Utilization**: The model benefits from a more extensive historical dataset, allowing it to better capture the variations and trends over time, leading to more reliable forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycaret\n",
    "pycaret.__version__\n",
    "\n",
    "# print(df_TR202.head())\n",
    "# print(df_TR203.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_TR202_g = df_TR202.groupby('DepartureDate').agg({\n",
    "    'SeatsSold': 'sum',\n",
    "    'AverageFare(SGD)': 'mean',\n",
    "    'WeightedAverageFare(SGD)': 'mean',\n",
    "    'TotalSeatsSold': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12, 20))\n",
    "\n",
    "# Plot SeatsSold\n",
    "df_TR202_g.plot(x='DepartureDate', y='SeatsSold', ax=axs[0], title='SeatsSold vs DepartureDate', color='blue', marker='o')\n",
    "axs[0].set_xlabel('Departure Date')\n",
    "axs[0].set_ylabel('Seats Sold')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot AverageFare(SGD)\n",
    "df_TR202_g.plot(x='DepartureDate', y='AverageFare(SGD)', ax=axs[1], title='AverageFare(SGD) vs DepartureDate', color='green', marker='o')\n",
    "axs[1].set_xlabel('Departure Date')\n",
    "axs[1].set_ylabel('Average Fare (SGD)')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot WeightedAverageFare(SGD)\n",
    "df_TR202_g.plot(x='DepartureDate', y='WeightedAverageFare(SGD)', ax=axs[2], title='WeightedAverageFare(SGD) vs DepartureDate', color='red', marker='o')\n",
    "axs[2].set_xlabel('Departure Date')\n",
    "axs[2].set_ylabel('Weighted Average Fare (SGD)')\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Plot TotalSeatsSold\n",
    "df_TR202_g.plot(x='DepartureDate', y='TotalSeatsSold', ax=axs[3], title='TotalSeatsSold vs DepartureDate', color='purple', marker='o')\n",
    "axs[3].set_xlabel('Departure Date')\n",
    "axs[3].set_ylabel('Total Seats Sold')\n",
    "axs[3].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_seats_sold_202 = df_TR202_g[['DepartureDate', 'SeatsSold']]\n",
    "df_average_fare_202 = df_TR202_g[['DepartureDate', 'AverageFare(SGD)']]\n",
    "df_weighted_average_fare_202 = df_TR202_g[['DepartureDate', 'WeightedAverageFare(SGD)']]\n",
    "df_total_seats_sold_202 = df_TR202_g[['DepartureDate', 'TotalSeatsSold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x2000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_TR203_g = df_TR203.groupby('DepartureDate').agg({\n",
    "    'SeatsSold': 'sum',\n",
    "    'AverageFare(SGD)': 'mean',\n",
    "    'WeightedAverageFare(SGD)': 'mean',\n",
    "    'TotalSeatsSold': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, figsize=(12, 20))\n",
    "\n",
    "# Plot SeatsSold\n",
    "df_TR203_g.plot(x='DepartureDate', y='SeatsSold', ax=axs[0], title='SeatsSold vs DepartureDate', color='blue', marker='o')\n",
    "axs[0].set_xlabel('Departure Date')\n",
    "axs[0].set_ylabel('Seats Sold')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot AverageFare(SGD)\n",
    "df_TR203_g.plot(x='DepartureDate', y='AverageFare(SGD)', ax=axs[1], title='AverageFare(SGD) vs DepartureDate', color='green', marker='o')\n",
    "axs[1].set_xlabel('Departure Date')\n",
    "axs[1].set_ylabel('Average Fare (SGD)')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot WeightedAverageFare(SGD)\n",
    "df_TR203_g.plot(x='DepartureDate', y='WeightedAverageFare(SGD)', ax=axs[2], title='WeightedAverageFare(SGD) vs DepartureDate', color='red', marker='o')\n",
    "axs[2].set_xlabel('Departure Date')\n",
    "axs[2].set_ylabel('Weighted Average Fare (SGD)')\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Plot TotalSeatsSold\n",
    "df_TR203_g.plot(x='DepartureDate', y='TotalSeatsSold', ax=axs[3], title='TotalSeatsSold vs DepartureDate', color='purple', marker='o')\n",
    "axs[3].set_xlabel('Departure Date')\n",
    "axs[3].set_ylabel('Total Seats Sold')\n",
    "axs[3].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "df_seats_sold_203 = df_TR203_g[['DepartureDate', 'SeatsSold']]\n",
    "df_average_fare_203 = df_TR203_g[['DepartureDate', 'AverageFare(SGD)']]\n",
    "df_weighted_average_fare_203 = df_TR203_g[['DepartureDate', 'WeightedAverageFare(SGD)']]\n",
    "df_total_seats_sold_203 = df_TR203_g[['DepartureDate', 'TotalSeatsSold']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_05eca_row28_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_05eca\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_05eca_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_05eca_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_05eca_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_05eca_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_05eca_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_05eca_row1_col1\" class=\"data row1 col1\" >SeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_05eca_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_05eca_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_05eca_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_05eca_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_05eca_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_05eca_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_05eca_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_05eca_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_05eca_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_05eca_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_05eca_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_05eca_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_05eca_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_05eca_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_05eca_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_05eca_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_05eca_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_05eca_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_05eca_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_05eca_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_05eca_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_05eca_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_05eca_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_05eca_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_05eca_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_05eca_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_05eca_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_05eca_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_05eca_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_05eca_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_05eca_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_05eca_row17_col1\" class=\"data row17 col1\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_05eca_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_05eca_row18_col1\" class=\"data row18 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_05eca_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_05eca_row19_col1\" class=\"data row19 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_05eca_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_05eca_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_05eca_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_05eca_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_05eca_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_05eca_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_05eca_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_05eca_row23_col1\" class=\"data row23 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_05eca_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_05eca_row24_col1\" class=\"data row24 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_05eca_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_05eca_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_05eca_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_05eca_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_05eca_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_05eca_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_05eca_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_05eca_row28_col1\" class=\"data row28 col1\" >Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_05eca_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_05eca_row29_col1\" class=\"data row29 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_05eca_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_05eca_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_05eca_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_05eca_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_05eca_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_05eca_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_05eca_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_05eca_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_05eca_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_05eca_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_05eca_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_05eca_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05eca_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_05eca_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_05eca_row36_col1\" class=\"data row36 col1\" >0afd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc7deafb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bb51a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb51a_row0_col0, #T_bb51a_row0_col2, #T_bb51a_row0_col4, #T_bb51a_row0_col7, #T_bb51a_row1_col0, #T_bb51a_row1_col1, #T_bb51a_row1_col3, #T_bb51a_row1_col4, #T_bb51a_row1_col5, #T_bb51a_row1_col6, #T_bb51a_row1_col7, #T_bb51a_row2_col0, #T_bb51a_row2_col1, #T_bb51a_row2_col3, #T_bb51a_row2_col5, #T_bb51a_row2_col6, #T_bb51a_row2_col7, #T_bb51a_row3_col0, #T_bb51a_row3_col1, #T_bb51a_row3_col3, #T_bb51a_row3_col5, #T_bb51a_row3_col6, #T_bb51a_row3_col7, #T_bb51a_row4_col0, #T_bb51a_row4_col1, #T_bb51a_row4_col2, #T_bb51a_row4_col3, #T_bb51a_row4_col4, #T_bb51a_row4_col5, #T_bb51a_row4_col6, #T_bb51a_row4_col7, #T_bb51a_row5_col0, #T_bb51a_row5_col1, #T_bb51a_row5_col2, #T_bb51a_row5_col3, #T_bb51a_row5_col4, #T_bb51a_row5_col5, #T_bb51a_row5_col6, #T_bb51a_row5_col7, #T_bb51a_row6_col0, #T_bb51a_row6_col1, #T_bb51a_row6_col2, #T_bb51a_row6_col3, #T_bb51a_row6_col4, #T_bb51a_row6_col5, #T_bb51a_row6_col6, #T_bb51a_row6_col7, #T_bb51a_row7_col0, #T_bb51a_row7_col1, #T_bb51a_row7_col2, #T_bb51a_row7_col3, #T_bb51a_row7_col4, #T_bb51a_row7_col5, #T_bb51a_row7_col6, #T_bb51a_row8_col0, #T_bb51a_row8_col1, #T_bb51a_row8_col2, #T_bb51a_row8_col3, #T_bb51a_row8_col4, #T_bb51a_row8_col5, #T_bb51a_row8_col6, #T_bb51a_row8_col7, #T_bb51a_row9_col0, #T_bb51a_row9_col1, #T_bb51a_row9_col2, #T_bb51a_row9_col3, #T_bb51a_row9_col4, #T_bb51a_row9_col5, #T_bb51a_row9_col6, #T_bb51a_row9_col7, #T_bb51a_row10_col0, #T_bb51a_row10_col1, #T_bb51a_row10_col2, #T_bb51a_row10_col3, #T_bb51a_row10_col4, #T_bb51a_row10_col5, #T_bb51a_row10_col6, #T_bb51a_row10_col7, #T_bb51a_row11_col0, #T_bb51a_row11_col1, #T_bb51a_row11_col2, #T_bb51a_row11_col3, #T_bb51a_row11_col4, #T_bb51a_row11_col5, #T_bb51a_row11_col6, #T_bb51a_row11_col7, #T_bb51a_row12_col0, #T_bb51a_row12_col1, #T_bb51a_row12_col2, #T_bb51a_row12_col3, #T_bb51a_row12_col4, #T_bb51a_row12_col5, #T_bb51a_row12_col6, #T_bb51a_row12_col7, #T_bb51a_row13_col0, #T_bb51a_row13_col1, #T_bb51a_row13_col2, #T_bb51a_row13_col3, #T_bb51a_row13_col4, #T_bb51a_row13_col5, #T_bb51a_row13_col6, #T_bb51a_row13_col7, #T_bb51a_row14_col0, #T_bb51a_row14_col1, #T_bb51a_row14_col2, #T_bb51a_row14_col3, #T_bb51a_row14_col4, #T_bb51a_row14_col5, #T_bb51a_row14_col6, #T_bb51a_row14_col7, #T_bb51a_row15_col0, #T_bb51a_row15_col1, #T_bb51a_row15_col2, #T_bb51a_row15_col3, #T_bb51a_row15_col4, #T_bb51a_row15_col5, #T_bb51a_row15_col6, #T_bb51a_row15_col7, #T_bb51a_row16_col0, #T_bb51a_row16_col1, #T_bb51a_row16_col2, #T_bb51a_row16_col3, #T_bb51a_row16_col4, #T_bb51a_row16_col5, #T_bb51a_row16_col6, #T_bb51a_row16_col7, #T_bb51a_row17_col0, #T_bb51a_row17_col1, #T_bb51a_row17_col2, #T_bb51a_row17_col3, #T_bb51a_row17_col4, #T_bb51a_row17_col5, #T_bb51a_row17_col6, #T_bb51a_row17_col7, #T_bb51a_row18_col0, #T_bb51a_row18_col1, #T_bb51a_row18_col2, #T_bb51a_row18_col3, #T_bb51a_row18_col4, #T_bb51a_row18_col5, #T_bb51a_row18_col6, #T_bb51a_row18_col7, #T_bb51a_row19_col0, #T_bb51a_row19_col1, #T_bb51a_row19_col2, #T_bb51a_row19_col3, #T_bb51a_row19_col4, #T_bb51a_row19_col5, #T_bb51a_row19_col6, #T_bb51a_row19_col7, #T_bb51a_row20_col0, #T_bb51a_row20_col1, #T_bb51a_row20_col2, #T_bb51a_row20_col3, #T_bb51a_row20_col4, #T_bb51a_row20_col5, #T_bb51a_row20_col6, #T_bb51a_row20_col7, #T_bb51a_row21_col0, #T_bb51a_row21_col1, #T_bb51a_row21_col2, #T_bb51a_row21_col3, #T_bb51a_row21_col4, #T_bb51a_row21_col5, #T_bb51a_row21_col6, #T_bb51a_row21_col7, #T_bb51a_row22_col0, #T_bb51a_row22_col1, #T_bb51a_row22_col2, #T_bb51a_row22_col3, #T_bb51a_row22_col4, #T_bb51a_row22_col5, #T_bb51a_row22_col6, #T_bb51a_row22_col7, #T_bb51a_row23_col0, #T_bb51a_row23_col1, #T_bb51a_row23_col2, #T_bb51a_row23_col3, #T_bb51a_row23_col4, #T_bb51a_row23_col5, #T_bb51a_row23_col6, #T_bb51a_row23_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bb51a_row0_col1, #T_bb51a_row0_col3, #T_bb51a_row0_col5, #T_bb51a_row0_col6, #T_bb51a_row1_col2, #T_bb51a_row2_col2, #T_bb51a_row2_col4, #T_bb51a_row3_col2, #T_bb51a_row3_col4, #T_bb51a_row7_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_bb51a_row0_col8, #T_bb51a_row1_col8, #T_bb51a_row2_col8, #T_bb51a_row3_col8, #T_bb51a_row4_col8, #T_bb51a_row5_col8, #T_bb51a_row6_col8, #T_bb51a_row7_col8, #T_bb51a_row8_col8, #T_bb51a_row9_col8, #T_bb51a_row10_col8, #T_bb51a_row11_col8, #T_bb51a_row12_col8, #T_bb51a_row13_col8, #T_bb51a_row14_col8, #T_bb51a_row15_col8, #T_bb51a_row16_col8, #T_bb51a_row17_col8, #T_bb51a_row18_col8, #T_bb51a_row20_col8, #T_bb51a_row21_col8, #T_bb51a_row22_col8, #T_bb51a_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_bb51a_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bb51a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bb51a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_bb51a_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_bb51a_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_bb51a_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_bb51a_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_bb51a_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_bb51a_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_bb51a_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_bb51a_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row0\" class=\"row_heading level0 row0\" >theta</th>\n",
       "      <td id=\"T_bb51a_row0_col0\" class=\"data row0 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_bb51a_row0_col1\" class=\"data row0 col1\" >0.3722</td>\n",
       "      <td id=\"T_bb51a_row0_col2\" class=\"data row0 col2\" >0.3732</td>\n",
       "      <td id=\"T_bb51a_row0_col3\" class=\"data row0 col3\" >6.6515</td>\n",
       "      <td id=\"T_bb51a_row0_col4\" class=\"data row0 col4\" >9.2942</td>\n",
       "      <td id=\"T_bb51a_row0_col5\" class=\"data row0 col5\" >0.0390</td>\n",
       "      <td id=\"T_bb51a_row0_col6\" class=\"data row0 col6\" >0.0386</td>\n",
       "      <td id=\"T_bb51a_row0_col7\" class=\"data row0 col7\" >-1.9294</td>\n",
       "      <td id=\"T_bb51a_row0_col8\" class=\"data row0 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row1\" class=\"row_heading level0 row1\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row1_col0\" class=\"data row1 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row1_col1\" class=\"data row1 col1\" >0.3965</td>\n",
       "      <td id=\"T_bb51a_row1_col2\" class=\"data row1 col2\" >0.3625</td>\n",
       "      <td id=\"T_bb51a_row1_col3\" class=\"data row1 col3\" >6.8958</td>\n",
       "      <td id=\"T_bb51a_row1_col4\" class=\"data row1 col4\" >8.9052</td>\n",
       "      <td id=\"T_bb51a_row1_col5\" class=\"data row1 col5\" >0.0407</td>\n",
       "      <td id=\"T_bb51a_row1_col6\" class=\"data row1 col6\" >0.0394</td>\n",
       "      <td id=\"T_bb51a_row1_col7\" class=\"data row1 col7\" >-0.6563</td>\n",
       "      <td id=\"T_bb51a_row1_col8\" class=\"data row1 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row2\" class=\"row_heading level0 row2\" >omp_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row2_col0\" class=\"data row2 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row2_col1\" class=\"data row2 col1\" >0.3965</td>\n",
       "      <td id=\"T_bb51a_row2_col2\" class=\"data row2 col2\" >0.3625</td>\n",
       "      <td id=\"T_bb51a_row2_col3\" class=\"data row2 col3\" >6.8956</td>\n",
       "      <td id=\"T_bb51a_row2_col4\" class=\"data row2 col4\" >8.9050</td>\n",
       "      <td id=\"T_bb51a_row2_col5\" class=\"data row2 col5\" >0.0407</td>\n",
       "      <td id=\"T_bb51a_row2_col6\" class=\"data row2 col6\" >0.0394</td>\n",
       "      <td id=\"T_bb51a_row2_col7\" class=\"data row2 col7\" >-0.6562</td>\n",
       "      <td id=\"T_bb51a_row2_col8\" class=\"data row2 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row3\" class=\"row_heading level0 row3\" >lr_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row3_col0\" class=\"data row3 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row3_col1\" class=\"data row3 col1\" >0.3965</td>\n",
       "      <td id=\"T_bb51a_row3_col2\" class=\"data row3 col2\" >0.3625</td>\n",
       "      <td id=\"T_bb51a_row3_col3\" class=\"data row3 col3\" >6.8956</td>\n",
       "      <td id=\"T_bb51a_row3_col4\" class=\"data row3 col4\" >8.9050</td>\n",
       "      <td id=\"T_bb51a_row3_col5\" class=\"data row3 col5\" >0.0407</td>\n",
       "      <td id=\"T_bb51a_row3_col6\" class=\"data row3 col6\" >0.0394</td>\n",
       "      <td id=\"T_bb51a_row3_col7\" class=\"data row3 col7\" >-0.6562</td>\n",
       "      <td id=\"T_bb51a_row3_col8\" class=\"data row3 col8\" >0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row4\" class=\"row_heading level0 row4\" >en_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row4_col0\" class=\"data row4 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row4_col1\" class=\"data row4 col1\" >0.3970</td>\n",
       "      <td id=\"T_bb51a_row4_col2\" class=\"data row4 col2\" >0.3628</td>\n",
       "      <td id=\"T_bb51a_row4_col3\" class=\"data row4 col3\" >6.9042</td>\n",
       "      <td id=\"T_bb51a_row4_col4\" class=\"data row4 col4\" >8.9119</td>\n",
       "      <td id=\"T_bb51a_row4_col5\" class=\"data row4 col5\" >0.0407</td>\n",
       "      <td id=\"T_bb51a_row4_col6\" class=\"data row4 col6\" >0.0394</td>\n",
       "      <td id=\"T_bb51a_row4_col7\" class=\"data row4 col7\" >-0.6607</td>\n",
       "      <td id=\"T_bb51a_row4_col8\" class=\"data row4 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row5\" class=\"row_heading level0 row5\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row5_col0\" class=\"data row5 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row5_col1\" class=\"data row5 col1\" >0.3973</td>\n",
       "      <td id=\"T_bb51a_row5_col2\" class=\"data row5 col2\" >0.3629</td>\n",
       "      <td id=\"T_bb51a_row5_col3\" class=\"data row5 col3\" >6.9101</td>\n",
       "      <td id=\"T_bb51a_row5_col4\" class=\"data row5 col4\" >8.9166</td>\n",
       "      <td id=\"T_bb51a_row5_col5\" class=\"data row5 col5\" >0.0408</td>\n",
       "      <td id=\"T_bb51a_row5_col6\" class=\"data row5 col6\" >0.0395</td>\n",
       "      <td id=\"T_bb51a_row5_col7\" class=\"data row5 col7\" >-0.6638</td>\n",
       "      <td id=\"T_bb51a_row5_col8\" class=\"data row5 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row6\" class=\"row_heading level0 row6\" >llar_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row6_col0\" class=\"data row6 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row6_col1\" class=\"data row6 col1\" >0.3973</td>\n",
       "      <td id=\"T_bb51a_row6_col2\" class=\"data row6 col2\" >0.3629</td>\n",
       "      <td id=\"T_bb51a_row6_col3\" class=\"data row6 col3\" >6.9101</td>\n",
       "      <td id=\"T_bb51a_row6_col4\" class=\"data row6 col4\" >8.9166</td>\n",
       "      <td id=\"T_bb51a_row6_col5\" class=\"data row6 col5\" >0.0408</td>\n",
       "      <td id=\"T_bb51a_row6_col6\" class=\"data row6 col6\" >0.0395</td>\n",
       "      <td id=\"T_bb51a_row6_col7\" class=\"data row6 col7\" >-0.6638</td>\n",
       "      <td id=\"T_bb51a_row6_col8\" class=\"data row6 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row7\" class=\"row_heading level0 row7\" >huber_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row7_col0\" class=\"data row7 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row7_col1\" class=\"data row7 col1\" >0.4215</td>\n",
       "      <td id=\"T_bb51a_row7_col2\" class=\"data row7 col2\" >0.3664</td>\n",
       "      <td id=\"T_bb51a_row7_col3\" class=\"data row7 col3\" >7.1987</td>\n",
       "      <td id=\"T_bb51a_row7_col4\" class=\"data row7 col4\" >8.9095</td>\n",
       "      <td id=\"T_bb51a_row7_col5\" class=\"data row7 col5\" >0.0428</td>\n",
       "      <td id=\"T_bb51a_row7_col6\" class=\"data row7 col6\" >0.0407</td>\n",
       "      <td id=\"T_bb51a_row7_col7\" class=\"data row7 col7\" >-0.3611</td>\n",
       "      <td id=\"T_bb51a_row7_col8\" class=\"data row7 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row8\" class=\"row_heading level0 row8\" >exp_smooth</th>\n",
       "      <td id=\"T_bb51a_row8_col0\" class=\"data row8 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_bb51a_row8_col1\" class=\"data row8 col1\" >0.4267</td>\n",
       "      <td id=\"T_bb51a_row8_col2\" class=\"data row8 col2\" >0.3972</td>\n",
       "      <td id=\"T_bb51a_row8_col3\" class=\"data row8 col3\" >7.5027</td>\n",
       "      <td id=\"T_bb51a_row8_col4\" class=\"data row8 col4\" >9.8314</td>\n",
       "      <td id=\"T_bb51a_row8_col5\" class=\"data row8 col5\" >0.0440</td>\n",
       "      <td id=\"T_bb51a_row8_col6\" class=\"data row8 col6\" >0.0431</td>\n",
       "      <td id=\"T_bb51a_row8_col7\" class=\"data row8 col7\" >-1.5898</td>\n",
       "      <td id=\"T_bb51a_row8_col8\" class=\"data row8 col8\" >0.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row9\" class=\"row_heading level0 row9\" >ets</th>\n",
       "      <td id=\"T_bb51a_row9_col0\" class=\"data row9 col0\" >ETS</td>\n",
       "      <td id=\"T_bb51a_row9_col1\" class=\"data row9 col1\" >0.4268</td>\n",
       "      <td id=\"T_bb51a_row9_col2\" class=\"data row9 col2\" >0.3972</td>\n",
       "      <td id=\"T_bb51a_row9_col3\" class=\"data row9 col3\" >7.5030</td>\n",
       "      <td id=\"T_bb51a_row9_col4\" class=\"data row9 col4\" >9.8316</td>\n",
       "      <td id=\"T_bb51a_row9_col5\" class=\"data row9 col5\" >0.0440</td>\n",
       "      <td id=\"T_bb51a_row9_col6\" class=\"data row9 col6\" >0.0431</td>\n",
       "      <td id=\"T_bb51a_row9_col7\" class=\"data row9 col7\" >-1.5899</td>\n",
       "      <td id=\"T_bb51a_row9_col8\" class=\"data row9 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row10\" class=\"row_heading level0 row10\" >polytrend</th>\n",
       "      <td id=\"T_bb51a_row10_col0\" class=\"data row10 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_bb51a_row10_col1\" class=\"data row10 col1\" >0.4268</td>\n",
       "      <td id=\"T_bb51a_row10_col2\" class=\"data row10 col2\" >0.3972</td>\n",
       "      <td id=\"T_bb51a_row10_col3\" class=\"data row10 col3\" >7.5030</td>\n",
       "      <td id=\"T_bb51a_row10_col4\" class=\"data row10 col4\" >9.8316</td>\n",
       "      <td id=\"T_bb51a_row10_col5\" class=\"data row10 col5\" >0.0440</td>\n",
       "      <td id=\"T_bb51a_row10_col6\" class=\"data row10 col6\" >0.0431</td>\n",
       "      <td id=\"T_bb51a_row10_col7\" class=\"data row10 col7\" >-1.5899</td>\n",
       "      <td id=\"T_bb51a_row10_col8\" class=\"data row10 col8\" >0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row11\" class=\"row_heading level0 row11\" >br_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row11_col0\" class=\"data row11 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row11_col1\" class=\"data row11 col1\" >0.4311</td>\n",
       "      <td id=\"T_bb51a_row11_col2\" class=\"data row11 col2\" >0.3889</td>\n",
       "      <td id=\"T_bb51a_row11_col3\" class=\"data row11 col3\" >7.5359</td>\n",
       "      <td id=\"T_bb51a_row11_col4\" class=\"data row11 col4\" >9.5894</td>\n",
       "      <td id=\"T_bb51a_row11_col5\" class=\"data row11 col5\" >0.0443</td>\n",
       "      <td id=\"T_bb51a_row11_col6\" class=\"data row11 col6\" >0.0431</td>\n",
       "      <td id=\"T_bb51a_row11_col7\" class=\"data row11 col7\" >-1.1610</td>\n",
       "      <td id=\"T_bb51a_row11_col8\" class=\"data row11 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row12\" class=\"row_heading level0 row12\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row12_col0\" class=\"data row12 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row12_col1\" class=\"data row12 col1\" >0.4314</td>\n",
       "      <td id=\"T_bb51a_row12_col2\" class=\"data row12 col2\" >0.3891</td>\n",
       "      <td id=\"T_bb51a_row12_col3\" class=\"data row12 col3\" >7.5409</td>\n",
       "      <td id=\"T_bb51a_row12_col4\" class=\"data row12 col4\" >9.5952</td>\n",
       "      <td id=\"T_bb51a_row12_col5\" class=\"data row12 col5\" >0.0443</td>\n",
       "      <td id=\"T_bb51a_row12_col6\" class=\"data row12 col6\" >0.0431</td>\n",
       "      <td id=\"T_bb51a_row12_col7\" class=\"data row12 col7\" >-1.1655</td>\n",
       "      <td id=\"T_bb51a_row12_col8\" class=\"data row12 col8\" >0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row13\" class=\"row_heading level0 row13\" >knn_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row13_col0\" class=\"data row13 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row13_col1\" class=\"data row13 col1\" >0.4777</td>\n",
       "      <td id=\"T_bb51a_row13_col2\" class=\"data row13 col2\" >0.4159</td>\n",
       "      <td id=\"T_bb51a_row13_col3\" class=\"data row13 col3\" >8.2585</td>\n",
       "      <td id=\"T_bb51a_row13_col4\" class=\"data row13 col4\" >10.1777</td>\n",
       "      <td id=\"T_bb51a_row13_col5\" class=\"data row13 col5\" >0.0487</td>\n",
       "      <td id=\"T_bb51a_row13_col6\" class=\"data row13 col6\" >0.0467</td>\n",
       "      <td id=\"T_bb51a_row13_col7\" class=\"data row13 col7\" >-0.9548</td>\n",
       "      <td id=\"T_bb51a_row13_col8\" class=\"data row13 col8\" >0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row14\" class=\"row_heading level0 row14\" >rf_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row14_col0\" class=\"data row14 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row14_col1\" class=\"data row14 col1\" >0.6147</td>\n",
       "      <td id=\"T_bb51a_row14_col2\" class=\"data row14 col2\" >0.5490</td>\n",
       "      <td id=\"T_bb51a_row14_col3\" class=\"data row14 col3\" >10.8204</td>\n",
       "      <td id=\"T_bb51a_row14_col4\" class=\"data row14 col4\" >13.6507</td>\n",
       "      <td id=\"T_bb51a_row14_col5\" class=\"data row14 col5\" >0.0632</td>\n",
       "      <td id=\"T_bb51a_row14_col6\" class=\"data row14 col6\" >0.0619</td>\n",
       "      <td id=\"T_bb51a_row14_col7\" class=\"data row14 col7\" >-4.9387</td>\n",
       "      <td id=\"T_bb51a_row14_col8\" class=\"data row14 col8\" >0.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row15\" class=\"row_heading level0 row15\" >et_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row15_col0\" class=\"data row15 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row15_col1\" class=\"data row15 col1\" >0.7734</td>\n",
       "      <td id=\"T_bb51a_row15_col2\" class=\"data row15 col2\" >0.6449</td>\n",
       "      <td id=\"T_bb51a_row15_col3\" class=\"data row15 col3\" >13.5842</td>\n",
       "      <td id=\"T_bb51a_row15_col4\" class=\"data row15 col4\" >16.0376</td>\n",
       "      <td id=\"T_bb51a_row15_col5\" class=\"data row15 col5\" >0.0787</td>\n",
       "      <td id=\"T_bb51a_row15_col6\" class=\"data row15 col6\" >0.0766</td>\n",
       "      <td id=\"T_bb51a_row15_col7\" class=\"data row15 col7\" >-7.2217</td>\n",
       "      <td id=\"T_bb51a_row15_col8\" class=\"data row15 col8\" >0.2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row16\" class=\"row_heading level0 row16\" >auto_arima</th>\n",
       "      <td id=\"T_bb51a_row16_col0\" class=\"data row16 col0\" >Auto ARIMA</td>\n",
       "      <td id=\"T_bb51a_row16_col1\" class=\"data row16 col1\" >0.7762</td>\n",
       "      <td id=\"T_bb51a_row16_col2\" class=\"data row16 col2\" >0.5859</td>\n",
       "      <td id=\"T_bb51a_row16_col3\" class=\"data row16 col3\" >14.0087</td>\n",
       "      <td id=\"T_bb51a_row16_col4\" class=\"data row16 col4\" >14.8137</td>\n",
       "      <td id=\"T_bb51a_row16_col5\" class=\"data row16 col5\" >0.0799</td>\n",
       "      <td id=\"T_bb51a_row16_col6\" class=\"data row16 col6\" >0.0826</td>\n",
       "      <td id=\"T_bb51a_row16_col7\" class=\"data row16 col7\" >-11.7632</td>\n",
       "      <td id=\"T_bb51a_row16_col8\" class=\"data row16 col8\" >0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row17\" class=\"row_heading level0 row17\" >arima</th>\n",
       "      <td id=\"T_bb51a_row17_col0\" class=\"data row17 col0\" >ARIMA</td>\n",
       "      <td id=\"T_bb51a_row17_col1\" class=\"data row17 col1\" >0.9476</td>\n",
       "      <td id=\"T_bb51a_row17_col2\" class=\"data row17 col2\" >0.6864</td>\n",
       "      <td id=\"T_bb51a_row17_col3\" class=\"data row17 col3\" >16.8647</td>\n",
       "      <td id=\"T_bb51a_row17_col4\" class=\"data row17 col4\" >17.2097</td>\n",
       "      <td id=\"T_bb51a_row17_col5\" class=\"data row17 col5\" >0.0949</td>\n",
       "      <td id=\"T_bb51a_row17_col6\" class=\"data row17 col6\" >0.0995</td>\n",
       "      <td id=\"T_bb51a_row17_col7\" class=\"data row17 col7\" >-11.8446</td>\n",
       "      <td id=\"T_bb51a_row17_col8\" class=\"data row17 col8\" >0.3850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row18\" class=\"row_heading level0 row18\" >grand_means</th>\n",
       "      <td id=\"T_bb51a_row18_col0\" class=\"data row18 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_bb51a_row18_col1\" class=\"data row18 col1\" >0.9564</td>\n",
       "      <td id=\"T_bb51a_row18_col2\" class=\"data row18 col2\" >0.6941</td>\n",
       "      <td id=\"T_bb51a_row18_col3\" class=\"data row18 col3\" >17.0350</td>\n",
       "      <td id=\"T_bb51a_row18_col4\" class=\"data row18 col4\" >17.4117</td>\n",
       "      <td id=\"T_bb51a_row18_col5\" class=\"data row18 col5\" >0.0958</td>\n",
       "      <td id=\"T_bb51a_row18_col6\" class=\"data row18 col6\" >0.1005</td>\n",
       "      <td id=\"T_bb51a_row18_col7\" class=\"data row18 col7\" >-12.4156</td>\n",
       "      <td id=\"T_bb51a_row18_col8\" class=\"data row18 col8\" >0.3650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row19\" class=\"row_heading level0 row19\" >croston</th>\n",
       "      <td id=\"T_bb51a_row19_col0\" class=\"data row19 col0\" >Croston</td>\n",
       "      <td id=\"T_bb51a_row19_col1\" class=\"data row19 col1\" >1.0575</td>\n",
       "      <td id=\"T_bb51a_row19_col2\" class=\"data row19 col2\" >0.7638</td>\n",
       "      <td id=\"T_bb51a_row19_col3\" class=\"data row19 col3\" >18.9473</td>\n",
       "      <td id=\"T_bb51a_row19_col4\" class=\"data row19 col4\" >19.2428</td>\n",
       "      <td id=\"T_bb51a_row19_col5\" class=\"data row19 col5\" >0.1066</td>\n",
       "      <td id=\"T_bb51a_row19_col6\" class=\"data row19 col6\" >0.1127</td>\n",
       "      <td id=\"T_bb51a_row19_col7\" class=\"data row19 col7\" >-18.1139</td>\n",
       "      <td id=\"T_bb51a_row19_col8\" class=\"data row19 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row20\" class=\"row_heading level0 row20\" >ada_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row20_col0\" class=\"data row20 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row20_col1\" class=\"data row20 col1\" >1.0602</td>\n",
       "      <td id=\"T_bb51a_row20_col2\" class=\"data row20 col2\" >0.8171</td>\n",
       "      <td id=\"T_bb51a_row20_col3\" class=\"data row20 col3\" >19.1293</td>\n",
       "      <td id=\"T_bb51a_row20_col4\" class=\"data row20 col4\" >20.6233</td>\n",
       "      <td id=\"T_bb51a_row20_col5\" class=\"data row20 col5\" >0.1096</td>\n",
       "      <td id=\"T_bb51a_row20_col6\" class=\"data row20 col6\" >0.1133</td>\n",
       "      <td id=\"T_bb51a_row20_col7\" class=\"data row20 col7\" >-22.3527</td>\n",
       "      <td id=\"T_bb51a_row20_col8\" class=\"data row20 col8\" >0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row21\" class=\"row_heading level0 row21\" >naive</th>\n",
       "      <td id=\"T_bb51a_row21_col0\" class=\"data row21 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_bb51a_row21_col1\" class=\"data row21 col1\" >1.0758</td>\n",
       "      <td id=\"T_bb51a_row21_col2\" class=\"data row21 col2\" >0.8791</td>\n",
       "      <td id=\"T_bb51a_row21_col3\" class=\"data row21 col3\" >19.8000</td>\n",
       "      <td id=\"T_bb51a_row21_col4\" class=\"data row21 col4\" >22.4123</td>\n",
       "      <td id=\"T_bb51a_row21_col5\" class=\"data row21 col5\" >0.1131</td>\n",
       "      <td id=\"T_bb51a_row21_col6\" class=\"data row21 col6\" >0.1221</td>\n",
       "      <td id=\"T_bb51a_row21_col7\" class=\"data row21 col7\" >-37.2595</td>\n",
       "      <td id=\"T_bb51a_row21_col8\" class=\"data row21 col8\" >0.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row22\" class=\"row_heading level0 row22\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row22_col0\" class=\"data row22 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row22_col1\" class=\"data row22 col1\" >1.1371</td>\n",
       "      <td id=\"T_bb51a_row22_col2\" class=\"data row22 col2\" >0.8872</td>\n",
       "      <td id=\"T_bb51a_row22_col3\" class=\"data row22 col3\" >20.6059</td>\n",
       "      <td id=\"T_bb51a_row22_col4\" class=\"data row22 col4\" >22.4424</td>\n",
       "      <td id=\"T_bb51a_row22_col5\" class=\"data row22 col5\" >0.1180</td>\n",
       "      <td id=\"T_bb51a_row22_col6\" class=\"data row22 col6\" >0.1235</td>\n",
       "      <td id=\"T_bb51a_row22_col7\" class=\"data row22 col7\" >-28.8242</td>\n",
       "      <td id=\"T_bb51a_row22_col8\" class=\"data row22 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bb51a_level0_row23\" class=\"row_heading level0 row23\" >dt_cds_dt</th>\n",
       "      <td id=\"T_bb51a_row23_col0\" class=\"data row23 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_bb51a_row23_col1\" class=\"data row23 col1\" >1.5260</td>\n",
       "      <td id=\"T_bb51a_row23_col2\" class=\"data row23 col2\" >1.1118</td>\n",
       "      <td id=\"T_bb51a_row23_col3\" class=\"data row23 col3\" >27.1672</td>\n",
       "      <td id=\"T_bb51a_row23_col4\" class=\"data row23 col4\" >27.8609</td>\n",
       "      <td id=\"T_bb51a_row23_col5\" class=\"data row23 col5\" >0.1545</td>\n",
       "      <td id=\"T_bb51a_row23_col6\" class=\"data row23 col6\" >0.1613</td>\n",
       "      <td id=\"T_bb51a_row23_col7\" class=\"data row23 col7\" >-32.0679</td>\n",
       "      <td id=\"T_bb51a_row23_col8\" class=\"data row23 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc72fa080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ce8a_row25_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ce8a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7ce8a_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_7ce8a_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7ce8a_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_7ce8a_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_7ce8a_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_7ce8a_row1_col1\" class=\"data row1 col1\" >AverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_7ce8a_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_7ce8a_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_7ce8a_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_7ce8a_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_7ce8a_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_7ce8a_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_7ce8a_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_7ce8a_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_7ce8a_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_7ce8a_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_7ce8a_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_7ce8a_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_7ce8a_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_7ce8a_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_7ce8a_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_7ce8a_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_7ce8a_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_7ce8a_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_7ce8a_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_7ce8a_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_7ce8a_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_7ce8a_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_7ce8a_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_7ce8a_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_7ce8a_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_7ce8a_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_7ce8a_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_7ce8a_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_7ce8a_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_7ce8a_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_7ce8a_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_7ce8a_row17_col1\" class=\"data row17 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_7ce8a_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_7ce8a_row18_col1\" class=\"data row18 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_7ce8a_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_7ce8a_row19_col1\" class=\"data row19 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_7ce8a_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_7ce8a_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_7ce8a_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_7ce8a_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_7ce8a_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_7ce8a_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_7ce8a_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_7ce8a_row23_col1\" class=\"data row23 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_7ce8a_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_7ce8a_row24_col1\" class=\"data row24 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_7ce8a_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_7ce8a_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_7ce8a_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_7ce8a_row26_col1\" class=\"data row26 col1\" >mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_7ce8a_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_7ce8a_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_7ce8a_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_7ce8a_row28_col1\" class=\"data row28 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_7ce8a_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_7ce8a_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_7ce8a_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_7ce8a_row30_col1\" class=\"data row30 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_7ce8a_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_7ce8a_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_7ce8a_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_7ce8a_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_7ce8a_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_7ce8a_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_7ce8a_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_7ce8a_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_7ce8a_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_7ce8a_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ce8a_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_7ce8a_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_7ce8a_row36_col1\" class=\"data row36 col1\" >2ad1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc715a980>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6cda7 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6cda7_row0_col0, #T_6cda7_row1_col0, #T_6cda7_row1_col1, #T_6cda7_row1_col2, #T_6cda7_row1_col3, #T_6cda7_row1_col4, #T_6cda7_row1_col5, #T_6cda7_row1_col6, #T_6cda7_row1_col7, #T_6cda7_row2_col0, #T_6cda7_row2_col1, #T_6cda7_row2_col2, #T_6cda7_row2_col3, #T_6cda7_row2_col4, #T_6cda7_row2_col5, #T_6cda7_row2_col6, #T_6cda7_row2_col7, #T_6cda7_row3_col0, #T_6cda7_row3_col1, #T_6cda7_row3_col2, #T_6cda7_row3_col3, #T_6cda7_row3_col4, #T_6cda7_row3_col5, #T_6cda7_row3_col6, #T_6cda7_row3_col7, #T_6cda7_row4_col0, #T_6cda7_row4_col1, #T_6cda7_row4_col2, #T_6cda7_row4_col3, #T_6cda7_row4_col4, #T_6cda7_row4_col5, #T_6cda7_row4_col6, #T_6cda7_row4_col7, #T_6cda7_row5_col0, #T_6cda7_row5_col1, #T_6cda7_row5_col2, #T_6cda7_row5_col3, #T_6cda7_row5_col4, #T_6cda7_row5_col5, #T_6cda7_row5_col6, #T_6cda7_row5_col7, #T_6cda7_row6_col0, #T_6cda7_row6_col1, #T_6cda7_row6_col2, #T_6cda7_row6_col3, #T_6cda7_row6_col4, #T_6cda7_row6_col5, #T_6cda7_row6_col6, #T_6cda7_row6_col7, #T_6cda7_row7_col0, #T_6cda7_row7_col1, #T_6cda7_row7_col2, #T_6cda7_row7_col3, #T_6cda7_row7_col4, #T_6cda7_row7_col5, #T_6cda7_row7_col6, #T_6cda7_row7_col7, #T_6cda7_row8_col0, #T_6cda7_row8_col1, #T_6cda7_row8_col2, #T_6cda7_row8_col3, #T_6cda7_row8_col4, #T_6cda7_row8_col5, #T_6cda7_row8_col6, #T_6cda7_row8_col7, #T_6cda7_row9_col0, #T_6cda7_row9_col1, #T_6cda7_row9_col2, #T_6cda7_row9_col3, #T_6cda7_row9_col4, #T_6cda7_row9_col5, #T_6cda7_row9_col6, #T_6cda7_row9_col7, #T_6cda7_row10_col0, #T_6cda7_row10_col1, #T_6cda7_row10_col2, #T_6cda7_row10_col3, #T_6cda7_row10_col4, #T_6cda7_row10_col5, #T_6cda7_row10_col6, #T_6cda7_row10_col7, #T_6cda7_row11_col0, #T_6cda7_row11_col1, #T_6cda7_row11_col2, #T_6cda7_row11_col3, #T_6cda7_row11_col4, #T_6cda7_row11_col5, #T_6cda7_row11_col6, #T_6cda7_row11_col7, #T_6cda7_row12_col0, #T_6cda7_row12_col1, #T_6cda7_row12_col2, #T_6cda7_row12_col3, #T_6cda7_row12_col4, #T_6cda7_row12_col5, #T_6cda7_row12_col6, #T_6cda7_row12_col7, #T_6cda7_row13_col0, #T_6cda7_row13_col1, #T_6cda7_row13_col2, #T_6cda7_row13_col3, #T_6cda7_row13_col4, #T_6cda7_row13_col5, #T_6cda7_row13_col6, #T_6cda7_row13_col7, #T_6cda7_row14_col0, #T_6cda7_row14_col1, #T_6cda7_row14_col2, #T_6cda7_row14_col3, #T_6cda7_row14_col4, #T_6cda7_row14_col5, #T_6cda7_row14_col6, #T_6cda7_row14_col7, #T_6cda7_row15_col0, #T_6cda7_row15_col1, #T_6cda7_row15_col2, #T_6cda7_row15_col3, #T_6cda7_row15_col4, #T_6cda7_row15_col5, #T_6cda7_row15_col6, #T_6cda7_row15_col7, #T_6cda7_row16_col0, #T_6cda7_row16_col1, #T_6cda7_row16_col2, #T_6cda7_row16_col3, #T_6cda7_row16_col4, #T_6cda7_row16_col5, #T_6cda7_row16_col6, #T_6cda7_row16_col7, #T_6cda7_row17_col0, #T_6cda7_row17_col1, #T_6cda7_row17_col2, #T_6cda7_row17_col3, #T_6cda7_row17_col4, #T_6cda7_row17_col5, #T_6cda7_row17_col6, #T_6cda7_row17_col7, #T_6cda7_row18_col0, #T_6cda7_row18_col1, #T_6cda7_row18_col2, #T_6cda7_row18_col3, #T_6cda7_row18_col4, #T_6cda7_row18_col5, #T_6cda7_row18_col6, #T_6cda7_row18_col7, #T_6cda7_row19_col0, #T_6cda7_row19_col1, #T_6cda7_row19_col2, #T_6cda7_row19_col3, #T_6cda7_row19_col4, #T_6cda7_row19_col5, #T_6cda7_row19_col6, #T_6cda7_row19_col7, #T_6cda7_row20_col0, #T_6cda7_row20_col1, #T_6cda7_row20_col2, #T_6cda7_row20_col3, #T_6cda7_row20_col4, #T_6cda7_row20_col5, #T_6cda7_row20_col6, #T_6cda7_row20_col7, #T_6cda7_row21_col0, #T_6cda7_row21_col1, #T_6cda7_row21_col2, #T_6cda7_row21_col3, #T_6cda7_row21_col4, #T_6cda7_row21_col5, #T_6cda7_row21_col6, #T_6cda7_row21_col7, #T_6cda7_row22_col0, #T_6cda7_row22_col1, #T_6cda7_row22_col2, #T_6cda7_row22_col3, #T_6cda7_row22_col4, #T_6cda7_row22_col5, #T_6cda7_row22_col6, #T_6cda7_row22_col7, #T_6cda7_row23_col0, #T_6cda7_row23_col1, #T_6cda7_row23_col2, #T_6cda7_row23_col3, #T_6cda7_row23_col4, #T_6cda7_row23_col5, #T_6cda7_row23_col6, #T_6cda7_row23_col7, #T_6cda7_row24_col0, #T_6cda7_row24_col1, #T_6cda7_row24_col2, #T_6cda7_row24_col3, #T_6cda7_row24_col4, #T_6cda7_row24_col5, #T_6cda7_row24_col6, #T_6cda7_row24_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6cda7_row0_col1, #T_6cda7_row0_col2, #T_6cda7_row0_col3, #T_6cda7_row0_col4, #T_6cda7_row0_col5, #T_6cda7_row0_col6, #T_6cda7_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_6cda7_row0_col8, #T_6cda7_row1_col8, #T_6cda7_row2_col8, #T_6cda7_row3_col8, #T_6cda7_row4_col8, #T_6cda7_row5_col8, #T_6cda7_row6_col8, #T_6cda7_row7_col8, #T_6cda7_row8_col8, #T_6cda7_row10_col8, #T_6cda7_row11_col8, #T_6cda7_row12_col8, #T_6cda7_row13_col8, #T_6cda7_row14_col8, #T_6cda7_row15_col8, #T_6cda7_row16_col8, #T_6cda7_row18_col8, #T_6cda7_row19_col8, #T_6cda7_row20_col8, #T_6cda7_row21_col8, #T_6cda7_row22_col8, #T_6cda7_row23_col8, #T_6cda7_row24_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_6cda7_row9_col8, #T_6cda7_row17_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6cda7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6cda7_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6cda7_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_6cda7_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_6cda7_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_6cda7_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_6cda7_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_6cda7_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_6cda7_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_6cda7_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row0\" class=\"row_heading level0 row0\" >theta</th>\n",
       "      <td id=\"T_6cda7_row0_col0\" class=\"data row0 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_6cda7_row0_col1\" class=\"data row0 col1\" >0.6330</td>\n",
       "      <td id=\"T_6cda7_row0_col2\" class=\"data row0 col2\" >0.5571</td>\n",
       "      <td id=\"T_6cda7_row0_col3\" class=\"data row0 col3\" >7.4382</td>\n",
       "      <td id=\"T_6cda7_row0_col4\" class=\"data row0 col4\" >8.9411</td>\n",
       "      <td id=\"T_6cda7_row0_col5\" class=\"data row0 col5\" >0.1606</td>\n",
       "      <td id=\"T_6cda7_row0_col6\" class=\"data row0 col6\" >0.1761</td>\n",
       "      <td id=\"T_6cda7_row0_col7\" class=\"data row0 col7\" >0.6547</td>\n",
       "      <td id=\"T_6cda7_row0_col8\" class=\"data row0 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row1\" class=\"row_heading level0 row1\" >arima</th>\n",
       "      <td id=\"T_6cda7_row1_col0\" class=\"data row1 col0\" >ARIMA</td>\n",
       "      <td id=\"T_6cda7_row1_col1\" class=\"data row1 col1\" >0.6521</td>\n",
       "      <td id=\"T_6cda7_row1_col2\" class=\"data row1 col2\" >0.5639</td>\n",
       "      <td id=\"T_6cda7_row1_col3\" class=\"data row1 col3\" >7.7906</td>\n",
       "      <td id=\"T_6cda7_row1_col4\" class=\"data row1 col4\" >9.2704</td>\n",
       "      <td id=\"T_6cda7_row1_col5\" class=\"data row1 col5\" >0.1831</td>\n",
       "      <td id=\"T_6cda7_row1_col6\" class=\"data row1 col6\" >0.2186</td>\n",
       "      <td id=\"T_6cda7_row1_col7\" class=\"data row1 col7\" >0.4788</td>\n",
       "      <td id=\"T_6cda7_row1_col8\" class=\"data row1 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row2\" class=\"row_heading level0 row2\" >exp_smooth</th>\n",
       "      <td id=\"T_6cda7_row2_col0\" class=\"data row2 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_6cda7_row2_col1\" class=\"data row2 col1\" >0.6750</td>\n",
       "      <td id=\"T_6cda7_row2_col2\" class=\"data row2 col2\" >0.5973</td>\n",
       "      <td id=\"T_6cda7_row2_col3\" class=\"data row2 col3\" >8.0163</td>\n",
       "      <td id=\"T_6cda7_row2_col4\" class=\"data row2 col4\" >9.7197</td>\n",
       "      <td id=\"T_6cda7_row2_col5\" class=\"data row2 col5\" >0.1647</td>\n",
       "      <td id=\"T_6cda7_row2_col6\" class=\"data row2 col6\" >0.1771</td>\n",
       "      <td id=\"T_6cda7_row2_col7\" class=\"data row2 col7\" >0.5184</td>\n",
       "      <td id=\"T_6cda7_row2_col8\" class=\"data row2 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row3\" class=\"row_heading level0 row3\" >ets</th>\n",
       "      <td id=\"T_6cda7_row3_col0\" class=\"data row3 col0\" >ETS</td>\n",
       "      <td id=\"T_6cda7_row3_col1\" class=\"data row3 col1\" >0.6750</td>\n",
       "      <td id=\"T_6cda7_row3_col2\" class=\"data row3 col2\" >0.5973</td>\n",
       "      <td id=\"T_6cda7_row3_col3\" class=\"data row3 col3\" >8.0163</td>\n",
       "      <td id=\"T_6cda7_row3_col4\" class=\"data row3 col4\" >9.7200</td>\n",
       "      <td id=\"T_6cda7_row3_col5\" class=\"data row3 col5\" >0.1647</td>\n",
       "      <td id=\"T_6cda7_row3_col6\" class=\"data row3 col6\" >0.1771</td>\n",
       "      <td id=\"T_6cda7_row3_col7\" class=\"data row3 col7\" >0.5184</td>\n",
       "      <td id=\"T_6cda7_row3_col8\" class=\"data row3 col8\" >0.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row4\" class=\"row_heading level0 row4\" >snaive</th>\n",
       "      <td id=\"T_6cda7_row4_col0\" class=\"data row4 col0\" >Seasonal Naive Forecaster</td>\n",
       "      <td id=\"T_6cda7_row4_col1\" class=\"data row4 col1\" >0.6857</td>\n",
       "      <td id=\"T_6cda7_row4_col2\" class=\"data row4 col2\" >0.6097</td>\n",
       "      <td id=\"T_6cda7_row4_col3\" class=\"data row4 col3\" >8.1437</td>\n",
       "      <td id=\"T_6cda7_row4_col4\" class=\"data row4 col4\" >9.9031</td>\n",
       "      <td id=\"T_6cda7_row4_col5\" class=\"data row4 col5\" >0.1906</td>\n",
       "      <td id=\"T_6cda7_row4_col6\" class=\"data row4 col6\" >0.2230</td>\n",
       "      <td id=\"T_6cda7_row4_col7\" class=\"data row4 col7\" >0.5145</td>\n",
       "      <td id=\"T_6cda7_row4_col8\" class=\"data row4 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row5\" class=\"row_heading level0 row5\" >stlf</th>\n",
       "      <td id=\"T_6cda7_row5_col0\" class=\"data row5 col0\" >STLF</td>\n",
       "      <td id=\"T_6cda7_row5_col1\" class=\"data row5 col1\" >0.7588</td>\n",
       "      <td id=\"T_6cda7_row5_col2\" class=\"data row5 col2\" >0.6081</td>\n",
       "      <td id=\"T_6cda7_row5_col3\" class=\"data row5 col3\" >9.0437</td>\n",
       "      <td id=\"T_6cda7_row5_col4\" class=\"data row5 col4\" >9.9835</td>\n",
       "      <td id=\"T_6cda7_row5_col5\" class=\"data row5 col5\" >0.2203</td>\n",
       "      <td id=\"T_6cda7_row5_col6\" class=\"data row5 col6\" >0.2561</td>\n",
       "      <td id=\"T_6cda7_row5_col7\" class=\"data row5 col7\" >0.4092</td>\n",
       "      <td id=\"T_6cda7_row5_col8\" class=\"data row5 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row6\" class=\"row_heading level0 row6\" >ada_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row6_col0\" class=\"data row6 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row6_col1\" class=\"data row6 col1\" >1.1152</td>\n",
       "      <td id=\"T_6cda7_row6_col2\" class=\"data row6 col2\" >1.0540</td>\n",
       "      <td id=\"T_6cda7_row6_col3\" class=\"data row6 col3\" >13.3629</td>\n",
       "      <td id=\"T_6cda7_row6_col4\" class=\"data row6 col4\" >17.3858</td>\n",
       "      <td id=\"T_6cda7_row6_col5\" class=\"data row6 col5\" >0.2551</td>\n",
       "      <td id=\"T_6cda7_row6_col6\" class=\"data row6 col6\" >0.3411</td>\n",
       "      <td id=\"T_6cda7_row6_col7\" class=\"data row6 col7\" >-0.9559</td>\n",
       "      <td id=\"T_6cda7_row6_col8\" class=\"data row6 col8\" >0.1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row7\" class=\"row_heading level0 row7\" >knn_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row7_col0\" class=\"data row7 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row7_col1\" class=\"data row7 col1\" >1.1592</td>\n",
       "      <td id=\"T_6cda7_row7_col2\" class=\"data row7 col2\" >1.1410</td>\n",
       "      <td id=\"T_6cda7_row7_col3\" class=\"data row7 col3\" >13.7031</td>\n",
       "      <td id=\"T_6cda7_row7_col4\" class=\"data row7 col4\" >18.3938</td>\n",
       "      <td id=\"T_6cda7_row7_col5\" class=\"data row7 col5\" >0.2455</td>\n",
       "      <td id=\"T_6cda7_row7_col6\" class=\"data row7 col6\" >0.2935</td>\n",
       "      <td id=\"T_6cda7_row7_col7\" class=\"data row7 col7\" >-0.5212</td>\n",
       "      <td id=\"T_6cda7_row7_col8\" class=\"data row7 col8\" >0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row8\" class=\"row_heading level0 row8\" >grand_means</th>\n",
       "      <td id=\"T_6cda7_row8_col0\" class=\"data row8 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_6cda7_row8_col1\" class=\"data row8 col1\" >1.1696</td>\n",
       "      <td id=\"T_6cda7_row8_col2\" class=\"data row8 col2\" >1.2228</td>\n",
       "      <td id=\"T_6cda7_row8_col3\" class=\"data row8 col3\" >13.7691</td>\n",
       "      <td id=\"T_6cda7_row8_col4\" class=\"data row8 col4\" >19.5373</td>\n",
       "      <td id=\"T_6cda7_row8_col5\" class=\"data row8 col5\" >0.2319</td>\n",
       "      <td id=\"T_6cda7_row8_col6\" class=\"data row8 col6\" >0.2863</td>\n",
       "      <td id=\"T_6cda7_row8_col7\" class=\"data row8 col7\" >-0.6049</td>\n",
       "      <td id=\"T_6cda7_row8_col8\" class=\"data row8 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row9\" class=\"row_heading level0 row9\" >croston</th>\n",
       "      <td id=\"T_6cda7_row9_col0\" class=\"data row9 col0\" >Croston</td>\n",
       "      <td id=\"T_6cda7_row9_col1\" class=\"data row9 col1\" >1.1898</td>\n",
       "      <td id=\"T_6cda7_row9_col2\" class=\"data row9 col2\" >1.2626</td>\n",
       "      <td id=\"T_6cda7_row9_col3\" class=\"data row9 col3\" >14.0106</td>\n",
       "      <td id=\"T_6cda7_row9_col4\" class=\"data row9 col4\" >20.2040</td>\n",
       "      <td id=\"T_6cda7_row9_col5\" class=\"data row9 col5\" >0.2319</td>\n",
       "      <td id=\"T_6cda7_row9_col6\" class=\"data row9 col6\" >0.2923</td>\n",
       "      <td id=\"T_6cda7_row9_col7\" class=\"data row9 col7\" >-0.7291</td>\n",
       "      <td id=\"T_6cda7_row9_col8\" class=\"data row9 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row10\" class=\"row_heading level0 row10\" >et_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row10_col0\" class=\"data row10 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row10_col1\" class=\"data row10 col1\" >1.2070</td>\n",
       "      <td id=\"T_6cda7_row10_col2\" class=\"data row10 col2\" >1.1906</td>\n",
       "      <td id=\"T_6cda7_row10_col3\" class=\"data row10 col3\" >14.3232</td>\n",
       "      <td id=\"T_6cda7_row10_col4\" class=\"data row10 col4\" >19.3034</td>\n",
       "      <td id=\"T_6cda7_row10_col5\" class=\"data row10 col5\" >0.2548</td>\n",
       "      <td id=\"T_6cda7_row10_col6\" class=\"data row10 col6\" >0.3218</td>\n",
       "      <td id=\"T_6cda7_row10_col7\" class=\"data row10 col7\" >-0.7978</td>\n",
       "      <td id=\"T_6cda7_row10_col8\" class=\"data row10 col8\" >0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row11\" class=\"row_heading level0 row11\" >br_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row11_col0\" class=\"data row11 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row11_col1\" class=\"data row11 col1\" >1.2082</td>\n",
       "      <td id=\"T_6cda7_row11_col2\" class=\"data row11 col2\" >1.2010</td>\n",
       "      <td id=\"T_6cda7_row11_col3\" class=\"data row11 col3\" >14.3147</td>\n",
       "      <td id=\"T_6cda7_row11_col4\" class=\"data row11 col4\" >19.3804</td>\n",
       "      <td id=\"T_6cda7_row11_col5\" class=\"data row11 col5\" >0.2529</td>\n",
       "      <td id=\"T_6cda7_row11_col6\" class=\"data row11 col6\" >0.3153</td>\n",
       "      <td id=\"T_6cda7_row11_col7\" class=\"data row11 col7\" >-0.7079</td>\n",
       "      <td id=\"T_6cda7_row11_col8\" class=\"data row11 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row12\" class=\"row_heading level0 row12\" >rf_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row12_col0\" class=\"data row12 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row12_col1\" class=\"data row12 col1\" >1.2228</td>\n",
       "      <td id=\"T_6cda7_row12_col2\" class=\"data row12 col2\" >1.1185</td>\n",
       "      <td id=\"T_6cda7_row12_col3\" class=\"data row12 col3\" >14.5230</td>\n",
       "      <td id=\"T_6cda7_row12_col4\" class=\"data row12 col4\" >18.1473</td>\n",
       "      <td id=\"T_6cda7_row12_col5\" class=\"data row12 col5\" >0.2733</td>\n",
       "      <td id=\"T_6cda7_row12_col6\" class=\"data row12 col6\" >0.3379</td>\n",
       "      <td id=\"T_6cda7_row12_col7\" class=\"data row12 col7\" >-0.6049</td>\n",
       "      <td id=\"T_6cda7_row12_col8\" class=\"data row12 col8\" >0.2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row13\" class=\"row_heading level0 row13\" >dt_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row13_col0\" class=\"data row13 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row13_col1\" class=\"data row13 col1\" >1.2357</td>\n",
       "      <td id=\"T_6cda7_row13_col2\" class=\"data row13 col2\" >1.0835</td>\n",
       "      <td id=\"T_6cda7_row13_col3\" class=\"data row13 col3\" >14.7208</td>\n",
       "      <td id=\"T_6cda7_row13_col4\" class=\"data row13 col4\" >17.7445</td>\n",
       "      <td id=\"T_6cda7_row13_col5\" class=\"data row13 col5\" >0.2904</td>\n",
       "      <td id=\"T_6cda7_row13_col6\" class=\"data row13 col6\" >0.3780</td>\n",
       "      <td id=\"T_6cda7_row13_col7\" class=\"data row13 col7\" >-0.7839</td>\n",
       "      <td id=\"T_6cda7_row13_col8\" class=\"data row13 col8\" >0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row14\" class=\"row_heading level0 row14\" >omp_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row14_col0\" class=\"data row14 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row14_col1\" class=\"data row14 col1\" >1.2410</td>\n",
       "      <td id=\"T_6cda7_row14_col2\" class=\"data row14 col2\" >1.1755</td>\n",
       "      <td id=\"T_6cda7_row14_col3\" class=\"data row14 col3\" >14.6612</td>\n",
       "      <td id=\"T_6cda7_row14_col4\" class=\"data row14 col4\" >18.8777</td>\n",
       "      <td id=\"T_6cda7_row14_col5\" class=\"data row14 col5\" >0.2681</td>\n",
       "      <td id=\"T_6cda7_row14_col6\" class=\"data row14 col6\" >0.3229</td>\n",
       "      <td id=\"T_6cda7_row14_col7\" class=\"data row14 col7\" >-0.5460</td>\n",
       "      <td id=\"T_6cda7_row14_col8\" class=\"data row14 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row15\" class=\"row_heading level0 row15\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row15_col0\" class=\"data row15 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row15_col1\" class=\"data row15 col1\" >1.2918</td>\n",
       "      <td id=\"T_6cda7_row15_col2\" class=\"data row15 col2\" >1.2892</td>\n",
       "      <td id=\"T_6cda7_row15_col3\" class=\"data row15 col3\" >15.2759</td>\n",
       "      <td id=\"T_6cda7_row15_col4\" class=\"data row15 col4\" >20.7287</td>\n",
       "      <td id=\"T_6cda7_row15_col5\" class=\"data row15 col5\" >0.2699</td>\n",
       "      <td id=\"T_6cda7_row15_col6\" class=\"data row15 col6\" >0.3380</td>\n",
       "      <td id=\"T_6cda7_row15_col7\" class=\"data row15 col7\" >-0.8834</td>\n",
       "      <td id=\"T_6cda7_row15_col8\" class=\"data row15 col8\" >0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row16\" class=\"row_heading level0 row16\" >naive</th>\n",
       "      <td id=\"T_6cda7_row16_col0\" class=\"data row16 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_6cda7_row16_col1\" class=\"data row16 col1\" >1.3103</td>\n",
       "      <td id=\"T_6cda7_row16_col2\" class=\"data row16 col2\" >1.3439</td>\n",
       "      <td id=\"T_6cda7_row16_col3\" class=\"data row16 col3\" >15.3928</td>\n",
       "      <td id=\"T_6cda7_row16_col4\" class=\"data row16 col4\" >21.4197</td>\n",
       "      <td id=\"T_6cda7_row16_col5\" class=\"data row16 col5\" >0.2588</td>\n",
       "      <td id=\"T_6cda7_row16_col6\" class=\"data row16 col6\" >0.3301</td>\n",
       "      <td id=\"T_6cda7_row16_col7\" class=\"data row16 col7\" >-0.9146</td>\n",
       "      <td id=\"T_6cda7_row16_col8\" class=\"data row16 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row17\" class=\"row_heading level0 row17\" >polytrend</th>\n",
       "      <td id=\"T_6cda7_row17_col0\" class=\"data row17 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_6cda7_row17_col1\" class=\"data row17 col1\" >1.3452</td>\n",
       "      <td id=\"T_6cda7_row17_col2\" class=\"data row17 col2\" >1.3222</td>\n",
       "      <td id=\"T_6cda7_row17_col3\" class=\"data row17 col3\" >15.9225</td>\n",
       "      <td id=\"T_6cda7_row17_col4\" class=\"data row17 col4\" >21.2841</td>\n",
       "      <td id=\"T_6cda7_row17_col5\" class=\"data row17 col5\" >0.2854</td>\n",
       "      <td id=\"T_6cda7_row17_col6\" class=\"data row17 col6\" >0.3604</td>\n",
       "      <td id=\"T_6cda7_row17_col7\" class=\"data row17 col7\" >-1.0067</td>\n",
       "      <td id=\"T_6cda7_row17_col8\" class=\"data row17 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row18\" class=\"row_heading level0 row18\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row18_col0\" class=\"data row18 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row18_col1\" class=\"data row18 col1\" >1.4424</td>\n",
       "      <td id=\"T_6cda7_row18_col2\" class=\"data row18 col2\" >1.2735</td>\n",
       "      <td id=\"T_6cda7_row18_col3\" class=\"data row18 col3\" >17.1317</td>\n",
       "      <td id=\"T_6cda7_row18_col4\" class=\"data row18 col4\" >20.6893</td>\n",
       "      <td id=\"T_6cda7_row18_col5\" class=\"data row18 col5\" >0.3324</td>\n",
       "      <td id=\"T_6cda7_row18_col6\" class=\"data row18 col6\" >0.4281</td>\n",
       "      <td id=\"T_6cda7_row18_col7\" class=\"data row18 col7\" >-1.1273</td>\n",
       "      <td id=\"T_6cda7_row18_col8\" class=\"data row18 col8\" >0.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row19\" class=\"row_heading level0 row19\" >en_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row19_col0\" class=\"data row19 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row19_col1\" class=\"data row19 col1\" >3.3925</td>\n",
       "      <td id=\"T_6cda7_row19_col2\" class=\"data row19 col2\" >3.6231</td>\n",
       "      <td id=\"T_6cda7_row19_col3\" class=\"data row19 col3\" >40.6637</td>\n",
       "      <td id=\"T_6cda7_row19_col4\" class=\"data row19 col4\" >60.2730</td>\n",
       "      <td id=\"T_6cda7_row19_col5\" class=\"data row19 col5\" >1.0679</td>\n",
       "      <td id=\"T_6cda7_row19_col6\" class=\"data row19 col6\" >0.6112</td>\n",
       "      <td id=\"T_6cda7_row19_col7\" class=\"data row19 col7\" >-26.6957</td>\n",
       "      <td id=\"T_6cda7_row19_col8\" class=\"data row19 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row20\" class=\"row_heading level0 row20\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row20_col0\" class=\"data row20 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row20_col1\" class=\"data row20 col1\" >4.0769</td>\n",
       "      <td id=\"T_6cda7_row20_col2\" class=\"data row20 col2\" >4.1102</td>\n",
       "      <td id=\"T_6cda7_row20_col3\" class=\"data row20 col3\" >48.9407</td>\n",
       "      <td id=\"T_6cda7_row20_col4\" class=\"data row20 col4\" >68.5033</td>\n",
       "      <td id=\"T_6cda7_row20_col5\" class=\"data row20 col5\" >1.3070</td>\n",
       "      <td id=\"T_6cda7_row20_col6\" class=\"data row20 col6\" >0.6781</td>\n",
       "      <td id=\"T_6cda7_row20_col7\" class=\"data row20 col7\" >-36.0946</td>\n",
       "      <td id=\"T_6cda7_row20_col8\" class=\"data row20 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row21\" class=\"row_heading level0 row21\" >llar_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row21_col0\" class=\"data row21 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row21_col1\" class=\"data row21 col1\" >4.0788</td>\n",
       "      <td id=\"T_6cda7_row21_col2\" class=\"data row21 col2\" >4.1115</td>\n",
       "      <td id=\"T_6cda7_row21_col3\" class=\"data row21 col3\" >48.9632</td>\n",
       "      <td id=\"T_6cda7_row21_col4\" class=\"data row21 col4\" >68.5260</td>\n",
       "      <td id=\"T_6cda7_row21_col5\" class=\"data row21 col5\" >1.3076</td>\n",
       "      <td id=\"T_6cda7_row21_col6\" class=\"data row21 col6\" >0.6783</td>\n",
       "      <td id=\"T_6cda7_row21_col7\" class=\"data row21 col7\" >-36.1220</td>\n",
       "      <td id=\"T_6cda7_row21_col8\" class=\"data row21 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row22\" class=\"row_heading level0 row22\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row22_col0\" class=\"data row22 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row22_col1\" class=\"data row22 col1\" >5.9108</td>\n",
       "      <td id=\"T_6cda7_row22_col2\" class=\"data row22 col2\" >5.6123</td>\n",
       "      <td id=\"T_6cda7_row22_col3\" class=\"data row22 col3\" >71.1124</td>\n",
       "      <td id=\"T_6cda7_row22_col4\" class=\"data row22 col4\" >93.8682</td>\n",
       "      <td id=\"T_6cda7_row22_col5\" class=\"data row22 col5\" >1.9615</td>\n",
       "      <td id=\"T_6cda7_row22_col6\" class=\"data row22 col6\" >0.7769</td>\n",
       "      <td id=\"T_6cda7_row22_col7\" class=\"data row22 col7\" >-73.6076</td>\n",
       "      <td id=\"T_6cda7_row22_col8\" class=\"data row22 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row23\" class=\"row_heading level0 row23\" >huber_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row23_col0\" class=\"data row23 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row23_col1\" class=\"data row23 col1\" >6.7412</td>\n",
       "      <td id=\"T_6cda7_row23_col2\" class=\"data row23 col2\" >6.3450</td>\n",
       "      <td id=\"T_6cda7_row23_col3\" class=\"data row23 col3\" >81.1871</td>\n",
       "      <td id=\"T_6cda7_row23_col4\" class=\"data row23 col4\" >106.4249</td>\n",
       "      <td id=\"T_6cda7_row23_col5\" class=\"data row23 col5\" >2.2747</td>\n",
       "      <td id=\"T_6cda7_row23_col6\" class=\"data row23 col6\" >0.7789</td>\n",
       "      <td id=\"T_6cda7_row23_col7\" class=\"data row23 col7\" >-100.3905</td>\n",
       "      <td id=\"T_6cda7_row23_col8\" class=\"data row23 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6cda7_level0_row24\" class=\"row_heading level0 row24\" >lr_cds_dt</th>\n",
       "      <td id=\"T_6cda7_row24_col0\" class=\"data row24 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_6cda7_row24_col1\" class=\"data row24 col1\" >6.7986</td>\n",
       "      <td id=\"T_6cda7_row24_col2\" class=\"data row24 col2\" >6.4583</td>\n",
       "      <td id=\"T_6cda7_row24_col3\" class=\"data row24 col3\" >81.8466</td>\n",
       "      <td id=\"T_6cda7_row24_col4\" class=\"data row24 col4\" >108.1578</td>\n",
       "      <td id=\"T_6cda7_row24_col5\" class=\"data row24 col5\" >2.2829</td>\n",
       "      <td id=\"T_6cda7_row24_col6\" class=\"data row24 col6\" >0.7932</td>\n",
       "      <td id=\"T_6cda7_row24_col7\" class=\"data row24 col7\" >-100.5842</td>\n",
       "      <td id=\"T_6cda7_row24_col8\" class=\"data row24 col8\" >0.1350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc72fbca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee19a_row25_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee19a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee19a_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ee19a_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ee19a_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_ee19a_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ee19a_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ee19a_row1_col1\" class=\"data row1 col1\" >WeightedAverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ee19a_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_ee19a_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ee19a_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_ee19a_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ee19a_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_ee19a_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ee19a_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_ee19a_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ee19a_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_ee19a_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ee19a_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_ee19a_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ee19a_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_ee19a_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ee19a_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ee19a_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ee19a_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ee19a_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ee19a_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_ee19a_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ee19a_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_ee19a_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ee19a_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_ee19a_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ee19a_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_ee19a_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ee19a_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_ee19a_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ee19a_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_ee19a_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ee19a_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_ee19a_row17_col1\" class=\"data row17 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ee19a_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_ee19a_row18_col1\" class=\"data row18 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ee19a_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_ee19a_row19_col1\" class=\"data row19 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ee19a_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_ee19a_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ee19a_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_ee19a_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ee19a_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_ee19a_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ee19a_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_ee19a_row23_col1\" class=\"data row23 col1\" >[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_ee19a_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_ee19a_row24_col1\" class=\"data row24 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_ee19a_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_ee19a_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_ee19a_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_ee19a_row26_col1\" class=\"data row26 col1\" >mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_ee19a_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_ee19a_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_ee19a_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_ee19a_row28_col1\" class=\"data row28 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_ee19a_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_ee19a_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_ee19a_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_ee19a_row30_col1\" class=\"data row30 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_ee19a_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ee19a_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_ee19a_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ee19a_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_ee19a_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ee19a_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_ee19a_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ee19a_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_ee19a_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ee19a_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee19a_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_ee19a_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_ee19a_row36_col1\" class=\"data row36 col1\" >208f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc72f9810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_94883 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_94883_row0_col0, #T_94883_row0_col2, #T_94883_row0_col4, #T_94883_row0_col7, #T_94883_row1_col0, #T_94883_row1_col1, #T_94883_row1_col2, #T_94883_row1_col3, #T_94883_row1_col4, #T_94883_row1_col5, #T_94883_row1_col6, #T_94883_row2_col0, #T_94883_row2_col1, #T_94883_row2_col3, #T_94883_row2_col5, #T_94883_row2_col6, #T_94883_row2_col7, #T_94883_row3_col0, #T_94883_row3_col1, #T_94883_row3_col2, #T_94883_row3_col3, #T_94883_row3_col4, #T_94883_row3_col5, #T_94883_row3_col6, #T_94883_row3_col7, #T_94883_row4_col0, #T_94883_row4_col1, #T_94883_row4_col2, #T_94883_row4_col3, #T_94883_row4_col4, #T_94883_row4_col5, #T_94883_row4_col6, #T_94883_row4_col7, #T_94883_row5_col0, #T_94883_row5_col1, #T_94883_row5_col2, #T_94883_row5_col3, #T_94883_row5_col4, #T_94883_row5_col5, #T_94883_row5_col6, #T_94883_row5_col7, #T_94883_row6_col0, #T_94883_row6_col1, #T_94883_row6_col2, #T_94883_row6_col3, #T_94883_row6_col4, #T_94883_row6_col5, #T_94883_row6_col6, #T_94883_row6_col7, #T_94883_row7_col0, #T_94883_row7_col1, #T_94883_row7_col2, #T_94883_row7_col3, #T_94883_row7_col4, #T_94883_row7_col5, #T_94883_row7_col6, #T_94883_row7_col7, #T_94883_row8_col0, #T_94883_row8_col1, #T_94883_row8_col2, #T_94883_row8_col3, #T_94883_row8_col4, #T_94883_row8_col5, #T_94883_row8_col6, #T_94883_row8_col7, #T_94883_row9_col0, #T_94883_row9_col1, #T_94883_row9_col2, #T_94883_row9_col3, #T_94883_row9_col4, #T_94883_row9_col5, #T_94883_row9_col6, #T_94883_row9_col7, #T_94883_row10_col0, #T_94883_row10_col1, #T_94883_row10_col2, #T_94883_row10_col3, #T_94883_row10_col4, #T_94883_row10_col5, #T_94883_row10_col6, #T_94883_row10_col7, #T_94883_row11_col0, #T_94883_row11_col1, #T_94883_row11_col2, #T_94883_row11_col3, #T_94883_row11_col4, #T_94883_row11_col5, #T_94883_row11_col6, #T_94883_row11_col7, #T_94883_row12_col0, #T_94883_row12_col1, #T_94883_row12_col2, #T_94883_row12_col3, #T_94883_row12_col4, #T_94883_row12_col5, #T_94883_row12_col6, #T_94883_row12_col7, #T_94883_row13_col0, #T_94883_row13_col1, #T_94883_row13_col2, #T_94883_row13_col3, #T_94883_row13_col4, #T_94883_row13_col5, #T_94883_row13_col6, #T_94883_row13_col7, #T_94883_row14_col0, #T_94883_row14_col1, #T_94883_row14_col2, #T_94883_row14_col3, #T_94883_row14_col4, #T_94883_row14_col5, #T_94883_row14_col6, #T_94883_row14_col7, #T_94883_row15_col0, #T_94883_row15_col1, #T_94883_row15_col2, #T_94883_row15_col3, #T_94883_row15_col4, #T_94883_row15_col5, #T_94883_row15_col6, #T_94883_row15_col7, #T_94883_row16_col0, #T_94883_row16_col1, #T_94883_row16_col2, #T_94883_row16_col3, #T_94883_row16_col4, #T_94883_row16_col5, #T_94883_row16_col6, #T_94883_row16_col7, #T_94883_row17_col0, #T_94883_row17_col1, #T_94883_row17_col2, #T_94883_row17_col3, #T_94883_row17_col4, #T_94883_row17_col5, #T_94883_row17_col6, #T_94883_row17_col7, #T_94883_row18_col0, #T_94883_row18_col1, #T_94883_row18_col2, #T_94883_row18_col3, #T_94883_row18_col4, #T_94883_row18_col5, #T_94883_row18_col6, #T_94883_row18_col7, #T_94883_row19_col0, #T_94883_row19_col1, #T_94883_row19_col2, #T_94883_row19_col3, #T_94883_row19_col4, #T_94883_row19_col5, #T_94883_row19_col6, #T_94883_row19_col7, #T_94883_row20_col0, #T_94883_row20_col1, #T_94883_row20_col2, #T_94883_row20_col3, #T_94883_row20_col4, #T_94883_row20_col5, #T_94883_row20_col6, #T_94883_row20_col7, #T_94883_row21_col0, #T_94883_row21_col1, #T_94883_row21_col2, #T_94883_row21_col3, #T_94883_row21_col4, #T_94883_row21_col5, #T_94883_row21_col6, #T_94883_row21_col7, #T_94883_row22_col0, #T_94883_row22_col1, #T_94883_row22_col2, #T_94883_row22_col3, #T_94883_row22_col4, #T_94883_row22_col5, #T_94883_row22_col6, #T_94883_row22_col7, #T_94883_row23_col0, #T_94883_row23_col1, #T_94883_row23_col2, #T_94883_row23_col3, #T_94883_row23_col4, #T_94883_row23_col5, #T_94883_row23_col6, #T_94883_row23_col7, #T_94883_row24_col0, #T_94883_row24_col1, #T_94883_row24_col2, #T_94883_row24_col3, #T_94883_row24_col4, #T_94883_row24_col5, #T_94883_row24_col6, #T_94883_row24_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_94883_row0_col1, #T_94883_row0_col3, #T_94883_row0_col5, #T_94883_row0_col6, #T_94883_row1_col7, #T_94883_row2_col2, #T_94883_row2_col4 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_94883_row0_col8, #T_94883_row1_col8, #T_94883_row2_col8, #T_94883_row3_col8, #T_94883_row4_col8, #T_94883_row5_col8, #T_94883_row6_col8, #T_94883_row7_col8, #T_94883_row8_col8, #T_94883_row9_col8, #T_94883_row11_col8, #T_94883_row12_col8, #T_94883_row13_col8, #T_94883_row14_col8, #T_94883_row15_col8, #T_94883_row16_col8, #T_94883_row17_col8, #T_94883_row18_col8, #T_94883_row19_col8, #T_94883_row20_col8, #T_94883_row21_col8, #T_94883_row22_col8, #T_94883_row23_col8, #T_94883_row24_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_94883_row10_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_94883\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_94883_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_94883_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_94883_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_94883_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_94883_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_94883_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_94883_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_94883_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_94883_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row0\" class=\"row_heading level0 row0\" >exp_smooth</th>\n",
       "      <td id=\"T_94883_row0_col0\" class=\"data row0 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_94883_row0_col1\" class=\"data row0 col1\" >0.6030</td>\n",
       "      <td id=\"T_94883_row0_col2\" class=\"data row0 col2\" >0.6657</td>\n",
       "      <td id=\"T_94883_row0_col3\" class=\"data row0 col3\" >7.9298</td>\n",
       "      <td id=\"T_94883_row0_col4\" class=\"data row0 col4\" >10.7979</td>\n",
       "      <td id=\"T_94883_row0_col5\" class=\"data row0 col5\" >0.1791</td>\n",
       "      <td id=\"T_94883_row0_col6\" class=\"data row0 col6\" >0.1772</td>\n",
       "      <td id=\"T_94883_row0_col7\" class=\"data row0 col7\" >0.5267</td>\n",
       "      <td id=\"T_94883_row0_col8\" class=\"data row0 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row1\" class=\"row_heading level0 row1\" >theta</th>\n",
       "      <td id=\"T_94883_row1_col0\" class=\"data row1 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_94883_row1_col1\" class=\"data row1 col1\" >0.6408</td>\n",
       "      <td id=\"T_94883_row1_col2\" class=\"data row1 col2\" >0.6557</td>\n",
       "      <td id=\"T_94883_row1_col3\" class=\"data row1 col3\" >8.4414</td>\n",
       "      <td id=\"T_94883_row1_col4\" class=\"data row1 col4\" >10.5745</td>\n",
       "      <td id=\"T_94883_row1_col5\" class=\"data row1 col5\" >0.1814</td>\n",
       "      <td id=\"T_94883_row1_col6\" class=\"data row1 col6\" >0.1990</td>\n",
       "      <td id=\"T_94883_row1_col7\" class=\"data row1 col7\" >0.5356</td>\n",
       "      <td id=\"T_94883_row1_col8\" class=\"data row1 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row2\" class=\"row_heading level0 row2\" >arima</th>\n",
       "      <td id=\"T_94883_row2_col0\" class=\"data row2 col0\" >ARIMA</td>\n",
       "      <td id=\"T_94883_row2_col1\" class=\"data row2 col1\" >0.7019</td>\n",
       "      <td id=\"T_94883_row2_col2\" class=\"data row2 col2\" >0.6365</td>\n",
       "      <td id=\"T_94883_row2_col3\" class=\"data row2 col3\" >9.2187</td>\n",
       "      <td id=\"T_94883_row2_col4\" class=\"data row2 col4\" >10.3696</td>\n",
       "      <td id=\"T_94883_row2_col5\" class=\"data row2 col5\" >0.2109</td>\n",
       "      <td id=\"T_94883_row2_col6\" class=\"data row2 col6\" >0.2498</td>\n",
       "      <td id=\"T_94883_row2_col7\" class=\"data row2 col7\" >0.5159</td>\n",
       "      <td id=\"T_94883_row2_col8\" class=\"data row2 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row3\" class=\"row_heading level0 row3\" >snaive</th>\n",
       "      <td id=\"T_94883_row3_col0\" class=\"data row3 col0\" >Seasonal Naive Forecaster</td>\n",
       "      <td id=\"T_94883_row3_col1\" class=\"data row3 col1\" >0.7565</td>\n",
       "      <td id=\"T_94883_row3_col2\" class=\"data row3 col2\" >0.7339</td>\n",
       "      <td id=\"T_94883_row3_col3\" class=\"data row3 col3\" >9.9416</td>\n",
       "      <td id=\"T_94883_row3_col4\" class=\"data row3 col4\" >11.9057</td>\n",
       "      <td id=\"T_94883_row3_col5\" class=\"data row3 col5\" >0.2197</td>\n",
       "      <td id=\"T_94883_row3_col6\" class=\"data row3 col6\" >0.2632</td>\n",
       "      <td id=\"T_94883_row3_col7\" class=\"data row3 col7\" >0.4229</td>\n",
       "      <td id=\"T_94883_row3_col8\" class=\"data row3 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row4\" class=\"row_heading level0 row4\" >ets</th>\n",
       "      <td id=\"T_94883_row4_col0\" class=\"data row4 col0\" >ETS</td>\n",
       "      <td id=\"T_94883_row4_col1\" class=\"data row4 col1\" >0.7909</td>\n",
       "      <td id=\"T_94883_row4_col2\" class=\"data row4 col2\" >0.7869</td>\n",
       "      <td id=\"T_94883_row4_col3\" class=\"data row4 col3\" >10.3922</td>\n",
       "      <td id=\"T_94883_row4_col4\" class=\"data row4 col4\" >12.7924</td>\n",
       "      <td id=\"T_94883_row4_col5\" class=\"data row4 col5\" >0.2077</td>\n",
       "      <td id=\"T_94883_row4_col6\" class=\"data row4 col6\" >0.2380</td>\n",
       "      <td id=\"T_94883_row4_col7\" class=\"data row4 col7\" >0.3081</td>\n",
       "      <td id=\"T_94883_row4_col8\" class=\"data row4 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row5\" class=\"row_heading level0 row5\" >stlf</th>\n",
       "      <td id=\"T_94883_row5_col0\" class=\"data row5 col0\" >STLF</td>\n",
       "      <td id=\"T_94883_row5_col1\" class=\"data row5 col1\" >0.8608</td>\n",
       "      <td id=\"T_94883_row5_col2\" class=\"data row5 col2\" >0.7674</td>\n",
       "      <td id=\"T_94883_row5_col3\" class=\"data row5 col3\" >11.3115</td>\n",
       "      <td id=\"T_94883_row5_col4\" class=\"data row5 col4\" >12.4729</td>\n",
       "      <td id=\"T_94883_row5_col5\" class=\"data row5 col5\" >0.2508</td>\n",
       "      <td id=\"T_94883_row5_col6\" class=\"data row5 col6\" >0.2895</td>\n",
       "      <td id=\"T_94883_row5_col7\" class=\"data row5 col7\" >0.3447</td>\n",
       "      <td id=\"T_94883_row5_col8\" class=\"data row5 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row6\" class=\"row_heading level0 row6\" >knn_cds_dt</th>\n",
       "      <td id=\"T_94883_row6_col0\" class=\"data row6 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row6_col1\" class=\"data row6 col1\" >1.0854</td>\n",
       "      <td id=\"T_94883_row6_col2\" class=\"data row6 col2\" >1.1807</td>\n",
       "      <td id=\"T_94883_row6_col3\" class=\"data row6 col3\" >14.2708</td>\n",
       "      <td id=\"T_94883_row6_col4\" class=\"data row6 col4\" >19.1346</td>\n",
       "      <td id=\"T_94883_row6_col5\" class=\"data row6 col5\" >0.2441</td>\n",
       "      <td id=\"T_94883_row6_col6\" class=\"data row6 col6\" >0.3026</td>\n",
       "      <td id=\"T_94883_row6_col7\" class=\"data row6 col7\" >-0.4749</td>\n",
       "      <td id=\"T_94883_row6_col8\" class=\"data row6 col8\" >0.1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row7\" class=\"row_heading level0 row7\" >br_cds_dt</th>\n",
       "      <td id=\"T_94883_row7_col0\" class=\"data row7 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row7_col1\" class=\"data row7 col1\" >1.1530</td>\n",
       "      <td id=\"T_94883_row7_col2\" class=\"data row7 col2\" >1.2529</td>\n",
       "      <td id=\"T_94883_row7_col3\" class=\"data row7 col3\" >15.1585</td>\n",
       "      <td id=\"T_94883_row7_col4\" class=\"data row7 col4\" >20.3156</td>\n",
       "      <td id=\"T_94883_row7_col5\" class=\"data row7 col5\" >0.2570</td>\n",
       "      <td id=\"T_94883_row7_col6\" class=\"data row7 col6\" >0.3256</td>\n",
       "      <td id=\"T_94883_row7_col7\" class=\"data row7 col7\" >-0.6700</td>\n",
       "      <td id=\"T_94883_row7_col8\" class=\"data row7 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row8\" class=\"row_heading level0 row8\" >et_cds_dt</th>\n",
       "      <td id=\"T_94883_row8_col0\" class=\"data row8 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row8_col1\" class=\"data row8 col1\" >1.2009</td>\n",
       "      <td id=\"T_94883_row8_col2\" class=\"data row8 col2\" >1.2484</td>\n",
       "      <td id=\"T_94883_row8_col3\" class=\"data row8 col3\" >15.7782</td>\n",
       "      <td id=\"T_94883_row8_col4\" class=\"data row8 col4\" >20.2980</td>\n",
       "      <td id=\"T_94883_row8_col5\" class=\"data row8 col5\" >0.2765</td>\n",
       "      <td id=\"T_94883_row8_col6\" class=\"data row8 col6\" >0.3613</td>\n",
       "      <td id=\"T_94883_row8_col7\" class=\"data row8 col7\" >-0.7508</td>\n",
       "      <td id=\"T_94883_row8_col8\" class=\"data row8 col8\" >0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row9\" class=\"row_heading level0 row9\" >grand_means</th>\n",
       "      <td id=\"T_94883_row9_col0\" class=\"data row9 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_94883_row9_col1\" class=\"data row9 col1\" >1.2180</td>\n",
       "      <td id=\"T_94883_row9_col2\" class=\"data row9 col2\" >1.3431</td>\n",
       "      <td id=\"T_94883_row9_col3\" class=\"data row9 col3\" >16.0339</td>\n",
       "      <td id=\"T_94883_row9_col4\" class=\"data row9 col4\" >21.6799</td>\n",
       "      <td id=\"T_94883_row9_col5\" class=\"data row9 col5\" >0.2658</td>\n",
       "      <td id=\"T_94883_row9_col6\" class=\"data row9 col6\" >0.3311</td>\n",
       "      <td id=\"T_94883_row9_col7\" class=\"data row9 col7\" >-0.9211</td>\n",
       "      <td id=\"T_94883_row9_col8\" class=\"data row9 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row10\" class=\"row_heading level0 row10\" >croston</th>\n",
       "      <td id=\"T_94883_row10_col0\" class=\"data row10 col0\" >Croston</td>\n",
       "      <td id=\"T_94883_row10_col1\" class=\"data row10 col1\" >1.2417</td>\n",
       "      <td id=\"T_94883_row10_col2\" class=\"data row10 col2\" >1.3802</td>\n",
       "      <td id=\"T_94883_row10_col3\" class=\"data row10 col3\" >16.3435</td>\n",
       "      <td id=\"T_94883_row10_col4\" class=\"data row10 col4\" >22.2900</td>\n",
       "      <td id=\"T_94883_row10_col5\" class=\"data row10 col5\" >0.2675</td>\n",
       "      <td id=\"T_94883_row10_col6\" class=\"data row10 col6\" >0.3394</td>\n",
       "      <td id=\"T_94883_row10_col7\" class=\"data row10 col7\" >-1.0162</td>\n",
       "      <td id=\"T_94883_row10_col8\" class=\"data row10 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row11\" class=\"row_heading level0 row11\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_94883_row11_col0\" class=\"data row11 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row11_col1\" class=\"data row11 col1\" >1.2489</td>\n",
       "      <td id=\"T_94883_row11_col2\" class=\"data row11 col2\" >1.3720</td>\n",
       "      <td id=\"T_94883_row11_col3\" class=\"data row11 col3\" >16.4266</td>\n",
       "      <td id=\"T_94883_row11_col4\" class=\"data row11 col4\" >22.2023</td>\n",
       "      <td id=\"T_94883_row11_col5\" class=\"data row11 col5\" >0.2746</td>\n",
       "      <td id=\"T_94883_row11_col6\" class=\"data row11 col6\" >0.3515</td>\n",
       "      <td id=\"T_94883_row11_col7\" class=\"data row11 col7\" >-0.9753</td>\n",
       "      <td id=\"T_94883_row11_col8\" class=\"data row11 col8\" >0.1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row12\" class=\"row_heading level0 row12\" >omp_cds_dt</th>\n",
       "      <td id=\"T_94883_row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row12_col1\" class=\"data row12 col1\" >1.2498</td>\n",
       "      <td id=\"T_94883_row12_col2\" class=\"data row12 col2\" >1.2691</td>\n",
       "      <td id=\"T_94883_row12_col3\" class=\"data row12 col3\" >16.4417</td>\n",
       "      <td id=\"T_94883_row12_col4\" class=\"data row12 col4\" >20.5333</td>\n",
       "      <td id=\"T_94883_row12_col5\" class=\"data row12 col5\" >0.2914</td>\n",
       "      <td id=\"T_94883_row12_col6\" class=\"data row12 col6\" >0.3565</td>\n",
       "      <td id=\"T_94883_row12_col7\" class=\"data row12 col7\" >-0.6899</td>\n",
       "      <td id=\"T_94883_row12_col8\" class=\"data row12 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row13\" class=\"row_heading level0 row13\" >polytrend</th>\n",
       "      <td id=\"T_94883_row13_col0\" class=\"data row13 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_94883_row13_col1\" class=\"data row13 col1\" >1.2841</td>\n",
       "      <td id=\"T_94883_row13_col2\" class=\"data row13 col2\" >1.3930</td>\n",
       "      <td id=\"T_94883_row13_col3\" class=\"data row13 col3\" >16.8871</td>\n",
       "      <td id=\"T_94883_row13_col4\" class=\"data row13 col4\" >22.5494</td>\n",
       "      <td id=\"T_94883_row13_col5\" class=\"data row13 col5\" >0.2862</td>\n",
       "      <td id=\"T_94883_row13_col6\" class=\"data row13 col6\" >0.3677</td>\n",
       "      <td id=\"T_94883_row13_col7\" class=\"data row13 col7\" >-1.0377</td>\n",
       "      <td id=\"T_94883_row13_col8\" class=\"data row13 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row14\" class=\"row_heading level0 row14\" >rf_cds_dt</th>\n",
       "      <td id=\"T_94883_row14_col0\" class=\"data row14 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row14_col1\" class=\"data row14 col1\" >1.3112</td>\n",
       "      <td id=\"T_94883_row14_col2\" class=\"data row14 col2\" >1.2895</td>\n",
       "      <td id=\"T_94883_row14_col3\" class=\"data row14 col3\" >17.2366</td>\n",
       "      <td id=\"T_94883_row14_col4\" class=\"data row14 col4\" >20.9197</td>\n",
       "      <td id=\"T_94883_row14_col5\" class=\"data row14 col5\" >0.3160</td>\n",
       "      <td id=\"T_94883_row14_col6\" class=\"data row14 col6\" >0.4007</td>\n",
       "      <td id=\"T_94883_row14_col7\" class=\"data row14 col7\" >-0.7821</td>\n",
       "      <td id=\"T_94883_row14_col8\" class=\"data row14 col8\" >0.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row15\" class=\"row_heading level0 row15\" >naive</th>\n",
       "      <td id=\"T_94883_row15_col0\" class=\"data row15 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_94883_row15_col1\" class=\"data row15 col1\" >1.3646</td>\n",
       "      <td id=\"T_94883_row15_col2\" class=\"data row15 col2\" >1.3986</td>\n",
       "      <td id=\"T_94883_row15_col3\" class=\"data row15 col3\" >17.9751</td>\n",
       "      <td id=\"T_94883_row15_col4\" class=\"data row15 col4\" >22.5245</td>\n",
       "      <td id=\"T_94883_row15_col5\" class=\"data row15 col5\" >0.3155</td>\n",
       "      <td id=\"T_94883_row15_col6\" class=\"data row15 col6\" >0.3861</td>\n",
       "      <td id=\"T_94883_row15_col7\" class=\"data row15 col7\" >-1.1727</td>\n",
       "      <td id=\"T_94883_row15_col8\" class=\"data row15 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row16\" class=\"row_heading level0 row16\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_94883_row16_col0\" class=\"data row16 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row16_col1\" class=\"data row16 col1\" >1.3951</td>\n",
       "      <td id=\"T_94883_row16_col2\" class=\"data row16 col2\" >1.4577</td>\n",
       "      <td id=\"T_94883_row16_col3\" class=\"data row16 col3\" >18.3428</td>\n",
       "      <td id=\"T_94883_row16_col4\" class=\"data row16 col4\" >23.6176</td>\n",
       "      <td id=\"T_94883_row16_col5\" class=\"data row16 col5\" >0.3262</td>\n",
       "      <td id=\"T_94883_row16_col6\" class=\"data row16 col6\" >0.4373</td>\n",
       "      <td id=\"T_94883_row16_col7\" class=\"data row16 col7\" >-1.2428</td>\n",
       "      <td id=\"T_94883_row16_col8\" class=\"data row16 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row17\" class=\"row_heading level0 row17\" >dt_cds_dt</th>\n",
       "      <td id=\"T_94883_row17_col0\" class=\"data row17 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row17_col1\" class=\"data row17 col1\" >1.7421</td>\n",
       "      <td id=\"T_94883_row17_col2\" class=\"data row17 col2\" >1.6800</td>\n",
       "      <td id=\"T_94883_row17_col3\" class=\"data row17 col3\" >22.9308</td>\n",
       "      <td id=\"T_94883_row17_col4\" class=\"data row17 col4\" >27.1469</td>\n",
       "      <td id=\"T_94883_row17_col5\" class=\"data row17 col5\" >0.4192</td>\n",
       "      <td id=\"T_94883_row17_col6\" class=\"data row17 col6\" >0.5445</td>\n",
       "      <td id=\"T_94883_row17_col7\" class=\"data row17 col7\" >-1.9737</td>\n",
       "      <td id=\"T_94883_row17_col8\" class=\"data row17 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row18\" class=\"row_heading level0 row18\" >ada_cds_dt</th>\n",
       "      <td id=\"T_94883_row18_col0\" class=\"data row18 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row18_col1\" class=\"data row18 col1\" >1.7674</td>\n",
       "      <td id=\"T_94883_row18_col2\" class=\"data row18 col2\" >1.6870</td>\n",
       "      <td id=\"T_94883_row18_col3\" class=\"data row18 col3\" >23.2619</td>\n",
       "      <td id=\"T_94883_row18_col4\" class=\"data row18 col4\" >27.2332</td>\n",
       "      <td id=\"T_94883_row18_col5\" class=\"data row18 col5\" >0.4299</td>\n",
       "      <td id=\"T_94883_row18_col6\" class=\"data row18 col6\" >0.5729</td>\n",
       "      <td id=\"T_94883_row18_col7\" class=\"data row18 col7\" >-2.0274</td>\n",
       "      <td id=\"T_94883_row18_col8\" class=\"data row18 col8\" >0.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row19\" class=\"row_heading level0 row19\" >en_cds_dt</th>\n",
       "      <td id=\"T_94883_row19_col0\" class=\"data row19 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row19_col1\" class=\"data row19 col1\" >2.8317</td>\n",
       "      <td id=\"T_94883_row19_col2\" class=\"data row19 col2\" >2.8909</td>\n",
       "      <td id=\"T_94883_row19_col3\" class=\"data row19 col3\" >37.1616</td>\n",
       "      <td id=\"T_94883_row19_col4\" class=\"data row19 col4\" >47.2815</td>\n",
       "      <td id=\"T_94883_row19_col5\" class=\"data row19 col5\" >1.0311</td>\n",
       "      <td id=\"T_94883_row19_col6\" class=\"data row19 col6\" >0.7900</td>\n",
       "      <td id=\"T_94883_row19_col7\" class=\"data row19 col7\" >-10.7097</td>\n",
       "      <td id=\"T_94883_row19_col8\" class=\"data row19 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row20\" class=\"row_heading level0 row20\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_94883_row20_col0\" class=\"data row20 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row20_col1\" class=\"data row20 col1\" >3.4582</td>\n",
       "      <td id=\"T_94883_row20_col2\" class=\"data row20 col2\" >3.6269</td>\n",
       "      <td id=\"T_94883_row20_col3\" class=\"data row20 col3\" >45.3707</td>\n",
       "      <td id=\"T_94883_row20_col4\" class=\"data row20 col4\" >59.3982</td>\n",
       "      <td id=\"T_94883_row20_col5\" class=\"data row20 col5\" >1.2420</td>\n",
       "      <td id=\"T_94883_row20_col6\" class=\"data row20 col6\" >0.6826</td>\n",
       "      <td id=\"T_94883_row20_col7\" class=\"data row20 col7\" >-18.6333</td>\n",
       "      <td id=\"T_94883_row20_col8\" class=\"data row20 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row21\" class=\"row_heading level0 row21\" >llar_cds_dt</th>\n",
       "      <td id=\"T_94883_row21_col0\" class=\"data row21 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row21_col1\" class=\"data row21 col1\" >3.4608</td>\n",
       "      <td id=\"T_94883_row21_col2\" class=\"data row21 col2\" >3.6285</td>\n",
       "      <td id=\"T_94883_row21_col3\" class=\"data row21 col3\" >45.4043</td>\n",
       "      <td id=\"T_94883_row21_col4\" class=\"data row21 col4\" >59.4243</td>\n",
       "      <td id=\"T_94883_row21_col5\" class=\"data row21 col5\" >1.2430</td>\n",
       "      <td id=\"T_94883_row21_col6\" class=\"data row21 col6\" >0.6830</td>\n",
       "      <td id=\"T_94883_row21_col7\" class=\"data row21 col7\" >-18.6525</td>\n",
       "      <td id=\"T_94883_row21_col8\" class=\"data row21 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row22\" class=\"row_heading level0 row22\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_94883_row22_col0\" class=\"data row22 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row22_col1\" class=\"data row22 col1\" >5.6503</td>\n",
       "      <td id=\"T_94883_row22_col2\" class=\"data row22 col2\" >5.2756</td>\n",
       "      <td id=\"T_94883_row22_col3\" class=\"data row22 col3\" >74.0962</td>\n",
       "      <td id=\"T_94883_row22_col4\" class=\"data row22 col4\" >86.5325</td>\n",
       "      <td id=\"T_94883_row22_col5\" class=\"data row22 col5\" >2.0773</td>\n",
       "      <td id=\"T_94883_row22_col6\" class=\"data row22 col6\" >0.9276</td>\n",
       "      <td id=\"T_94883_row22_col7\" class=\"data row22 col7\" >-43.8848</td>\n",
       "      <td id=\"T_94883_row22_col8\" class=\"data row22 col8\" >0.1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row23\" class=\"row_heading level0 row23\" >lr_cds_dt</th>\n",
       "      <td id=\"T_94883_row23_col0\" class=\"data row23 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row23_col1\" class=\"data row23 col1\" >8.3645</td>\n",
       "      <td id=\"T_94883_row23_col2\" class=\"data row23 col2\" >8.2011</td>\n",
       "      <td id=\"T_94883_row23_col3\" class=\"data row23 col3\" >109.6626</td>\n",
       "      <td id=\"T_94883_row23_col4\" class=\"data row23 col4\" >134.6865</td>\n",
       "      <td id=\"T_94883_row23_col5\" class=\"data row23 col5\" >3.1505</td>\n",
       "      <td id=\"T_94883_row23_col6\" class=\"data row23 col6\" >0.9858</td>\n",
       "      <td id=\"T_94883_row23_col7\" class=\"data row23 col7\" >-114.7725</td>\n",
       "      <td id=\"T_94883_row23_col8\" class=\"data row23 col8\" >0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_94883_level0_row24\" class=\"row_heading level0 row24\" >huber_cds_dt</th>\n",
       "      <td id=\"T_94883_row24_col0\" class=\"data row24 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_94883_row24_col1\" class=\"data row24 col1\" >8.4824</td>\n",
       "      <td id=\"T_94883_row24_col2\" class=\"data row24 col2\" >8.2030</td>\n",
       "      <td id=\"T_94883_row24_col3\" class=\"data row24 col3\" >111.2218</td>\n",
       "      <td id=\"T_94883_row24_col4\" class=\"data row24 col4\" >134.7169</td>\n",
       "      <td id=\"T_94883_row24_col5\" class=\"data row24 col5\" >3.1870</td>\n",
       "      <td id=\"T_94883_row24_col6\" class=\"data row24 col6\" >1.0191</td>\n",
       "      <td id=\"T_94883_row24_col7\" class=\"data row24 col7\" >-114.7757</td>\n",
       "      <td id=\"T_94883_row24_col8\" class=\"data row24 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cabb35360>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5b5c_row28_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5b5c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5b5c_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_f5b5c_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f5b5c_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_f5b5c_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f5b5c_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_f5b5c_row1_col1\" class=\"data row1 col1\" >TotalSeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f5b5c_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_f5b5c_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f5b5c_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_f5b5c_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f5b5c_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_f5b5c_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f5b5c_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_f5b5c_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f5b5c_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_f5b5c_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f5b5c_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_f5b5c_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f5b5c_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_f5b5c_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f5b5c_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_f5b5c_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f5b5c_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_f5b5c_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f5b5c_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_f5b5c_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f5b5c_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_f5b5c_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f5b5c_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_f5b5c_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f5b5c_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_f5b5c_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f5b5c_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_f5b5c_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f5b5c_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_f5b5c_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f5b5c_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_f5b5c_row17_col1\" class=\"data row17 col1\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f5b5c_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_f5b5c_row18_col1\" class=\"data row18 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f5b5c_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_f5b5c_row19_col1\" class=\"data row19 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_f5b5c_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_f5b5c_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_f5b5c_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_f5b5c_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_f5b5c_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_f5b5c_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_f5b5c_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_f5b5c_row23_col1\" class=\"data row23 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_f5b5c_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_f5b5c_row24_col1\" class=\"data row24 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_f5b5c_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_f5b5c_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_f5b5c_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_f5b5c_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_f5b5c_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_f5b5c_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_f5b5c_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_f5b5c_row28_col1\" class=\"data row28 col1\" >Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_f5b5c_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_f5b5c_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_f5b5c_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_f5b5c_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_f5b5c_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_f5b5c_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_f5b5c_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_f5b5c_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_f5b5c_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_f5b5c_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_f5b5c_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_f5b5c_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_f5b5c_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_f5b5c_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5b5c_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_f5b5c_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_f5b5c_row36_col1\" class=\"data row36 col1\" >741c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca1b08790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e1fc3 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e1fc3_row0_col0, #T_e1fc3_row1_col0, #T_e1fc3_row1_col1, #T_e1fc3_row1_col2, #T_e1fc3_row1_col3, #T_e1fc3_row1_col4, #T_e1fc3_row1_col5, #T_e1fc3_row1_col6, #T_e1fc3_row1_col7, #T_e1fc3_row2_col0, #T_e1fc3_row2_col1, #T_e1fc3_row2_col2, #T_e1fc3_row2_col3, #T_e1fc3_row2_col4, #T_e1fc3_row2_col5, #T_e1fc3_row2_col6, #T_e1fc3_row2_col7, #T_e1fc3_row3_col0, #T_e1fc3_row3_col1, #T_e1fc3_row3_col2, #T_e1fc3_row3_col3, #T_e1fc3_row3_col4, #T_e1fc3_row3_col5, #T_e1fc3_row3_col6, #T_e1fc3_row3_col7, #T_e1fc3_row4_col0, #T_e1fc3_row4_col1, #T_e1fc3_row4_col2, #T_e1fc3_row4_col3, #T_e1fc3_row4_col4, #T_e1fc3_row4_col5, #T_e1fc3_row4_col6, #T_e1fc3_row4_col7, #T_e1fc3_row5_col0, #T_e1fc3_row5_col1, #T_e1fc3_row5_col2, #T_e1fc3_row5_col3, #T_e1fc3_row5_col4, #T_e1fc3_row5_col5, #T_e1fc3_row5_col6, #T_e1fc3_row5_col7, #T_e1fc3_row6_col0, #T_e1fc3_row6_col1, #T_e1fc3_row6_col2, #T_e1fc3_row6_col3, #T_e1fc3_row6_col4, #T_e1fc3_row6_col5, #T_e1fc3_row6_col6, #T_e1fc3_row6_col7, #T_e1fc3_row7_col0, #T_e1fc3_row7_col1, #T_e1fc3_row7_col2, #T_e1fc3_row7_col3, #T_e1fc3_row7_col4, #T_e1fc3_row7_col5, #T_e1fc3_row7_col6, #T_e1fc3_row7_col7, #T_e1fc3_row8_col0, #T_e1fc3_row8_col1, #T_e1fc3_row8_col2, #T_e1fc3_row8_col3, #T_e1fc3_row8_col4, #T_e1fc3_row8_col5, #T_e1fc3_row8_col6, #T_e1fc3_row8_col7, #T_e1fc3_row9_col0, #T_e1fc3_row9_col1, #T_e1fc3_row9_col2, #T_e1fc3_row9_col3, #T_e1fc3_row9_col4, #T_e1fc3_row9_col5, #T_e1fc3_row9_col6, #T_e1fc3_row9_col7, #T_e1fc3_row10_col0, #T_e1fc3_row10_col1, #T_e1fc3_row10_col2, #T_e1fc3_row10_col3, #T_e1fc3_row10_col4, #T_e1fc3_row10_col5, #T_e1fc3_row10_col6, #T_e1fc3_row10_col7, #T_e1fc3_row11_col0, #T_e1fc3_row11_col1, #T_e1fc3_row11_col2, #T_e1fc3_row11_col3, #T_e1fc3_row11_col4, #T_e1fc3_row11_col5, #T_e1fc3_row11_col6, #T_e1fc3_row11_col7, #T_e1fc3_row12_col0, #T_e1fc3_row12_col1, #T_e1fc3_row12_col2, #T_e1fc3_row12_col3, #T_e1fc3_row12_col4, #T_e1fc3_row12_col5, #T_e1fc3_row12_col6, #T_e1fc3_row12_col7, #T_e1fc3_row13_col0, #T_e1fc3_row13_col1, #T_e1fc3_row13_col2, #T_e1fc3_row13_col3, #T_e1fc3_row13_col4, #T_e1fc3_row13_col5, #T_e1fc3_row13_col6, #T_e1fc3_row13_col7, #T_e1fc3_row14_col0, #T_e1fc3_row14_col1, #T_e1fc3_row14_col2, #T_e1fc3_row14_col3, #T_e1fc3_row14_col4, #T_e1fc3_row14_col5, #T_e1fc3_row14_col6, #T_e1fc3_row14_col7, #T_e1fc3_row15_col0, #T_e1fc3_row15_col1, #T_e1fc3_row15_col2, #T_e1fc3_row15_col3, #T_e1fc3_row15_col4, #T_e1fc3_row15_col5, #T_e1fc3_row15_col6, #T_e1fc3_row15_col7, #T_e1fc3_row16_col0, #T_e1fc3_row16_col1, #T_e1fc3_row16_col2, #T_e1fc3_row16_col3, #T_e1fc3_row16_col4, #T_e1fc3_row16_col5, #T_e1fc3_row16_col6, #T_e1fc3_row16_col7, #T_e1fc3_row17_col0, #T_e1fc3_row17_col1, #T_e1fc3_row17_col2, #T_e1fc3_row17_col3, #T_e1fc3_row17_col4, #T_e1fc3_row17_col5, #T_e1fc3_row17_col6, #T_e1fc3_row17_col7, #T_e1fc3_row18_col0, #T_e1fc3_row18_col1, #T_e1fc3_row18_col2, #T_e1fc3_row18_col3, #T_e1fc3_row18_col4, #T_e1fc3_row18_col5, #T_e1fc3_row18_col6, #T_e1fc3_row18_col7, #T_e1fc3_row19_col0, #T_e1fc3_row19_col1, #T_e1fc3_row19_col2, #T_e1fc3_row19_col3, #T_e1fc3_row19_col4, #T_e1fc3_row19_col5, #T_e1fc3_row19_col6, #T_e1fc3_row19_col7, #T_e1fc3_row20_col0, #T_e1fc3_row20_col1, #T_e1fc3_row20_col2, #T_e1fc3_row20_col3, #T_e1fc3_row20_col4, #T_e1fc3_row20_col5, #T_e1fc3_row20_col6, #T_e1fc3_row20_col7, #T_e1fc3_row21_col0, #T_e1fc3_row21_col1, #T_e1fc3_row21_col2, #T_e1fc3_row21_col3, #T_e1fc3_row21_col4, #T_e1fc3_row21_col5, #T_e1fc3_row21_col6, #T_e1fc3_row21_col7, #T_e1fc3_row22_col0, #T_e1fc3_row22_col1, #T_e1fc3_row22_col2, #T_e1fc3_row22_col3, #T_e1fc3_row22_col4, #T_e1fc3_row22_col5, #T_e1fc3_row22_col6, #T_e1fc3_row22_col7, #T_e1fc3_row23_col0, #T_e1fc3_row23_col1, #T_e1fc3_row23_col2, #T_e1fc3_row23_col3, #T_e1fc3_row23_col4, #T_e1fc3_row23_col5, #T_e1fc3_row23_col6, #T_e1fc3_row23_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e1fc3_row0_col1, #T_e1fc3_row0_col2, #T_e1fc3_row0_col3, #T_e1fc3_row0_col4, #T_e1fc3_row0_col5, #T_e1fc3_row0_col6, #T_e1fc3_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_e1fc3_row0_col8, #T_e1fc3_row1_col8, #T_e1fc3_row2_col8, #T_e1fc3_row3_col8, #T_e1fc3_row5_col8, #T_e1fc3_row6_col8, #T_e1fc3_row7_col8, #T_e1fc3_row8_col8, #T_e1fc3_row9_col8, #T_e1fc3_row10_col8, #T_e1fc3_row11_col8, #T_e1fc3_row12_col8, #T_e1fc3_row13_col8, #T_e1fc3_row14_col8, #T_e1fc3_row15_col8, #T_e1fc3_row16_col8, #T_e1fc3_row17_col8, #T_e1fc3_row18_col8, #T_e1fc3_row20_col8, #T_e1fc3_row21_col8, #T_e1fc3_row22_col8, #T_e1fc3_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_e1fc3_row4_col8, #T_e1fc3_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e1fc3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e1fc3_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e1fc3_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_e1fc3_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_e1fc3_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_e1fc3_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_e1fc3_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_e1fc3_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_e1fc3_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_e1fc3_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row0\" class=\"row_heading level0 row0\" >ets</th>\n",
       "      <td id=\"T_e1fc3_row0_col0\" class=\"data row0 col0\" >ETS</td>\n",
       "      <td id=\"T_e1fc3_row0_col1\" class=\"data row0 col1\" >0.7721</td>\n",
       "      <td id=\"T_e1fc3_row0_col2\" class=\"data row0 col2\" >0.8451</td>\n",
       "      <td id=\"T_e1fc3_row0_col3\" class=\"data row0 col3\" >1052.7637</td>\n",
       "      <td id=\"T_e1fc3_row0_col4\" class=\"data row0 col4\" >1408.5122</td>\n",
       "      <td id=\"T_e1fc3_row0_col5\" class=\"data row0 col5\" >0.1600</td>\n",
       "      <td id=\"T_e1fc3_row0_col6\" class=\"data row0 col6\" >0.1367</td>\n",
       "      <td id=\"T_e1fc3_row0_col7\" class=\"data row0 col7\" >-0.2619</td>\n",
       "      <td id=\"T_e1fc3_row0_col8\" class=\"data row0 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row1\" class=\"row_heading level0 row1\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row1_col1\" class=\"data row1 col1\" >0.8842</td>\n",
       "      <td id=\"T_e1fc3_row1_col2\" class=\"data row1 col2\" >0.9019</td>\n",
       "      <td id=\"T_e1fc3_row1_col3\" class=\"data row1 col3\" >1188.0374</td>\n",
       "      <td id=\"T_e1fc3_row1_col4\" class=\"data row1 col4\" >1484.7677</td>\n",
       "      <td id=\"T_e1fc3_row1_col5\" class=\"data row1 col5\" >0.1696</td>\n",
       "      <td id=\"T_e1fc3_row1_col6\" class=\"data row1 col6\" >0.1553</td>\n",
       "      <td id=\"T_e1fc3_row1_col7\" class=\"data row1 col7\" >-0.5991</td>\n",
       "      <td id=\"T_e1fc3_row1_col8\" class=\"data row1 col8\" >0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row2\" class=\"row_heading level0 row2\" >br_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row2_col0\" class=\"data row2 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row2_col1\" class=\"data row2 col1\" >0.8846</td>\n",
       "      <td id=\"T_e1fc3_row2_col2\" class=\"data row2 col2\" >0.9024</td>\n",
       "      <td id=\"T_e1fc3_row2_col3\" class=\"data row2 col3\" >1188.5809</td>\n",
       "      <td id=\"T_e1fc3_row2_col4\" class=\"data row2 col4\" >1485.5466</td>\n",
       "      <td id=\"T_e1fc3_row2_col5\" class=\"data row2 col5\" >0.1696</td>\n",
       "      <td id=\"T_e1fc3_row2_col6\" class=\"data row2 col6\" >0.1554</td>\n",
       "      <td id=\"T_e1fc3_row2_col7\" class=\"data row2 col7\" >-0.6015</td>\n",
       "      <td id=\"T_e1fc3_row2_col8\" class=\"data row2 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row3\" class=\"row_heading level0 row3\" >exp_smooth</th>\n",
       "      <td id=\"T_e1fc3_row3_col0\" class=\"data row3 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_e1fc3_row3_col1\" class=\"data row3 col1\" >0.8921</td>\n",
       "      <td id=\"T_e1fc3_row3_col2\" class=\"data row3 col2\" >0.9150</td>\n",
       "      <td id=\"T_e1fc3_row3_col3\" class=\"data row3 col3\" >1198.6759</td>\n",
       "      <td id=\"T_e1fc3_row3_col4\" class=\"data row3 col4\" >1506.5464</td>\n",
       "      <td id=\"T_e1fc3_row3_col5\" class=\"data row3 col5\" >0.1713</td>\n",
       "      <td id=\"T_e1fc3_row3_col6\" class=\"data row3 col6\" >0.1566</td>\n",
       "      <td id=\"T_e1fc3_row3_col7\" class=\"data row3 col7\" >-0.6434</td>\n",
       "      <td id=\"T_e1fc3_row3_col8\" class=\"data row3 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row4\" class=\"row_heading level0 row4\" >polytrend</th>\n",
       "      <td id=\"T_e1fc3_row4_col0\" class=\"data row4 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_e1fc3_row4_col1\" class=\"data row4 col1\" >0.8972</td>\n",
       "      <td id=\"T_e1fc3_row4_col2\" class=\"data row4 col2\" >0.9126</td>\n",
       "      <td id=\"T_e1fc3_row4_col3\" class=\"data row4 col3\" >1204.4477</td>\n",
       "      <td id=\"T_e1fc3_row4_col4\" class=\"data row4 col4\" >1500.4026</td>\n",
       "      <td id=\"T_e1fc3_row4_col5\" class=\"data row4 col5\" >0.1708</td>\n",
       "      <td id=\"T_e1fc3_row4_col6\" class=\"data row4 col6\" >0.1576</td>\n",
       "      <td id=\"T_e1fc3_row4_col7\" class=\"data row4 col7\" >-0.6651</td>\n",
       "      <td id=\"T_e1fc3_row4_col8\" class=\"data row4 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row5\" class=\"row_heading level0 row5\" >huber_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row5_col0\" class=\"data row5 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row5_col1\" class=\"data row5 col1\" >0.8974</td>\n",
       "      <td id=\"T_e1fc3_row5_col2\" class=\"data row5 col2\" >0.9270</td>\n",
       "      <td id=\"T_e1fc3_row5_col3\" class=\"data row5 col3\" >1205.7309</td>\n",
       "      <td id=\"T_e1fc3_row5_col4\" class=\"data row5 col4\" >1525.9613</td>\n",
       "      <td id=\"T_e1fc3_row5_col5\" class=\"data row5 col5\" >0.1725</td>\n",
       "      <td id=\"T_e1fc3_row5_col6\" class=\"data row5 col6\" >0.1576</td>\n",
       "      <td id=\"T_e1fc3_row5_col7\" class=\"data row5 col7\" >-0.6910</td>\n",
       "      <td id=\"T_e1fc3_row5_col8\" class=\"data row5 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row6\" class=\"row_heading level0 row6\" >lr_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row6_col0\" class=\"data row6 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row6_col1\" class=\"data row6 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row6_col2\" class=\"data row6 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row6_col3\" class=\"data row6 col3\" >1220.9328</td>\n",
       "      <td id=\"T_e1fc3_row6_col4\" class=\"data row6 col4\" >1541.3436</td>\n",
       "      <td id=\"T_e1fc3_row6_col5\" class=\"data row6 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row6_col6\" class=\"data row6 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row6_col7\" class=\"data row6 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row6_col8\" class=\"data row6 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row7\" class=\"row_heading level0 row7\" >en_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row7_col0\" class=\"data row7 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row7_col1\" class=\"data row7 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row7_col2\" class=\"data row7 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row7_col3\" class=\"data row7 col3\" >1220.9327</td>\n",
       "      <td id=\"T_e1fc3_row7_col4\" class=\"data row7 col4\" >1541.3434</td>\n",
       "      <td id=\"T_e1fc3_row7_col5\" class=\"data row7 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row7_col6\" class=\"data row7 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row7_col7\" class=\"data row7 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row7_col8\" class=\"data row7 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row8\" class=\"row_heading level0 row8\" >omp_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row8_col0\" class=\"data row8 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row8_col1\" class=\"data row8 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row8_col2\" class=\"data row8 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row8_col3\" class=\"data row8 col3\" >1220.9328</td>\n",
       "      <td id=\"T_e1fc3_row8_col4\" class=\"data row8 col4\" >1541.3436</td>\n",
       "      <td id=\"T_e1fc3_row8_col5\" class=\"data row8 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row8_col6\" class=\"data row8 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row8_col7\" class=\"data row8 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row8_col8\" class=\"data row8 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row9\" class=\"row_heading level0 row9\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row9_col0\" class=\"data row9 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row9_col1\" class=\"data row9 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row9_col2\" class=\"data row9 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row9_col3\" class=\"data row9 col3\" >1220.9328</td>\n",
       "      <td id=\"T_e1fc3_row9_col4\" class=\"data row9 col4\" >1541.3435</td>\n",
       "      <td id=\"T_e1fc3_row9_col5\" class=\"data row9 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row9_col6\" class=\"data row9 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row9_col7\" class=\"data row9 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row9_col8\" class=\"data row9 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row10\" class=\"row_heading level0 row10\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row10_col0\" class=\"data row10 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row10_col1\" class=\"data row10 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row10_col2\" class=\"data row10 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row10_col3\" class=\"data row10 col3\" >1220.9327</td>\n",
       "      <td id=\"T_e1fc3_row10_col4\" class=\"data row10 col4\" >1541.3433</td>\n",
       "      <td id=\"T_e1fc3_row10_col5\" class=\"data row10 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row10_col6\" class=\"data row10 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row10_col7\" class=\"data row10 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row10_col8\" class=\"data row10 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row11\" class=\"row_heading level0 row11\" >llar_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row11_col0\" class=\"data row11 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row11_col1\" class=\"data row11 col1\" >0.9098</td>\n",
       "      <td id=\"T_e1fc3_row11_col2\" class=\"data row11 col2\" >0.9385</td>\n",
       "      <td id=\"T_e1fc3_row11_col3\" class=\"data row11 col3\" >1220.9327</td>\n",
       "      <td id=\"T_e1fc3_row11_col4\" class=\"data row11 col4\" >1541.3433</td>\n",
       "      <td id=\"T_e1fc3_row11_col5\" class=\"data row11 col5\" >0.1728</td>\n",
       "      <td id=\"T_e1fc3_row11_col6\" class=\"data row11 col6\" >0.1599</td>\n",
       "      <td id=\"T_e1fc3_row11_col7\" class=\"data row11 col7\" >-0.7839</td>\n",
       "      <td id=\"T_e1fc3_row11_col8\" class=\"data row11 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row12\" class=\"row_heading level0 row12\" >rf_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row12_col0\" class=\"data row12 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row12_col1\" class=\"data row12 col1\" >0.9211</td>\n",
       "      <td id=\"T_e1fc3_row12_col2\" class=\"data row12 col2\" >0.9830</td>\n",
       "      <td id=\"T_e1fc3_row12_col3\" class=\"data row12 col3\" >1237.8392</td>\n",
       "      <td id=\"T_e1fc3_row12_col4\" class=\"data row12 col4\" >1612.3114</td>\n",
       "      <td id=\"T_e1fc3_row12_col5\" class=\"data row12 col5\" >0.1752</td>\n",
       "      <td id=\"T_e1fc3_row12_col6\" class=\"data row12 col6\" >0.1641</td>\n",
       "      <td id=\"T_e1fc3_row12_col7\" class=\"data row12 col7\" >-0.9918</td>\n",
       "      <td id=\"T_e1fc3_row12_col8\" class=\"data row12 col8\" >0.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row13\" class=\"row_heading level0 row13\" >ada_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row13_col0\" class=\"data row13 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row13_col1\" class=\"data row13 col1\" >0.9243</td>\n",
       "      <td id=\"T_e1fc3_row13_col2\" class=\"data row13 col2\" >0.9451</td>\n",
       "      <td id=\"T_e1fc3_row13_col3\" class=\"data row13 col3\" >1244.3357</td>\n",
       "      <td id=\"T_e1fc3_row13_col4\" class=\"data row13 col4\" >1550.3862</td>\n",
       "      <td id=\"T_e1fc3_row13_col5\" class=\"data row13 col5\" >0.1736</td>\n",
       "      <td id=\"T_e1fc3_row13_col6\" class=\"data row13 col6\" >0.1639</td>\n",
       "      <td id=\"T_e1fc3_row13_col7\" class=\"data row13 col7\" >-0.8373</td>\n",
       "      <td id=\"T_e1fc3_row13_col8\" class=\"data row13 col8\" >0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row14\" class=\"row_heading level0 row14\" >knn_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row14_col0\" class=\"data row14 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row14_col1\" class=\"data row14 col1\" >0.9383</td>\n",
       "      <td id=\"T_e1fc3_row14_col2\" class=\"data row14 col2\" >0.9502</td>\n",
       "      <td id=\"T_e1fc3_row14_col3\" class=\"data row14 col3\" >1251.3322</td>\n",
       "      <td id=\"T_e1fc3_row14_col4\" class=\"data row14 col4\" >1547.8996</td>\n",
       "      <td id=\"T_e1fc3_row14_col5\" class=\"data row14 col5\" >0.1730</td>\n",
       "      <td id=\"T_e1fc3_row14_col6\" class=\"data row14 col6\" >0.1655</td>\n",
       "      <td id=\"T_e1fc3_row14_col7\" class=\"data row14 col7\" >-1.0521</td>\n",
       "      <td id=\"T_e1fc3_row14_col8\" class=\"data row14 col8\" >0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row15\" class=\"row_heading level0 row15\" >theta</th>\n",
       "      <td id=\"T_e1fc3_row15_col0\" class=\"data row15 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_e1fc3_row15_col1\" class=\"data row15 col1\" >1.0416</td>\n",
       "      <td id=\"T_e1fc3_row15_col2\" class=\"data row15 col2\" >1.0776</td>\n",
       "      <td id=\"T_e1fc3_row15_col3\" class=\"data row15 col3\" >1390.8272</td>\n",
       "      <td id=\"T_e1fc3_row15_col4\" class=\"data row15 col4\" >1758.6870</td>\n",
       "      <td id=\"T_e1fc3_row15_col5\" class=\"data row15 col5\" >0.1915</td>\n",
       "      <td id=\"T_e1fc3_row15_col6\" class=\"data row15 col6\" >0.1830</td>\n",
       "      <td id=\"T_e1fc3_row15_col7\" class=\"data row15 col7\" >-1.5675</td>\n",
       "      <td id=\"T_e1fc3_row15_col8\" class=\"data row15 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row16\" class=\"row_heading level0 row16\" >grand_means</th>\n",
       "      <td id=\"T_e1fc3_row16_col0\" class=\"data row16 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_e1fc3_row16_col1\" class=\"data row16 col1\" >1.2310</td>\n",
       "      <td id=\"T_e1fc3_row16_col2\" class=\"data row16 col2\" >1.1198</td>\n",
       "      <td id=\"T_e1fc3_row16_col3\" class=\"data row16 col3\" >1654.5050</td>\n",
       "      <td id=\"T_e1fc3_row16_col4\" class=\"data row16 col4\" >1824.5027</td>\n",
       "      <td id=\"T_e1fc3_row16_col5\" class=\"data row16 col5\" >0.2063</td>\n",
       "      <td id=\"T_e1fc3_row16_col6\" class=\"data row16 col6\" >0.2192</td>\n",
       "      <td id=\"T_e1fc3_row16_col7\" class=\"data row16 col7\" >-1.8427</td>\n",
       "      <td id=\"T_e1fc3_row16_col8\" class=\"data row16 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row17\" class=\"row_heading level0 row17\" >auto_arima</th>\n",
       "      <td id=\"T_e1fc3_row17_col0\" class=\"data row17 col0\" >Auto ARIMA</td>\n",
       "      <td id=\"T_e1fc3_row17_col1\" class=\"data row17 col1\" >1.2310</td>\n",
       "      <td id=\"T_e1fc3_row17_col2\" class=\"data row17 col2\" >1.1198</td>\n",
       "      <td id=\"T_e1fc3_row17_col3\" class=\"data row17 col3\" >1654.5050</td>\n",
       "      <td id=\"T_e1fc3_row17_col4\" class=\"data row17 col4\" >1824.5027</td>\n",
       "      <td id=\"T_e1fc3_row17_col5\" class=\"data row17 col5\" >0.2063</td>\n",
       "      <td id=\"T_e1fc3_row17_col6\" class=\"data row17 col6\" >0.2192</td>\n",
       "      <td id=\"T_e1fc3_row17_col7\" class=\"data row17 col7\" >-1.8427</td>\n",
       "      <td id=\"T_e1fc3_row17_col8\" class=\"data row17 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row18\" class=\"row_heading level0 row18\" >arima</th>\n",
       "      <td id=\"T_e1fc3_row18_col0\" class=\"data row18 col0\" >ARIMA</td>\n",
       "      <td id=\"T_e1fc3_row18_col1\" class=\"data row18 col1\" >1.2785</td>\n",
       "      <td id=\"T_e1fc3_row18_col2\" class=\"data row18 col2\" >1.1731</td>\n",
       "      <td id=\"T_e1fc3_row18_col3\" class=\"data row18 col3\" >1717.3561</td>\n",
       "      <td id=\"T_e1fc3_row18_col4\" class=\"data row18 col4\" >1910.8257</td>\n",
       "      <td id=\"T_e1fc3_row18_col5\" class=\"data row18 col5\" >0.2159</td>\n",
       "      <td id=\"T_e1fc3_row18_col6\" class=\"data row18 col6\" >0.2281</td>\n",
       "      <td id=\"T_e1fc3_row18_col7\" class=\"data row18 col7\" >-2.1354</td>\n",
       "      <td id=\"T_e1fc3_row18_col8\" class=\"data row18 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row19\" class=\"row_heading level0 row19\" >croston</th>\n",
       "      <td id=\"T_e1fc3_row19_col0\" class=\"data row19 col0\" >Croston</td>\n",
       "      <td id=\"T_e1fc3_row19_col1\" class=\"data row19 col1\" >1.2787</td>\n",
       "      <td id=\"T_e1fc3_row19_col2\" class=\"data row19 col2\" >1.1673</td>\n",
       "      <td id=\"T_e1fc3_row19_col3\" class=\"data row19 col3\" >1711.2904</td>\n",
       "      <td id=\"T_e1fc3_row19_col4\" class=\"data row19 col4\" >1894.5606</td>\n",
       "      <td id=\"T_e1fc3_row19_col5\" class=\"data row19 col5\" >0.2143</td>\n",
       "      <td id=\"T_e1fc3_row19_col6\" class=\"data row19 col6\" >0.2281</td>\n",
       "      <td id=\"T_e1fc3_row19_col7\" class=\"data row19 col7\" >-2.2846</td>\n",
       "      <td id=\"T_e1fc3_row19_col8\" class=\"data row19 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row20\" class=\"row_heading level0 row20\" >et_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row20_col0\" class=\"data row20 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row20_col1\" class=\"data row20 col1\" >1.3302</td>\n",
       "      <td id=\"T_e1fc3_row20_col2\" class=\"data row20 col2\" >1.3134</td>\n",
       "      <td id=\"T_e1fc3_row20_col3\" class=\"data row20 col3\" >1765.0843</td>\n",
       "      <td id=\"T_e1fc3_row20_col4\" class=\"data row20 col4\" >2129.2610</td>\n",
       "      <td id=\"T_e1fc3_row20_col5\" class=\"data row20 col5\" >0.2388</td>\n",
       "      <td id=\"T_e1fc3_row20_col6\" class=\"data row20 col6\" >0.2392</td>\n",
       "      <td id=\"T_e1fc3_row20_col7\" class=\"data row20 col7\" >-3.2393</td>\n",
       "      <td id=\"T_e1fc3_row20_col8\" class=\"data row20 col8\" >0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row21\" class=\"row_heading level0 row21\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row21_col0\" class=\"data row21 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row21_col1\" class=\"data row21 col1\" >1.3687</td>\n",
       "      <td id=\"T_e1fc3_row21_col2\" class=\"data row21 col2\" >1.3457</td>\n",
       "      <td id=\"T_e1fc3_row21_col3\" class=\"data row21 col3\" >1813.7471</td>\n",
       "      <td id=\"T_e1fc3_row21_col4\" class=\"data row21 col4\" >2177.2586</td>\n",
       "      <td id=\"T_e1fc3_row21_col5\" class=\"data row21 col5\" >0.2435</td>\n",
       "      <td id=\"T_e1fc3_row21_col6\" class=\"data row21 col6\" >0.2462</td>\n",
       "      <td id=\"T_e1fc3_row21_col7\" class=\"data row21 col7\" >-3.6007</td>\n",
       "      <td id=\"T_e1fc3_row21_col8\" class=\"data row21 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row22\" class=\"row_heading level0 row22\" >dt_cds_dt</th>\n",
       "      <td id=\"T_e1fc3_row22_col0\" class=\"data row22 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_e1fc3_row22_col1\" class=\"data row22 col1\" >1.3811</td>\n",
       "      <td id=\"T_e1fc3_row22_col2\" class=\"data row22 col2\" >1.3556</td>\n",
       "      <td id=\"T_e1fc3_row22_col3\" class=\"data row22 col3\" >1830.1080</td>\n",
       "      <td id=\"T_e1fc3_row22_col4\" class=\"data row22 col4\" >2193.0906</td>\n",
       "      <td id=\"T_e1fc3_row22_col5\" class=\"data row22 col5\" >0.2457</td>\n",
       "      <td id=\"T_e1fc3_row22_col6\" class=\"data row22 col6\" >0.2486</td>\n",
       "      <td id=\"T_e1fc3_row22_col7\" class=\"data row22 col7\" >-3.6713</td>\n",
       "      <td id=\"T_e1fc3_row22_col8\" class=\"data row22 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e1fc3_level0_row23\" class=\"row_heading level0 row23\" >naive</th>\n",
       "      <td id=\"T_e1fc3_row23_col0\" class=\"data row23 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_e1fc3_row23_col1\" class=\"data row23 col1\" >1.4315</td>\n",
       "      <td id=\"T_e1fc3_row23_col2\" class=\"data row23 col2\" >1.3949</td>\n",
       "      <td id=\"T_e1fc3_row23_col3\" class=\"data row23 col3\" >1890.6000</td>\n",
       "      <td id=\"T_e1fc3_row23_col4\" class=\"data row23 col4\" >2249.1078</td>\n",
       "      <td id=\"T_e1fc3_row23_col5\" class=\"data row23 col5\" >0.2510</td>\n",
       "      <td id=\"T_e1fc3_row23_col6\" class=\"data row23 col6\" >0.2608</td>\n",
       "      <td id=\"T_e1fc3_row23_col7\" class=\"data row23 col7\" >-4.2384</td>\n",
       "      <td id=\"T_e1fc3_row23_col8\" class=\"data row23 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23ca1a9ac80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1fd5c_row25_col1, #T_1fd5c_row28_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1fd5c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1fd5c_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_1fd5c_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1fd5c_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_1fd5c_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_1fd5c_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_1fd5c_row1_col1\" class=\"data row1 col1\" >SeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_1fd5c_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_1fd5c_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_1fd5c_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_1fd5c_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_1fd5c_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_1fd5c_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_1fd5c_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_1fd5c_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_1fd5c_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_1fd5c_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_1fd5c_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_1fd5c_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_1fd5c_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_1fd5c_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_1fd5c_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_1fd5c_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_1fd5c_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_1fd5c_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_1fd5c_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_1fd5c_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_1fd5c_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_1fd5c_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_1fd5c_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_1fd5c_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_1fd5c_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_1fd5c_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_1fd5c_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_1fd5c_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_1fd5c_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_1fd5c_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_1fd5c_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_1fd5c_row17_col1\" class=\"data row17 col1\" >[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_1fd5c_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_1fd5c_row18_col1\" class=\"data row18 col1\" >[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_1fd5c_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_1fd5c_row19_col1\" class=\"data row19 col1\" >[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_1fd5c_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_1fd5c_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_1fd5c_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_1fd5c_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_1fd5c_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_1fd5c_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_1fd5c_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_1fd5c_row23_col1\" class=\"data row23 col1\" >[14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_1fd5c_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_1fd5c_row24_col1\" class=\"data row24 col1\" >14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_1fd5c_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_1fd5c_row25_col1\" class=\"data row25 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_1fd5c_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_1fd5c_row26_col1\" class=\"data row26 col1\" >mul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_1fd5c_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_1fd5c_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_1fd5c_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_1fd5c_row28_col1\" class=\"data row28 col1\" >Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_1fd5c_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_1fd5c_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_1fd5c_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_1fd5c_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_1fd5c_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_1fd5c_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_1fd5c_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_1fd5c_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_1fd5c_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_1fd5c_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_1fd5c_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_1fd5c_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_1fd5c_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_1fd5c_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1fd5c_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_1fd5c_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_1fd5c_row36_col1\" class=\"data row36 col1\" >c9c2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc7247700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2c658 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2c658_row0_col0, #T_2c658_row0_col7, #T_2c658_row1_col0, #T_2c658_row1_col1, #T_2c658_row1_col2, #T_2c658_row1_col3, #T_2c658_row1_col4, #T_2c658_row1_col5, #T_2c658_row1_col6, #T_2c658_row1_col7, #T_2c658_row2_col0, #T_2c658_row2_col1, #T_2c658_row2_col2, #T_2c658_row2_col3, #T_2c658_row2_col4, #T_2c658_row2_col5, #T_2c658_row2_col6, #T_2c658_row2_col7, #T_2c658_row3_col0, #T_2c658_row3_col1, #T_2c658_row3_col2, #T_2c658_row3_col3, #T_2c658_row3_col4, #T_2c658_row3_col5, #T_2c658_row3_col6, #T_2c658_row4_col0, #T_2c658_row4_col1, #T_2c658_row4_col2, #T_2c658_row4_col3, #T_2c658_row4_col4, #T_2c658_row4_col5, #T_2c658_row4_col6, #T_2c658_row4_col7, #T_2c658_row5_col0, #T_2c658_row5_col1, #T_2c658_row5_col2, #T_2c658_row5_col3, #T_2c658_row5_col4, #T_2c658_row5_col5, #T_2c658_row5_col6, #T_2c658_row5_col7, #T_2c658_row6_col0, #T_2c658_row6_col1, #T_2c658_row6_col2, #T_2c658_row6_col3, #T_2c658_row6_col4, #T_2c658_row6_col5, #T_2c658_row6_col6, #T_2c658_row6_col7, #T_2c658_row7_col0, #T_2c658_row7_col1, #T_2c658_row7_col2, #T_2c658_row7_col3, #T_2c658_row7_col4, #T_2c658_row7_col5, #T_2c658_row7_col6, #T_2c658_row7_col7, #T_2c658_row8_col0, #T_2c658_row8_col1, #T_2c658_row8_col2, #T_2c658_row8_col3, #T_2c658_row8_col4, #T_2c658_row8_col5, #T_2c658_row8_col6, #T_2c658_row8_col7, #T_2c658_row9_col0, #T_2c658_row9_col1, #T_2c658_row9_col2, #T_2c658_row9_col3, #T_2c658_row9_col4, #T_2c658_row9_col5, #T_2c658_row9_col6, #T_2c658_row9_col7, #T_2c658_row10_col0, #T_2c658_row10_col1, #T_2c658_row10_col2, #T_2c658_row10_col3, #T_2c658_row10_col4, #T_2c658_row10_col5, #T_2c658_row10_col6, #T_2c658_row10_col7, #T_2c658_row11_col0, #T_2c658_row11_col1, #T_2c658_row11_col2, #T_2c658_row11_col3, #T_2c658_row11_col4, #T_2c658_row11_col5, #T_2c658_row11_col6, #T_2c658_row11_col7, #T_2c658_row12_col0, #T_2c658_row12_col1, #T_2c658_row12_col2, #T_2c658_row12_col3, #T_2c658_row12_col4, #T_2c658_row12_col5, #T_2c658_row12_col6, #T_2c658_row12_col7, #T_2c658_row13_col0, #T_2c658_row13_col1, #T_2c658_row13_col2, #T_2c658_row13_col3, #T_2c658_row13_col4, #T_2c658_row13_col5, #T_2c658_row13_col6, #T_2c658_row13_col7, #T_2c658_row14_col0, #T_2c658_row14_col1, #T_2c658_row14_col2, #T_2c658_row14_col3, #T_2c658_row14_col4, #T_2c658_row14_col5, #T_2c658_row14_col6, #T_2c658_row14_col7, #T_2c658_row15_col0, #T_2c658_row15_col1, #T_2c658_row15_col2, #T_2c658_row15_col3, #T_2c658_row15_col4, #T_2c658_row15_col5, #T_2c658_row15_col6, #T_2c658_row15_col7, #T_2c658_row16_col0, #T_2c658_row16_col1, #T_2c658_row16_col2, #T_2c658_row16_col3, #T_2c658_row16_col4, #T_2c658_row16_col5, #T_2c658_row16_col6, #T_2c658_row16_col7, #T_2c658_row17_col0, #T_2c658_row17_col1, #T_2c658_row17_col2, #T_2c658_row17_col3, #T_2c658_row17_col4, #T_2c658_row17_col5, #T_2c658_row17_col6, #T_2c658_row17_col7, #T_2c658_row18_col0, #T_2c658_row18_col1, #T_2c658_row18_col2, #T_2c658_row18_col3, #T_2c658_row18_col4, #T_2c658_row18_col5, #T_2c658_row18_col6, #T_2c658_row18_col7, #T_2c658_row19_col0, #T_2c658_row19_col1, #T_2c658_row19_col2, #T_2c658_row19_col3, #T_2c658_row19_col4, #T_2c658_row19_col5, #T_2c658_row19_col6, #T_2c658_row19_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2c658_row0_col1, #T_2c658_row0_col2, #T_2c658_row0_col3, #T_2c658_row0_col4, #T_2c658_row0_col5, #T_2c658_row0_col6, #T_2c658_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2c658_row0_col8, #T_2c658_row1_col8, #T_2c658_row3_col8, #T_2c658_row4_col8, #T_2c658_row5_col8, #T_2c658_row6_col8, #T_2c658_row7_col8, #T_2c658_row8_col8, #T_2c658_row9_col8, #T_2c658_row10_col8, #T_2c658_row11_col8, #T_2c658_row12_col8, #T_2c658_row13_col8, #T_2c658_row14_col8, #T_2c658_row15_col8, #T_2c658_row16_col8, #T_2c658_row17_col8, #T_2c658_row18_col8, #T_2c658_row19_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_2c658_row2_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2c658\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2c658_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2c658_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_2c658_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_2c658_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_2c658_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_2c658_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_2c658_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_2c658_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_2c658_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row0\" class=\"row_heading level0 row0\" >snaive</th>\n",
       "      <td id=\"T_2c658_row0_col0\" class=\"data row0 col0\" >Seasonal Naive Forecaster</td>\n",
       "      <td id=\"T_2c658_row0_col1\" class=\"data row0 col1\" >1.2167</td>\n",
       "      <td id=\"T_2c658_row0_col2\" class=\"data row0 col2\" >1.2752</td>\n",
       "      <td id=\"T_2c658_row0_col3\" class=\"data row0 col3\" >4.0000</td>\n",
       "      <td id=\"T_2c658_row0_col4\" class=\"data row0 col4\" >5.1639</td>\n",
       "      <td id=\"T_2c658_row0_col5\" class=\"data row0 col5\" >0.0229</td>\n",
       "      <td id=\"T_2c658_row0_col6\" class=\"data row0 col6\" >0.0227</td>\n",
       "      <td id=\"T_2c658_row0_col7\" class=\"data row0 col7\" >-0.7166</td>\n",
       "      <td id=\"T_2c658_row0_col8\" class=\"data row0 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row1\" class=\"row_heading level0 row1\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_2c658_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row1_col1\" class=\"data row1 col1\" >1.3549</td>\n",
       "      <td id=\"T_2c658_row1_col2\" class=\"data row1 col2\" >2.0373</td>\n",
       "      <td id=\"T_2c658_row1_col3\" class=\"data row1 col3\" >4.8647</td>\n",
       "      <td id=\"T_2c658_row1_col4\" class=\"data row1 col4\" >8.1893</td>\n",
       "      <td id=\"T_2c658_row1_col5\" class=\"data row1 col5\" >0.0302</td>\n",
       "      <td id=\"T_2c658_row1_col6\" class=\"data row1 col6\" >0.0286</td>\n",
       "      <td id=\"T_2c658_row1_col7\" class=\"data row1 col7\" >-0.2867</td>\n",
       "      <td id=\"T_2c658_row1_col8\" class=\"data row1 col8\" >1.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row2\" class=\"row_heading level0 row2\" >croston</th>\n",
       "      <td id=\"T_2c658_row2_col0\" class=\"data row2 col0\" >Croston</td>\n",
       "      <td id=\"T_2c658_row2_col1\" class=\"data row2 col1\" >1.5125</td>\n",
       "      <td id=\"T_2c658_row2_col2\" class=\"data row2 col2\" >1.8622</td>\n",
       "      <td id=\"T_2c658_row2_col3\" class=\"data row2 col3\" >5.5181</td>\n",
       "      <td id=\"T_2c658_row2_col4\" class=\"data row2 col4\" >7.4854</td>\n",
       "      <td id=\"T_2c658_row2_col5\" class=\"data row2 col5\" >0.0335</td>\n",
       "      <td id=\"T_2c658_row2_col6\" class=\"data row2 col6\" >0.0323</td>\n",
       "      <td id=\"T_2c658_row2_col7\" class=\"data row2 col7\" >-0.0703</td>\n",
       "      <td id=\"T_2c658_row2_col8\" class=\"data row2 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row3\" class=\"row_heading level0 row3\" >grand_means</th>\n",
       "      <td id=\"T_2c658_row3_col0\" class=\"data row3 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_2c658_row3_col1\" class=\"data row3 col1\" >1.5400</td>\n",
       "      <td id=\"T_2c658_row3_col2\" class=\"data row3 col2\" >1.8325</td>\n",
       "      <td id=\"T_2c658_row3_col3\" class=\"data row3 col3\" >5.6500</td>\n",
       "      <td id=\"T_2c658_row3_col4\" class=\"data row3 col4\" >7.3648</td>\n",
       "      <td id=\"T_2c658_row3_col5\" class=\"data row3 col5\" >0.0341</td>\n",
       "      <td id=\"T_2c658_row3_col6\" class=\"data row3 col6\" >0.0331</td>\n",
       "      <td id=\"T_2c658_row3_col7\" class=\"data row3 col7\" >-0.0164</td>\n",
       "      <td id=\"T_2c658_row3_col8\" class=\"data row3 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row4\" class=\"row_heading level0 row4\" >polytrend</th>\n",
       "      <td id=\"T_2c658_row4_col0\" class=\"data row4 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_2c658_row4_col1\" class=\"data row4 col1\" >1.5844</td>\n",
       "      <td id=\"T_2c658_row4_col2\" class=\"data row4 col2\" >2.2444</td>\n",
       "      <td id=\"T_2c658_row4_col3\" class=\"data row4 col3\" >5.6532</td>\n",
       "      <td id=\"T_2c658_row4_col4\" class=\"data row4 col4\" >9.0303</td>\n",
       "      <td id=\"T_2c658_row4_col5\" class=\"data row4 col5\" >0.0348</td>\n",
       "      <td id=\"T_2c658_row4_col6\" class=\"data row4 col6\" >0.0330</td>\n",
       "      <td id=\"T_2c658_row4_col7\" class=\"data row4 col7\" >-0.8200</td>\n",
       "      <td id=\"T_2c658_row4_col8\" class=\"data row4 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row5\" class=\"row_heading level0 row5\" >naive</th>\n",
       "      <td id=\"T_2c658_row5_col0\" class=\"data row5 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_2c658_row5_col1\" class=\"data row5 col1\" >1.6417</td>\n",
       "      <td id=\"T_2c658_row5_col2\" class=\"data row5 col2\" >2.2764</td>\n",
       "      <td id=\"T_2c658_row5_col3\" class=\"data row5 col3\" >5.7000</td>\n",
       "      <td id=\"T_2c658_row5_col4\" class=\"data row5 col4\" >9.1684</td>\n",
       "      <td id=\"T_2c658_row5_col5\" class=\"data row5 col5\" >0.0351</td>\n",
       "      <td id=\"T_2c658_row5_col6\" class=\"data row5 col6\" >0.0333</td>\n",
       "      <td id=\"T_2c658_row5_col7\" class=\"data row5 col7\" >-1.2340</td>\n",
       "      <td id=\"T_2c658_row5_col8\" class=\"data row5 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row6\" class=\"row_heading level0 row6\" >stlf</th>\n",
       "      <td id=\"T_2c658_row6_col0\" class=\"data row6 col0\" >STLF</td>\n",
       "      <td id=\"T_2c658_row6_col1\" class=\"data row6 col1\" >1.6552</td>\n",
       "      <td id=\"T_2c658_row6_col2\" class=\"data row6 col2\" >1.4900</td>\n",
       "      <td id=\"T_2c658_row6_col3\" class=\"data row6 col3\" >5.2848</td>\n",
       "      <td id=\"T_2c658_row6_col4\" class=\"data row6 col4\" >6.0480</td>\n",
       "      <td id=\"T_2c658_row6_col5\" class=\"data row6 col5\" >0.0304</td>\n",
       "      <td id=\"T_2c658_row6_col6\" class=\"data row6 col6\" >0.0298</td>\n",
       "      <td id=\"T_2c658_row6_col7\" class=\"data row6 col7\" >-2.2782</td>\n",
       "      <td id=\"T_2c658_row6_col8\" class=\"data row6 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row7\" class=\"row_heading level0 row7\" >rf_cds_dt</th>\n",
       "      <td id=\"T_2c658_row7_col0\" class=\"data row7 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row7_col1\" class=\"data row7 col1\" >1.6677</td>\n",
       "      <td id=\"T_2c658_row7_col2\" class=\"data row7 col2\" >2.3269</td>\n",
       "      <td id=\"T_2c658_row7_col3\" class=\"data row7 col3\" >5.8031</td>\n",
       "      <td id=\"T_2c658_row7_col4\" class=\"data row7 col4\" >9.3717</td>\n",
       "      <td id=\"T_2c658_row7_col5\" class=\"data row7 col5\" >0.0357</td>\n",
       "      <td id=\"T_2c658_row7_col6\" class=\"data row7 col6\" >0.0339</td>\n",
       "      <td id=\"T_2c658_row7_col7\" class=\"data row7 col7\" >-1.3252</td>\n",
       "      <td id=\"T_2c658_row7_col8\" class=\"data row7 col8\" >1.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row8\" class=\"row_heading level0 row8\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_2c658_row8_col0\" class=\"data row8 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row8_col1\" class=\"data row8 col1\" >1.7883</td>\n",
       "      <td id=\"T_2c658_row8_col2\" class=\"data row8 col2\" >2.4262</td>\n",
       "      <td id=\"T_2c658_row8_col3\" class=\"data row8 col3\" >6.1649</td>\n",
       "      <td id=\"T_2c658_row8_col4\" class=\"data row8 col4\" >9.7770</td>\n",
       "      <td id=\"T_2c658_row8_col5\" class=\"data row8 col5\" >0.0378</td>\n",
       "      <td id=\"T_2c658_row8_col6\" class=\"data row8 col6\" >0.0358</td>\n",
       "      <td id=\"T_2c658_row8_col7\" class=\"data row8 col7\" >-1.7905</td>\n",
       "      <td id=\"T_2c658_row8_col8\" class=\"data row8 col8\" >1.6100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row9\" class=\"row_heading level0 row9\" >ada_cds_dt</th>\n",
       "      <td id=\"T_2c658_row9_col0\" class=\"data row9 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row9_col1\" class=\"data row9 col1\" >1.8397</td>\n",
       "      <td id=\"T_2c658_row9_col2\" class=\"data row9 col2\" >2.4307</td>\n",
       "      <td id=\"T_2c658_row9_col3\" class=\"data row9 col3\" >6.3191</td>\n",
       "      <td id=\"T_2c658_row9_col4\" class=\"data row9 col4\" >9.7955</td>\n",
       "      <td id=\"T_2c658_row9_col5\" class=\"data row9 col5\" >0.0387</td>\n",
       "      <td id=\"T_2c658_row9_col6\" class=\"data row9 col6\" >0.0367</td>\n",
       "      <td id=\"T_2c658_row9_col7\" class=\"data row9 col7\" >-1.8131</td>\n",
       "      <td id=\"T_2c658_row9_col8\" class=\"data row9 col8\" >1.6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row10\" class=\"row_heading level0 row10\" >dt_cds_dt</th>\n",
       "      <td id=\"T_2c658_row10_col0\" class=\"data row10 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row10_col1\" class=\"data row10 col1\" >1.8512</td>\n",
       "      <td id=\"T_2c658_row10_col2\" class=\"data row10 col2\" >2.4367</td>\n",
       "      <td id=\"T_2c658_row10_col3\" class=\"data row10 col3\" >6.3537</td>\n",
       "      <td id=\"T_2c658_row10_col4\" class=\"data row10 col4\" >9.8199</td>\n",
       "      <td id=\"T_2c658_row10_col5\" class=\"data row10 col5\" >0.0389</td>\n",
       "      <td id=\"T_2c658_row10_col6\" class=\"data row10 col6\" >0.0369</td>\n",
       "      <td id=\"T_2c658_row10_col7\" class=\"data row10 col7\" >-1.8430</td>\n",
       "      <td id=\"T_2c658_row10_col8\" class=\"data row10 col8\" >1.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row11\" class=\"row_heading level0 row11\" >et_cds_dt</th>\n",
       "      <td id=\"T_2c658_row11_col0\" class=\"data row11 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row11_col1\" class=\"data row11 col1\" >1.9464</td>\n",
       "      <td id=\"T_2c658_row11_col2\" class=\"data row11 col2\" >2.5025</td>\n",
       "      <td id=\"T_2c658_row11_col3\" class=\"data row11 col3\" >6.6393</td>\n",
       "      <td id=\"T_2c658_row11_col4\" class=\"data row11 col4\" >10.0886</td>\n",
       "      <td id=\"T_2c658_row11_col5\" class=\"data row11 col5\" >0.0402</td>\n",
       "      <td id=\"T_2c658_row11_col6\" class=\"data row11 col6\" >0.0388</td>\n",
       "      <td id=\"T_2c658_row11_col7\" class=\"data row11 col7\" >-2.1863</td>\n",
       "      <td id=\"T_2c658_row11_col8\" class=\"data row11 col8\" >1.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row12\" class=\"row_heading level0 row12\" >omp_cds_dt</th>\n",
       "      <td id=\"T_2c658_row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row12_col1\" class=\"data row12 col1\" >2.2376</td>\n",
       "      <td id=\"T_2c658_row12_col2\" class=\"data row12 col2\" >2.6862</td>\n",
       "      <td id=\"T_2c658_row12_col3\" class=\"data row12 col3\" >7.5128</td>\n",
       "      <td id=\"T_2c658_row12_col4\" class=\"data row12 col4\" >10.8386</td>\n",
       "      <td id=\"T_2c658_row12_col5\" class=\"data row12 col5\" >0.0455</td>\n",
       "      <td id=\"T_2c658_row12_col6\" class=\"data row12 col6\" >0.0433</td>\n",
       "      <td id=\"T_2c658_row12_col7\" class=\"data row12 col7\" >-3.2744</td>\n",
       "      <td id=\"T_2c658_row12_col8\" class=\"data row12 col8\" >0.1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row13\" class=\"row_heading level0 row13\" >en_cds_dt</th>\n",
       "      <td id=\"T_2c658_row13_col0\" class=\"data row13 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row13_col1\" class=\"data row13 col1\" >2.2711</td>\n",
       "      <td id=\"T_2c658_row13_col2\" class=\"data row13 col2\" >2.7796</td>\n",
       "      <td id=\"T_2c658_row13_col3\" class=\"data row13 col3\" >7.6134</td>\n",
       "      <td id=\"T_2c658_row13_col4\" class=\"data row13 col4\" >11.2198</td>\n",
       "      <td id=\"T_2c658_row13_col5\" class=\"data row13 col5\" >0.0460</td>\n",
       "      <td id=\"T_2c658_row13_col6\" class=\"data row13 col6\" >0.0437</td>\n",
       "      <td id=\"T_2c658_row13_col7\" class=\"data row13 col7\" >-3.9007</td>\n",
       "      <td id=\"T_2c658_row13_col8\" class=\"data row13 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row14\" class=\"row_heading level0 row14\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_2c658_row14_col0\" class=\"data row14 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row14_col1\" class=\"data row14 col1\" >2.2801</td>\n",
       "      <td id=\"T_2c658_row14_col2\" class=\"data row14 col2\" >2.7759</td>\n",
       "      <td id=\"T_2c658_row14_col3\" class=\"data row14 col3\" >7.6404</td>\n",
       "      <td id=\"T_2c658_row14_col4\" class=\"data row14 col4\" >11.2047</td>\n",
       "      <td id=\"T_2c658_row14_col5\" class=\"data row14 col5\" >0.0462</td>\n",
       "      <td id=\"T_2c658_row14_col6\" class=\"data row14 col6\" >0.0438</td>\n",
       "      <td id=\"T_2c658_row14_col7\" class=\"data row14 col7\" >-3.8750</td>\n",
       "      <td id=\"T_2c658_row14_col8\" class=\"data row14 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row15\" class=\"row_heading level0 row15\" >llar_cds_dt</th>\n",
       "      <td id=\"T_2c658_row15_col0\" class=\"data row15 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row15_col1\" class=\"data row15 col1\" >2.2801</td>\n",
       "      <td id=\"T_2c658_row15_col2\" class=\"data row15 col2\" >2.7759</td>\n",
       "      <td id=\"T_2c658_row15_col3\" class=\"data row15 col3\" >7.6402</td>\n",
       "      <td id=\"T_2c658_row15_col4\" class=\"data row15 col4\" >11.2046</td>\n",
       "      <td id=\"T_2c658_row15_col5\" class=\"data row15 col5\" >0.0462</td>\n",
       "      <td id=\"T_2c658_row15_col6\" class=\"data row15 col6\" >0.0438</td>\n",
       "      <td id=\"T_2c658_row15_col7\" class=\"data row15 col7\" >-3.8748</td>\n",
       "      <td id=\"T_2c658_row15_col8\" class=\"data row15 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row16\" class=\"row_heading level0 row16\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_2c658_row16_col0\" class=\"data row16 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row16_col1\" class=\"data row16 col1\" >2.3700</td>\n",
       "      <td id=\"T_2c658_row16_col2\" class=\"data row16 col2\" >2.8206</td>\n",
       "      <td id=\"T_2c658_row16_col3\" class=\"data row16 col3\" >7.9101</td>\n",
       "      <td id=\"T_2c658_row16_col4\" class=\"data row16 col4\" >11.3873</td>\n",
       "      <td id=\"T_2c658_row16_col5\" class=\"data row16 col5\" >0.0477</td>\n",
       "      <td id=\"T_2c658_row16_col6\" class=\"data row16 col6\" >0.0453</td>\n",
       "      <td id=\"T_2c658_row16_col7\" class=\"data row16 col7\" >-4.1916</td>\n",
       "      <td id=\"T_2c658_row16_col8\" class=\"data row16 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row17\" class=\"row_heading level0 row17\" >lr_cds_dt</th>\n",
       "      <td id=\"T_2c658_row17_col0\" class=\"data row17 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row17_col1\" class=\"data row17 col1\" >2.3723</td>\n",
       "      <td id=\"T_2c658_row17_col2\" class=\"data row17 col2\" >2.8227</td>\n",
       "      <td id=\"T_2c658_row17_col3\" class=\"data row17 col3\" >7.9169</td>\n",
       "      <td id=\"T_2c658_row17_col4\" class=\"data row17 col4\" >11.3959</td>\n",
       "      <td id=\"T_2c658_row17_col5\" class=\"data row17 col5\" >0.0477</td>\n",
       "      <td id=\"T_2c658_row17_col6\" class=\"data row17 col6\" >0.0454</td>\n",
       "      <td id=\"T_2c658_row17_col7\" class=\"data row17 col7\" >-4.2069</td>\n",
       "      <td id=\"T_2c658_row17_col8\" class=\"data row17 col8\" >0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row18\" class=\"row_heading level0 row18\" >br_cds_dt</th>\n",
       "      <td id=\"T_2c658_row18_col0\" class=\"data row18 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row18_col1\" class=\"data row18 col1\" >2.3723</td>\n",
       "      <td id=\"T_2c658_row18_col2\" class=\"data row18 col2\" >2.8227</td>\n",
       "      <td id=\"T_2c658_row18_col3\" class=\"data row18 col3\" >7.9169</td>\n",
       "      <td id=\"T_2c658_row18_col4\" class=\"data row18 col4\" >11.3959</td>\n",
       "      <td id=\"T_2c658_row18_col5\" class=\"data row18 col5\" >0.0477</td>\n",
       "      <td id=\"T_2c658_row18_col6\" class=\"data row18 col6\" >0.0454</td>\n",
       "      <td id=\"T_2c658_row18_col7\" class=\"data row18 col7\" >-4.2069</td>\n",
       "      <td id=\"T_2c658_row18_col8\" class=\"data row18 col8\" >0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c658_level0_row19\" class=\"row_heading level0 row19\" >huber_cds_dt</th>\n",
       "      <td id=\"T_2c658_row19_col0\" class=\"data row19 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_2c658_row19_col1\" class=\"data row19 col1\" >2.6917</td>\n",
       "      <td id=\"T_2c658_row19_col2\" class=\"data row19 col2\" >3.0841</td>\n",
       "      <td id=\"T_2c658_row19_col3\" class=\"data row19 col3\" >8.9839</td>\n",
       "      <td id=\"T_2c658_row19_col4\" class=\"data row19 col4\" >12.4578</td>\n",
       "      <td id=\"T_2c658_row19_col5\" class=\"data row19 col5\" >0.0539</td>\n",
       "      <td id=\"T_2c658_row19_col6\" class=\"data row19 col6\" >0.0511</td>\n",
       "      <td id=\"T_2c658_row19_col7\" class=\"data row19 col7\" >-5.7938</td>\n",
       "      <td id=\"T_2c658_row19_col8\" class=\"data row19 col8\" >0.1450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab672b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_744c6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_744c6_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_744c6_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_744c6_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_744c6_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_744c6_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_744c6_row1_col1\" class=\"data row1 col1\" >AverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_744c6_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_744c6_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_744c6_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_744c6_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_744c6_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_744c6_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_744c6_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_744c6_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_744c6_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_744c6_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_744c6_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_744c6_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_744c6_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_744c6_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_744c6_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_744c6_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_744c6_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_744c6_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_744c6_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_744c6_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_744c6_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_744c6_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_744c6_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_744c6_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_744c6_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_744c6_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_744c6_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_744c6_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_744c6_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_744c6_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_744c6_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_744c6_row17_col1\" class=\"data row17 col1\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_744c6_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_744c6_row18_col1\" class=\"data row18 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_744c6_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_744c6_row19_col1\" class=\"data row19 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_744c6_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_744c6_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_744c6_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_744c6_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_744c6_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_744c6_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_744c6_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_744c6_row23_col1\" class=\"data row23 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_744c6_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_744c6_row24_col1\" class=\"data row24 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_744c6_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_744c6_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_744c6_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_744c6_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_744c6_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_744c6_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_744c6_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_744c6_row28_col1\" class=\"data row28 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_744c6_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_744c6_row29_col1\" class=\"data row29 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_744c6_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_744c6_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_744c6_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_744c6_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_744c6_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_744c6_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_744c6_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_744c6_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_744c6_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_744c6_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_744c6_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_744c6_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_744c6_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_744c6_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_744c6_row36_col1\" class=\"data row36 col1\" >d3ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc16ee230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_02c27 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_02c27_row0_col0, #T_02c27_row0_col2, #T_02c27_row0_col4, #T_02c27_row0_col5, #T_02c27_row0_col7, #T_02c27_row1_col0, #T_02c27_row1_col1, #T_02c27_row1_col3, #T_02c27_row1_col6, #T_02c27_row2_col0, #T_02c27_row2_col1, #T_02c27_row2_col2, #T_02c27_row2_col3, #T_02c27_row2_col4, #T_02c27_row2_col5, #T_02c27_row2_col6, #T_02c27_row2_col7, #T_02c27_row3_col0, #T_02c27_row3_col1, #T_02c27_row3_col2, #T_02c27_row3_col3, #T_02c27_row3_col4, #T_02c27_row3_col5, #T_02c27_row3_col6, #T_02c27_row3_col7, #T_02c27_row4_col0, #T_02c27_row4_col1, #T_02c27_row4_col2, #T_02c27_row4_col3, #T_02c27_row4_col4, #T_02c27_row4_col5, #T_02c27_row4_col6, #T_02c27_row4_col7, #T_02c27_row5_col0, #T_02c27_row5_col1, #T_02c27_row5_col2, #T_02c27_row5_col3, #T_02c27_row5_col4, #T_02c27_row5_col5, #T_02c27_row5_col6, #T_02c27_row5_col7, #T_02c27_row6_col0, #T_02c27_row6_col1, #T_02c27_row6_col2, #T_02c27_row6_col3, #T_02c27_row6_col4, #T_02c27_row6_col5, #T_02c27_row6_col6, #T_02c27_row6_col7, #T_02c27_row7_col0, #T_02c27_row7_col1, #T_02c27_row7_col2, #T_02c27_row7_col3, #T_02c27_row7_col4, #T_02c27_row7_col5, #T_02c27_row7_col6, #T_02c27_row7_col7, #T_02c27_row8_col0, #T_02c27_row8_col1, #T_02c27_row8_col2, #T_02c27_row8_col3, #T_02c27_row8_col4, #T_02c27_row8_col5, #T_02c27_row8_col6, #T_02c27_row8_col7, #T_02c27_row9_col0, #T_02c27_row9_col1, #T_02c27_row9_col2, #T_02c27_row9_col3, #T_02c27_row9_col4, #T_02c27_row9_col5, #T_02c27_row9_col6, #T_02c27_row9_col7, #T_02c27_row10_col0, #T_02c27_row10_col1, #T_02c27_row10_col2, #T_02c27_row10_col3, #T_02c27_row10_col4, #T_02c27_row10_col5, #T_02c27_row10_col6, #T_02c27_row10_col7, #T_02c27_row11_col0, #T_02c27_row11_col1, #T_02c27_row11_col2, #T_02c27_row11_col3, #T_02c27_row11_col4, #T_02c27_row11_col5, #T_02c27_row11_col6, #T_02c27_row11_col7, #T_02c27_row12_col0, #T_02c27_row12_col1, #T_02c27_row12_col2, #T_02c27_row12_col3, #T_02c27_row12_col4, #T_02c27_row12_col5, #T_02c27_row12_col6, #T_02c27_row12_col7, #T_02c27_row13_col0, #T_02c27_row13_col1, #T_02c27_row13_col2, #T_02c27_row13_col3, #T_02c27_row13_col4, #T_02c27_row13_col5, #T_02c27_row13_col6, #T_02c27_row13_col7, #T_02c27_row14_col0, #T_02c27_row14_col1, #T_02c27_row14_col2, #T_02c27_row14_col3, #T_02c27_row14_col4, #T_02c27_row14_col5, #T_02c27_row14_col6, #T_02c27_row14_col7, #T_02c27_row15_col0, #T_02c27_row15_col1, #T_02c27_row15_col2, #T_02c27_row15_col3, #T_02c27_row15_col4, #T_02c27_row15_col5, #T_02c27_row15_col6, #T_02c27_row15_col7, #T_02c27_row16_col0, #T_02c27_row16_col1, #T_02c27_row16_col2, #T_02c27_row16_col3, #T_02c27_row16_col4, #T_02c27_row16_col5, #T_02c27_row16_col6, #T_02c27_row16_col7, #T_02c27_row17_col0, #T_02c27_row17_col1, #T_02c27_row17_col2, #T_02c27_row17_col3, #T_02c27_row17_col4, #T_02c27_row17_col5, #T_02c27_row17_col6, #T_02c27_row17_col7, #T_02c27_row18_col0, #T_02c27_row18_col1, #T_02c27_row18_col2, #T_02c27_row18_col3, #T_02c27_row18_col4, #T_02c27_row18_col5, #T_02c27_row18_col6, #T_02c27_row18_col7, #T_02c27_row19_col0, #T_02c27_row19_col1, #T_02c27_row19_col2, #T_02c27_row19_col3, #T_02c27_row19_col4, #T_02c27_row19_col5, #T_02c27_row19_col6, #T_02c27_row19_col7, #T_02c27_row20_col0, #T_02c27_row20_col1, #T_02c27_row20_col2, #T_02c27_row20_col3, #T_02c27_row20_col4, #T_02c27_row20_col5, #T_02c27_row20_col6, #T_02c27_row20_col7, #T_02c27_row21_col0, #T_02c27_row21_col1, #T_02c27_row21_col2, #T_02c27_row21_col3, #T_02c27_row21_col4, #T_02c27_row21_col5, #T_02c27_row21_col6, #T_02c27_row21_col7, #T_02c27_row22_col0, #T_02c27_row22_col1, #T_02c27_row22_col2, #T_02c27_row22_col3, #T_02c27_row22_col4, #T_02c27_row22_col5, #T_02c27_row22_col6, #T_02c27_row22_col7, #T_02c27_row23_col0, #T_02c27_row23_col1, #T_02c27_row23_col2, #T_02c27_row23_col3, #T_02c27_row23_col4, #T_02c27_row23_col5, #T_02c27_row23_col6, #T_02c27_row23_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_02c27_row0_col1, #T_02c27_row0_col3, #T_02c27_row0_col6, #T_02c27_row1_col2, #T_02c27_row1_col4, #T_02c27_row1_col5, #T_02c27_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_02c27_row0_col8, #T_02c27_row1_col8, #T_02c27_row2_col8, #T_02c27_row4_col8, #T_02c27_row5_col8, #T_02c27_row6_col8, #T_02c27_row7_col8, #T_02c27_row8_col8, #T_02c27_row9_col8, #T_02c27_row10_col8, #T_02c27_row11_col8, #T_02c27_row12_col8, #T_02c27_row13_col8, #T_02c27_row14_col8, #T_02c27_row15_col8, #T_02c27_row16_col8, #T_02c27_row17_col8, #T_02c27_row18_col8, #T_02c27_row19_col8, #T_02c27_row20_col8, #T_02c27_row22_col8, #T_02c27_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_02c27_row3_col8, #T_02c27_row21_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_02c27\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_02c27_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_02c27_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_02c27_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_02c27_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_02c27_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_02c27_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_02c27_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_02c27_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_02c27_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row0\" class=\"row_heading level0 row0\" >arima</th>\n",
       "      <td id=\"T_02c27_row0_col0\" class=\"data row0 col0\" >ARIMA</td>\n",
       "      <td id=\"T_02c27_row0_col1\" class=\"data row0 col1\" >1.3898</td>\n",
       "      <td id=\"T_02c27_row0_col2\" class=\"data row0 col2\" >1.3054</td>\n",
       "      <td id=\"T_02c27_row0_col3\" class=\"data row0 col3\" >18.6058</td>\n",
       "      <td id=\"T_02c27_row0_col4\" class=\"data row0 col4\" >21.6940</td>\n",
       "      <td id=\"T_02c27_row0_col5\" class=\"data row0 col5\" >0.3874</td>\n",
       "      <td id=\"T_02c27_row0_col6\" class=\"data row0 col6\" >0.3032</td>\n",
       "      <td id=\"T_02c27_row0_col7\" class=\"data row0 col7\" >-2.0504</td>\n",
       "      <td id=\"T_02c27_row0_col8\" class=\"data row0 col8\" >0.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row1\" class=\"row_heading level0 row1\" >grand_means</th>\n",
       "      <td id=\"T_02c27_row1_col0\" class=\"data row1 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_02c27_row1_col1\" class=\"data row1 col1\" >1.3903</td>\n",
       "      <td id=\"T_02c27_row1_col2\" class=\"data row1 col2\" >1.2840</td>\n",
       "      <td id=\"T_02c27_row1_col3\" class=\"data row1 col3\" >18.6120</td>\n",
       "      <td id=\"T_02c27_row1_col4\" class=\"data row1 col4\" >21.3379</td>\n",
       "      <td id=\"T_02c27_row1_col5\" class=\"data row1 col5\" >0.3844</td>\n",
       "      <td id=\"T_02c27_row1_col6\" class=\"data row1 col6\" >0.3037</td>\n",
       "      <td id=\"T_02c27_row1_col7\" class=\"data row1 col7\" >-1.9369</td>\n",
       "      <td id=\"T_02c27_row1_col8\" class=\"data row1 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row2\" class=\"row_heading level0 row2\" >auto_arima</th>\n",
       "      <td id=\"T_02c27_row2_col0\" class=\"data row2 col0\" >Auto ARIMA</td>\n",
       "      <td id=\"T_02c27_row2_col1\" class=\"data row2 col1\" >1.3972</td>\n",
       "      <td id=\"T_02c27_row2_col2\" class=\"data row2 col2\" >1.3138</td>\n",
       "      <td id=\"T_02c27_row2_col3\" class=\"data row2 col3\" >18.7058</td>\n",
       "      <td id=\"T_02c27_row2_col4\" class=\"data row2 col4\" >21.8331</td>\n",
       "      <td id=\"T_02c27_row2_col5\" class=\"data row2 col5\" >0.3893</td>\n",
       "      <td id=\"T_02c27_row2_col6\" class=\"data row2 col6\" >0.3045</td>\n",
       "      <td id=\"T_02c27_row2_col7\" class=\"data row2 col7\" >-2.1082</td>\n",
       "      <td id=\"T_02c27_row2_col8\" class=\"data row2 col8\" >0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row3\" class=\"row_heading level0 row3\" >croston</th>\n",
       "      <td id=\"T_02c27_row3_col0\" class=\"data row3 col0\" >Croston</td>\n",
       "      <td id=\"T_02c27_row3_col1\" class=\"data row3 col1\" >1.4398</td>\n",
       "      <td id=\"T_02c27_row3_col2\" class=\"data row3 col2\" >1.3114</td>\n",
       "      <td id=\"T_02c27_row3_col3\" class=\"data row3 col3\" >19.2751</td>\n",
       "      <td id=\"T_02c27_row3_col4\" class=\"data row3 col4\" >21.7889</td>\n",
       "      <td id=\"T_02c27_row3_col5\" class=\"data row3 col5\" >0.3936</td>\n",
       "      <td id=\"T_02c27_row3_col6\" class=\"data row3 col6\" >0.3121</td>\n",
       "      <td id=\"T_02c27_row3_col7\" class=\"data row3 col7\" >-2.2398</td>\n",
       "      <td id=\"T_02c27_row3_col8\" class=\"data row3 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row4\" class=\"row_heading level0 row4\" >naive</th>\n",
       "      <td id=\"T_02c27_row4_col0\" class=\"data row4 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_02c27_row4_col1\" class=\"data row4 col1\" >1.5782</td>\n",
       "      <td id=\"T_02c27_row4_col2\" class=\"data row4 col2\" >1.4866</td>\n",
       "      <td id=\"T_02c27_row4_col3\" class=\"data row4 col3\" >21.1286</td>\n",
       "      <td id=\"T_02c27_row4_col4\" class=\"data row4 col4\" >24.7074</td>\n",
       "      <td id=\"T_02c27_row4_col5\" class=\"data row4 col5\" >0.4416</td>\n",
       "      <td id=\"T_02c27_row4_col6\" class=\"data row4 col6\" >0.3345</td>\n",
       "      <td id=\"T_02c27_row4_col7\" class=\"data row4 col7\" >-2.8864</td>\n",
       "      <td id=\"T_02c27_row4_col8\" class=\"data row4 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row5\" class=\"row_heading level0 row5\" >knn_cds_dt</th>\n",
       "      <td id=\"T_02c27_row5_col0\" class=\"data row5 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row5_col1\" class=\"data row5 col1\" >1.6255</td>\n",
       "      <td id=\"T_02c27_row5_col2\" class=\"data row5 col2\" >1.3788</td>\n",
       "      <td id=\"T_02c27_row5_col3\" class=\"data row5 col3\" >21.7639</td>\n",
       "      <td id=\"T_02c27_row5_col4\" class=\"data row5 col4\" >22.8885</td>\n",
       "      <td id=\"T_02c27_row5_col5\" class=\"data row5 col5\" >0.4183</td>\n",
       "      <td id=\"T_02c27_row5_col6\" class=\"data row5 col6\" >0.3388</td>\n",
       "      <td id=\"T_02c27_row5_col7\" class=\"data row5 col7\" >-3.4587</td>\n",
       "      <td id=\"T_02c27_row5_col8\" class=\"data row5 col8\" >0.1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row6\" class=\"row_heading level0 row6\" >theta</th>\n",
       "      <td id=\"T_02c27_row6_col0\" class=\"data row6 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_02c27_row6_col1\" class=\"data row6 col1\" >1.6647</td>\n",
       "      <td id=\"T_02c27_row6_col2\" class=\"data row6 col2\" >1.4117</td>\n",
       "      <td id=\"T_02c27_row6_col3\" class=\"data row6 col3\" >22.2885</td>\n",
       "      <td id=\"T_02c27_row6_col4\" class=\"data row6 col4\" >23.4350</td>\n",
       "      <td id=\"T_02c27_row6_col5\" class=\"data row6 col5\" >0.4303</td>\n",
       "      <td id=\"T_02c27_row6_col6\" class=\"data row6 col6\" >0.3469</td>\n",
       "      <td id=\"T_02c27_row6_col7\" class=\"data row6 col7\" >-3.6736</td>\n",
       "      <td id=\"T_02c27_row6_col8\" class=\"data row6 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row7\" class=\"row_heading level0 row7\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_02c27_row7_col0\" class=\"data row7 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row7_col1\" class=\"data row7 col1\" >1.7001</td>\n",
       "      <td id=\"T_02c27_row7_col2\" class=\"data row7 col2\" >1.4993</td>\n",
       "      <td id=\"T_02c27_row7_col3\" class=\"data row7 col3\" >22.7649</td>\n",
       "      <td id=\"T_02c27_row7_col4\" class=\"data row7 col4\" >24.8784</td>\n",
       "      <td id=\"T_02c27_row7_col5\" class=\"data row7 col5\" >0.3925</td>\n",
       "      <td id=\"T_02c27_row7_col6\" class=\"data row7 col6\" >0.3324</td>\n",
       "      <td id=\"T_02c27_row7_col7\" class=\"data row7 col7\" >-5.0370</td>\n",
       "      <td id=\"T_02c27_row7_col8\" class=\"data row7 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row8\" class=\"row_heading level0 row8\" >rf_cds_dt</th>\n",
       "      <td id=\"T_02c27_row8_col0\" class=\"data row8 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row8_col1\" class=\"data row8 col1\" >1.7464</td>\n",
       "      <td id=\"T_02c27_row8_col2\" class=\"data row8 col2\" >1.5324</td>\n",
       "      <td id=\"T_02c27_row8_col3\" class=\"data row8 col3\" >23.3832</td>\n",
       "      <td id=\"T_02c27_row8_col4\" class=\"data row8 col4\" >25.4406</td>\n",
       "      <td id=\"T_02c27_row8_col5\" class=\"data row8 col5\" >0.4457</td>\n",
       "      <td id=\"T_02c27_row8_col6\" class=\"data row8 col6\" >0.3529</td>\n",
       "      <td id=\"T_02c27_row8_col7\" class=\"data row8 col7\" >-4.4537</td>\n",
       "      <td id=\"T_02c27_row8_col8\" class=\"data row8 col8\" >0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row9\" class=\"row_heading level0 row9\" >huber_cds_dt</th>\n",
       "      <td id=\"T_02c27_row9_col0\" class=\"data row9 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row9_col1\" class=\"data row9 col1\" >1.8348</td>\n",
       "      <td id=\"T_02c27_row9_col2\" class=\"data row9 col2\" >1.5858</td>\n",
       "      <td id=\"T_02c27_row9_col3\" class=\"data row9 col3\" >24.5667</td>\n",
       "      <td id=\"T_02c27_row9_col4\" class=\"data row9 col4\" >26.3209</td>\n",
       "      <td id=\"T_02c27_row9_col5\" class=\"data row9 col5\" >0.4813</td>\n",
       "      <td id=\"T_02c27_row9_col6\" class=\"data row9 col6\" >0.3702</td>\n",
       "      <td id=\"T_02c27_row9_col7\" class=\"data row9 col7\" >-5.2081</td>\n",
       "      <td id=\"T_02c27_row9_col8\" class=\"data row9 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row10\" class=\"row_heading level0 row10\" >dt_cds_dt</th>\n",
       "      <td id=\"T_02c27_row10_col0\" class=\"data row10 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row10_col1\" class=\"data row10 col1\" >1.8417</td>\n",
       "      <td id=\"T_02c27_row10_col2\" class=\"data row10 col2\" >1.6154</td>\n",
       "      <td id=\"T_02c27_row10_col3\" class=\"data row10 col3\" >24.6596</td>\n",
       "      <td id=\"T_02c27_row10_col4\" class=\"data row10 col4\" >26.8144</td>\n",
       "      <td id=\"T_02c27_row10_col5\" class=\"data row10 col5\" >0.4425</td>\n",
       "      <td id=\"T_02c27_row10_col6\" class=\"data row10 col6\" >0.3604</td>\n",
       "      <td id=\"T_02c27_row10_col7\" class=\"data row10 col7\" >-5.3015</td>\n",
       "      <td id=\"T_02c27_row10_col8\" class=\"data row10 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row11\" class=\"row_heading level0 row11\" >omp_cds_dt</th>\n",
       "      <td id=\"T_02c27_row11_col0\" class=\"data row11 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row11_col1\" class=\"data row11 col1\" >1.8610</td>\n",
       "      <td id=\"T_02c27_row11_col2\" class=\"data row11 col2\" >1.6200</td>\n",
       "      <td id=\"T_02c27_row11_col3\" class=\"data row11 col3\" >24.9173</td>\n",
       "      <td id=\"T_02c27_row11_col4\" class=\"data row11 col4\" >26.8903</td>\n",
       "      <td id=\"T_02c27_row11_col5\" class=\"data row11 col5\" >0.4905</td>\n",
       "      <td id=\"T_02c27_row11_col6\" class=\"data row11 col6\" >0.3746</td>\n",
       "      <td id=\"T_02c27_row11_col7\" class=\"data row11 col7\" >-5.3467</td>\n",
       "      <td id=\"T_02c27_row11_col8\" class=\"data row11 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row12\" class=\"row_heading level0 row12\" >lr_cds_dt</th>\n",
       "      <td id=\"T_02c27_row12_col0\" class=\"data row12 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row12_col1\" class=\"data row12 col1\" >1.8610</td>\n",
       "      <td id=\"T_02c27_row12_col2\" class=\"data row12 col2\" >1.6200</td>\n",
       "      <td id=\"T_02c27_row12_col3\" class=\"data row12 col3\" >24.9173</td>\n",
       "      <td id=\"T_02c27_row12_col4\" class=\"data row12 col4\" >26.8903</td>\n",
       "      <td id=\"T_02c27_row12_col5\" class=\"data row12 col5\" >0.4905</td>\n",
       "      <td id=\"T_02c27_row12_col6\" class=\"data row12 col6\" >0.3746</td>\n",
       "      <td id=\"T_02c27_row12_col7\" class=\"data row12 col7\" >-5.3467</td>\n",
       "      <td id=\"T_02c27_row12_col8\" class=\"data row12 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row13\" class=\"row_heading level0 row13\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_02c27_row13_col0\" class=\"data row13 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row13_col1\" class=\"data row13 col1\" >1.8610</td>\n",
       "      <td id=\"T_02c27_row13_col2\" class=\"data row13 col2\" >1.6200</td>\n",
       "      <td id=\"T_02c27_row13_col3\" class=\"data row13 col3\" >24.9175</td>\n",
       "      <td id=\"T_02c27_row13_col4\" class=\"data row13 col4\" >26.8904</td>\n",
       "      <td id=\"T_02c27_row13_col5\" class=\"data row13 col5\" >0.4905</td>\n",
       "      <td id=\"T_02c27_row13_col6\" class=\"data row13 col6\" >0.3746</td>\n",
       "      <td id=\"T_02c27_row13_col7\" class=\"data row13 col7\" >-5.3468</td>\n",
       "      <td id=\"T_02c27_row13_col8\" class=\"data row13 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row14\" class=\"row_heading level0 row14\" >en_cds_dt</th>\n",
       "      <td id=\"T_02c27_row14_col0\" class=\"data row14 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row14_col1\" class=\"data row14 col1\" >1.8616</td>\n",
       "      <td id=\"T_02c27_row14_col2\" class=\"data row14 col2\" >1.6202</td>\n",
       "      <td id=\"T_02c27_row14_col3\" class=\"data row14 col3\" >24.9255</td>\n",
       "      <td id=\"T_02c27_row14_col4\" class=\"data row14 col4\" >26.8937</td>\n",
       "      <td id=\"T_02c27_row14_col5\" class=\"data row14 col5\" >0.4906</td>\n",
       "      <td id=\"T_02c27_row14_col6\" class=\"data row14 col6\" >0.3747</td>\n",
       "      <td id=\"T_02c27_row14_col7\" class=\"data row14 col7\" >-5.3507</td>\n",
       "      <td id=\"T_02c27_row14_col8\" class=\"data row14 col8\" >0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row15\" class=\"row_heading level0 row15\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_02c27_row15_col0\" class=\"data row15 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row15_col1\" class=\"data row15 col1\" >1.8620</td>\n",
       "      <td id=\"T_02c27_row15_col2\" class=\"data row15 col2\" >1.6204</td>\n",
       "      <td id=\"T_02c27_row15_col3\" class=\"data row15 col3\" >24.9307</td>\n",
       "      <td id=\"T_02c27_row15_col4\" class=\"data row15 col4\" >26.8970</td>\n",
       "      <td id=\"T_02c27_row15_col5\" class=\"data row15 col5\" >0.4907</td>\n",
       "      <td id=\"T_02c27_row15_col6\" class=\"data row15 col6\" >0.3748</td>\n",
       "      <td id=\"T_02c27_row15_col7\" class=\"data row15 col7\" >-5.3536</td>\n",
       "      <td id=\"T_02c27_row15_col8\" class=\"data row15 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row16\" class=\"row_heading level0 row16\" >llar_cds_dt</th>\n",
       "      <td id=\"T_02c27_row16_col0\" class=\"data row16 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row16_col1\" class=\"data row16 col1\" >1.8620</td>\n",
       "      <td id=\"T_02c27_row16_col2\" class=\"data row16 col2\" >1.6204</td>\n",
       "      <td id=\"T_02c27_row16_col3\" class=\"data row16 col3\" >24.9307</td>\n",
       "      <td id=\"T_02c27_row16_col4\" class=\"data row16 col4\" >26.8970</td>\n",
       "      <td id=\"T_02c27_row16_col5\" class=\"data row16 col5\" >0.4907</td>\n",
       "      <td id=\"T_02c27_row16_col6\" class=\"data row16 col6\" >0.3748</td>\n",
       "      <td id=\"T_02c27_row16_col7\" class=\"data row16 col7\" >-5.3536</td>\n",
       "      <td id=\"T_02c27_row16_col8\" class=\"data row16 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row17\" class=\"row_heading level0 row17\" >br_cds_dt</th>\n",
       "      <td id=\"T_02c27_row17_col0\" class=\"data row17 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row17_col1\" class=\"data row17 col1\" >1.8893</td>\n",
       "      <td id=\"T_02c27_row17_col2\" class=\"data row17 col2\" >1.6338</td>\n",
       "      <td id=\"T_02c27_row17_col3\" class=\"data row17 col3\" >25.2960</td>\n",
       "      <td id=\"T_02c27_row17_col4\" class=\"data row17 col4\" >27.1188</td>\n",
       "      <td id=\"T_02c27_row17_col5\" class=\"data row17 col5\" >0.4959</td>\n",
       "      <td id=\"T_02c27_row17_col6\" class=\"data row17 col6\" >0.3789</td>\n",
       "      <td id=\"T_02c27_row17_col7\" class=\"data row17 col7\" >-5.5427</td>\n",
       "      <td id=\"T_02c27_row17_col8\" class=\"data row17 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row18\" class=\"row_heading level0 row18\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_02c27_row18_col0\" class=\"data row18 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row18_col1\" class=\"data row18 col1\" >1.9120</td>\n",
       "      <td id=\"T_02c27_row18_col2\" class=\"data row18 col2\" >1.6360</td>\n",
       "      <td id=\"T_02c27_row18_col3\" class=\"data row18 col3\" >25.6000</td>\n",
       "      <td id=\"T_02c27_row18_col4\" class=\"data row18 col4\" >27.1550</td>\n",
       "      <td id=\"T_02c27_row18_col5\" class=\"data row18 col5\" >0.4987</td>\n",
       "      <td id=\"T_02c27_row18_col6\" class=\"data row18 col6\" >0.3833</td>\n",
       "      <td id=\"T_02c27_row18_col7\" class=\"data row18 col7\" >-5.5489</td>\n",
       "      <td id=\"T_02c27_row18_col8\" class=\"data row18 col8\" >0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row19\" class=\"row_heading level0 row19\" >exp_smooth</th>\n",
       "      <td id=\"T_02c27_row19_col0\" class=\"data row19 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_02c27_row19_col1\" class=\"data row19 col1\" >1.9165</td>\n",
       "      <td id=\"T_02c27_row19_col2\" class=\"data row19 col2\" >1.6035</td>\n",
       "      <td id=\"T_02c27_row19_col3\" class=\"data row19 col3\" >25.6607</td>\n",
       "      <td id=\"T_02c27_row19_col4\" class=\"data row19 col4\" >26.6100</td>\n",
       "      <td id=\"T_02c27_row19_col5\" class=\"data row19 col5\" >0.4894</td>\n",
       "      <td id=\"T_02c27_row19_col6\" class=\"data row19 col6\" >0.3829</td>\n",
       "      <td id=\"T_02c27_row19_col7\" class=\"data row19 col7\" >-5.6771</td>\n",
       "      <td id=\"T_02c27_row19_col8\" class=\"data row19 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row20\" class=\"row_heading level0 row20\" >ets</th>\n",
       "      <td id=\"T_02c27_row20_col0\" class=\"data row20 col0\" >ETS</td>\n",
       "      <td id=\"T_02c27_row20_col1\" class=\"data row20 col1\" >1.9165</td>\n",
       "      <td id=\"T_02c27_row20_col2\" class=\"data row20 col2\" >1.6035</td>\n",
       "      <td id=\"T_02c27_row20_col3\" class=\"data row20 col3\" >25.6607</td>\n",
       "      <td id=\"T_02c27_row20_col4\" class=\"data row20 col4\" >26.6100</td>\n",
       "      <td id=\"T_02c27_row20_col5\" class=\"data row20 col5\" >0.4894</td>\n",
       "      <td id=\"T_02c27_row20_col6\" class=\"data row20 col6\" >0.3829</td>\n",
       "      <td id=\"T_02c27_row20_col7\" class=\"data row20 col7\" >-5.6771</td>\n",
       "      <td id=\"T_02c27_row20_col8\" class=\"data row20 col8\" >0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row21\" class=\"row_heading level0 row21\" >polytrend</th>\n",
       "      <td id=\"T_02c27_row21_col0\" class=\"data row21 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_02c27_row21_col1\" class=\"data row21 col1\" >1.9408</td>\n",
       "      <td id=\"T_02c27_row21_col2\" class=\"data row21 col2\" >1.6593</td>\n",
       "      <td id=\"T_02c27_row21_col3\" class=\"data row21 col3\" >25.9864</td>\n",
       "      <td id=\"T_02c27_row21_col4\" class=\"data row21 col4\" >27.5399</td>\n",
       "      <td id=\"T_02c27_row21_col5\" class=\"data row21 col5\" >0.5057</td>\n",
       "      <td id=\"T_02c27_row21_col6\" class=\"data row21 col6\" >0.3873</td>\n",
       "      <td id=\"T_02c27_row21_col7\" class=\"data row21 col7\" >-5.8038</td>\n",
       "      <td id=\"T_02c27_row21_col8\" class=\"data row21 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row22\" class=\"row_heading level0 row22\" >et_cds_dt</th>\n",
       "      <td id=\"T_02c27_row22_col0\" class=\"data row22 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row22_col1\" class=\"data row22 col1\" >2.1134</td>\n",
       "      <td id=\"T_02c27_row22_col2\" class=\"data row22 col2\" >1.8798</td>\n",
       "      <td id=\"T_02c27_row22_col3\" class=\"data row22 col3\" >28.2935</td>\n",
       "      <td id=\"T_02c27_row22_col4\" class=\"data row22 col4\" >31.2344</td>\n",
       "      <td id=\"T_02c27_row22_col5\" class=\"data row22 col5\" >0.5489</td>\n",
       "      <td id=\"T_02c27_row22_col6\" class=\"data row22 col6\" >0.4159</td>\n",
       "      <td id=\"T_02c27_row22_col7\" class=\"data row22 col7\" >-5.5128</td>\n",
       "      <td id=\"T_02c27_row22_col8\" class=\"data row22 col8\" >0.2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_02c27_level0_row23\" class=\"row_heading level0 row23\" >ada_cds_dt</th>\n",
       "      <td id=\"T_02c27_row23_col0\" class=\"data row23 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_02c27_row23_col1\" class=\"data row23 col1\" >2.2348</td>\n",
       "      <td id=\"T_02c27_row23_col2\" class=\"data row23 col2\" >2.0103</td>\n",
       "      <td id=\"T_02c27_row23_col3\" class=\"data row23 col3\" >29.9237</td>\n",
       "      <td id=\"T_02c27_row23_col4\" class=\"data row23 col4\" >33.3491</td>\n",
       "      <td id=\"T_02c27_row23_col5\" class=\"data row23 col5\" >0.5788</td>\n",
       "      <td id=\"T_02c27_row23_col6\" class=\"data row23 col6\" >0.4158</td>\n",
       "      <td id=\"T_02c27_row23_col7\" class=\"data row23 col7\" >-10.6104</td>\n",
       "      <td id=\"T_02c27_row23_col8\" class=\"data row23 col8\" >0.1450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cab7ddff0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_439d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_439d3_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_439d3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_439d3_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_439d3_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_439d3_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_439d3_row1_col1\" class=\"data row1 col1\" >WeightedAverageFare(SGD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_439d3_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_439d3_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_439d3_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_439d3_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_439d3_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_439d3_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_439d3_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_439d3_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_439d3_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_439d3_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_439d3_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_439d3_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_439d3_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_439d3_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_439d3_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_439d3_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_439d3_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_439d3_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_439d3_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_439d3_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_439d3_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_439d3_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_439d3_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_439d3_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_439d3_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_439d3_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_439d3_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_439d3_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_439d3_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_439d3_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_439d3_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_439d3_row17_col1\" class=\"data row17 col1\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_439d3_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_439d3_row18_col1\" class=\"data row18 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_439d3_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_439d3_row19_col1\" class=\"data row19 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_439d3_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_439d3_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_439d3_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_439d3_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_439d3_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_439d3_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_439d3_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_439d3_row23_col1\" class=\"data row23 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_439d3_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_439d3_row24_col1\" class=\"data row24 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_439d3_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_439d3_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_439d3_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_439d3_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_439d3_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_439d3_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_439d3_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_439d3_row28_col1\" class=\"data row28 col1\" >No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_439d3_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_439d3_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_439d3_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_439d3_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_439d3_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_439d3_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_439d3_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_439d3_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_439d3_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_439d3_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_439d3_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_439d3_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_439d3_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_439d3_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_439d3_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_439d3_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_439d3_row36_col1\" class=\"data row36 col1\" >2f05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc7278b20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_01194 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_01194_row0_col0, #T_01194_row0_col2, #T_01194_row0_col4, #T_01194_row0_col5, #T_01194_row0_col7, #T_01194_row1_col0, #T_01194_row1_col2, #T_01194_row1_col4, #T_01194_row1_col5, #T_01194_row1_col7, #T_01194_row2_col0, #T_01194_row2_col1, #T_01194_row2_col3, #T_01194_row2_col6, #T_01194_row3_col0, #T_01194_row3_col1, #T_01194_row3_col2, #T_01194_row3_col3, #T_01194_row3_col4, #T_01194_row3_col5, #T_01194_row3_col6, #T_01194_row3_col7, #T_01194_row4_col0, #T_01194_row4_col1, #T_01194_row4_col2, #T_01194_row4_col3, #T_01194_row4_col4, #T_01194_row4_col5, #T_01194_row4_col6, #T_01194_row4_col7, #T_01194_row5_col0, #T_01194_row5_col1, #T_01194_row5_col2, #T_01194_row5_col3, #T_01194_row5_col4, #T_01194_row5_col5, #T_01194_row5_col6, #T_01194_row5_col7, #T_01194_row6_col0, #T_01194_row6_col1, #T_01194_row6_col2, #T_01194_row6_col3, #T_01194_row6_col4, #T_01194_row6_col5, #T_01194_row6_col6, #T_01194_row6_col7, #T_01194_row7_col0, #T_01194_row7_col1, #T_01194_row7_col2, #T_01194_row7_col3, #T_01194_row7_col4, #T_01194_row7_col5, #T_01194_row7_col6, #T_01194_row7_col7, #T_01194_row8_col0, #T_01194_row8_col1, #T_01194_row8_col2, #T_01194_row8_col3, #T_01194_row8_col4, #T_01194_row8_col5, #T_01194_row8_col6, #T_01194_row8_col7, #T_01194_row9_col0, #T_01194_row9_col1, #T_01194_row9_col2, #T_01194_row9_col3, #T_01194_row9_col4, #T_01194_row9_col5, #T_01194_row9_col6, #T_01194_row9_col7, #T_01194_row10_col0, #T_01194_row10_col1, #T_01194_row10_col2, #T_01194_row10_col3, #T_01194_row10_col4, #T_01194_row10_col5, #T_01194_row10_col6, #T_01194_row10_col7, #T_01194_row11_col0, #T_01194_row11_col1, #T_01194_row11_col2, #T_01194_row11_col3, #T_01194_row11_col4, #T_01194_row11_col5, #T_01194_row11_col6, #T_01194_row11_col7, #T_01194_row12_col0, #T_01194_row12_col1, #T_01194_row12_col2, #T_01194_row12_col3, #T_01194_row12_col4, #T_01194_row12_col5, #T_01194_row12_col6, #T_01194_row12_col7, #T_01194_row13_col0, #T_01194_row13_col1, #T_01194_row13_col2, #T_01194_row13_col3, #T_01194_row13_col4, #T_01194_row13_col5, #T_01194_row13_col6, #T_01194_row13_col7, #T_01194_row14_col0, #T_01194_row14_col1, #T_01194_row14_col2, #T_01194_row14_col3, #T_01194_row14_col4, #T_01194_row14_col5, #T_01194_row14_col6, #T_01194_row14_col7, #T_01194_row15_col0, #T_01194_row15_col1, #T_01194_row15_col2, #T_01194_row15_col3, #T_01194_row15_col4, #T_01194_row15_col5, #T_01194_row15_col6, #T_01194_row15_col7, #T_01194_row16_col0, #T_01194_row16_col1, #T_01194_row16_col2, #T_01194_row16_col3, #T_01194_row16_col4, #T_01194_row16_col5, #T_01194_row16_col6, #T_01194_row16_col7, #T_01194_row17_col0, #T_01194_row17_col1, #T_01194_row17_col2, #T_01194_row17_col3, #T_01194_row17_col4, #T_01194_row17_col5, #T_01194_row17_col6, #T_01194_row17_col7, #T_01194_row18_col0, #T_01194_row18_col1, #T_01194_row18_col2, #T_01194_row18_col3, #T_01194_row18_col4, #T_01194_row18_col5, #T_01194_row18_col6, #T_01194_row18_col7, #T_01194_row19_col0, #T_01194_row19_col1, #T_01194_row19_col2, #T_01194_row19_col3, #T_01194_row19_col4, #T_01194_row19_col5, #T_01194_row19_col6, #T_01194_row19_col7, #T_01194_row20_col0, #T_01194_row20_col1, #T_01194_row20_col2, #T_01194_row20_col3, #T_01194_row20_col4, #T_01194_row20_col5, #T_01194_row20_col6, #T_01194_row20_col7, #T_01194_row21_col0, #T_01194_row21_col1, #T_01194_row21_col2, #T_01194_row21_col3, #T_01194_row21_col4, #T_01194_row21_col5, #T_01194_row21_col6, #T_01194_row21_col7, #T_01194_row22_col0, #T_01194_row22_col1, #T_01194_row22_col2, #T_01194_row22_col3, #T_01194_row22_col4, #T_01194_row22_col5, #T_01194_row22_col6, #T_01194_row22_col7, #T_01194_row23_col0, #T_01194_row23_col1, #T_01194_row23_col2, #T_01194_row23_col3, #T_01194_row23_col4, #T_01194_row23_col5, #T_01194_row23_col6, #T_01194_row23_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_01194_row0_col1, #T_01194_row0_col3, #T_01194_row0_col6, #T_01194_row1_col1, #T_01194_row1_col3, #T_01194_row1_col6, #T_01194_row2_col2, #T_01194_row2_col4, #T_01194_row2_col5, #T_01194_row2_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_01194_row0_col8, #T_01194_row1_col8, #T_01194_row2_col8, #T_01194_row4_col8, #T_01194_row5_col8, #T_01194_row6_col8, #T_01194_row7_col8, #T_01194_row8_col8, #T_01194_row9_col8, #T_01194_row10_col8, #T_01194_row11_col8, #T_01194_row12_col8, #T_01194_row13_col8, #T_01194_row14_col8, #T_01194_row15_col8, #T_01194_row16_col8, #T_01194_row17_col8, #T_01194_row18_col8, #T_01194_row19_col8, #T_01194_row20_col8, #T_01194_row21_col8, #T_01194_row22_col8, #T_01194_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_01194_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_01194\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_01194_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_01194_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_01194_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_01194_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_01194_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_01194_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_01194_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_01194_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_01194_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row0\" class=\"row_heading level0 row0\" >arima</th>\n",
       "      <td id=\"T_01194_row0_col0\" class=\"data row0 col0\" >ARIMA</td>\n",
       "      <td id=\"T_01194_row0_col1\" class=\"data row0 col1\" >1.2284</td>\n",
       "      <td id=\"T_01194_row0_col2\" class=\"data row0 col2\" >1.1490</td>\n",
       "      <td id=\"T_01194_row0_col3\" class=\"data row0 col3\" >18.1296</td>\n",
       "      <td id=\"T_01194_row0_col4\" class=\"data row0 col4\" >21.0172</td>\n",
       "      <td id=\"T_01194_row0_col5\" class=\"data row0 col5\" >0.3644</td>\n",
       "      <td id=\"T_01194_row0_col6\" class=\"data row0 col6\" >0.2871</td>\n",
       "      <td id=\"T_01194_row0_col7\" class=\"data row0 col7\" >-1.7221</td>\n",
       "      <td id=\"T_01194_row0_col8\" class=\"data row0 col8\" >0.0650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row1\" class=\"row_heading level0 row1\" >auto_arima</th>\n",
       "      <td id=\"T_01194_row1_col0\" class=\"data row1 col0\" >Auto ARIMA</td>\n",
       "      <td id=\"T_01194_row1_col1\" class=\"data row1 col1\" >1.2284</td>\n",
       "      <td id=\"T_01194_row1_col2\" class=\"data row1 col2\" >1.1490</td>\n",
       "      <td id=\"T_01194_row1_col3\" class=\"data row1 col3\" >18.1296</td>\n",
       "      <td id=\"T_01194_row1_col4\" class=\"data row1 col4\" >21.0172</td>\n",
       "      <td id=\"T_01194_row1_col5\" class=\"data row1 col5\" >0.3644</td>\n",
       "      <td id=\"T_01194_row1_col6\" class=\"data row1 col6\" >0.2871</td>\n",
       "      <td id=\"T_01194_row1_col7\" class=\"data row1 col7\" >-1.7221</td>\n",
       "      <td id=\"T_01194_row1_col8\" class=\"data row1 col8\" >0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row2\" class=\"row_heading level0 row2\" >grand_means</th>\n",
       "      <td id=\"T_01194_row2_col0\" class=\"data row2 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_01194_row2_col1\" class=\"data row2 col1\" >1.2311</td>\n",
       "      <td id=\"T_01194_row2_col2\" class=\"data row2 col2\" >1.1295</td>\n",
       "      <td id=\"T_01194_row2_col3\" class=\"data row2 col3\" >18.1634</td>\n",
       "      <td id=\"T_01194_row2_col4\" class=\"data row2 col4\" >20.6553</td>\n",
       "      <td id=\"T_01194_row2_col5\" class=\"data row2 col5\" >0.3616</td>\n",
       "      <td id=\"T_01194_row2_col6\" class=\"data row2 col6\" >0.2879</td>\n",
       "      <td id=\"T_01194_row2_col7\" class=\"data row2 col7\" >-1.6068</td>\n",
       "      <td id=\"T_01194_row2_col8\" class=\"data row2 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row3\" class=\"row_heading level0 row3\" >croston</th>\n",
       "      <td id=\"T_01194_row3_col0\" class=\"data row3 col0\" >Croston</td>\n",
       "      <td id=\"T_01194_row3_col1\" class=\"data row3 col1\" >1.2759</td>\n",
       "      <td id=\"T_01194_row3_col2\" class=\"data row3 col2\" >1.1737</td>\n",
       "      <td id=\"T_01194_row3_col3\" class=\"data row3 col3\" >18.8357</td>\n",
       "      <td id=\"T_01194_row3_col4\" class=\"data row3 col4\" >21.4940</td>\n",
       "      <td id=\"T_01194_row3_col5\" class=\"data row3 col5\" >0.3728</td>\n",
       "      <td id=\"T_01194_row3_col6\" class=\"data row3 col6\" >0.2963</td>\n",
       "      <td id=\"T_01194_row3_col7\" class=\"data row3 col7\" >-2.0108</td>\n",
       "      <td id=\"T_01194_row3_col8\" class=\"data row3 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row4\" class=\"row_heading level0 row4\" >naive</th>\n",
       "      <td id=\"T_01194_row4_col0\" class=\"data row4 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_01194_row4_col1\" class=\"data row4 col1\" >1.3962</td>\n",
       "      <td id=\"T_01194_row4_col2\" class=\"data row4 col2\" >1.3225</td>\n",
       "      <td id=\"T_01194_row4_col3\" class=\"data row4 col3\" >20.5984</td>\n",
       "      <td id=\"T_01194_row4_col4\" class=\"data row4 col4\" >24.1764</td>\n",
       "      <td id=\"T_01194_row4_col5\" class=\"data row4 col5\" >0.4181</td>\n",
       "      <td id=\"T_01194_row4_col6\" class=\"data row4 col6\" >0.3171</td>\n",
       "      <td id=\"T_01194_row4_col7\" class=\"data row4 col7\" >-2.5115</td>\n",
       "      <td id=\"T_01194_row4_col8\" class=\"data row4 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row5\" class=\"row_heading level0 row5\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_01194_row5_col0\" class=\"data row5 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row5_col1\" class=\"data row5 col1\" >1.4197</td>\n",
       "      <td id=\"T_01194_row5_col2\" class=\"data row5 col2\" >1.3044</td>\n",
       "      <td id=\"T_01194_row5_col3\" class=\"data row5 col3\" >21.0847</td>\n",
       "      <td id=\"T_01194_row5_col4\" class=\"data row5 col4\" >24.1241</td>\n",
       "      <td id=\"T_01194_row5_col5\" class=\"data row5 col5\" >0.3699</td>\n",
       "      <td id=\"T_01194_row5_col6\" class=\"data row5 col6\" >0.3011</td>\n",
       "      <td id=\"T_01194_row5_col7\" class=\"data row5 col7\" >-5.4262</td>\n",
       "      <td id=\"T_01194_row5_col8\" class=\"data row5 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row6\" class=\"row_heading level0 row6\" >theta</th>\n",
       "      <td id=\"T_01194_row6_col0\" class=\"data row6 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_01194_row6_col1\" class=\"data row6 col1\" >1.5235</td>\n",
       "      <td id=\"T_01194_row6_col2\" class=\"data row6 col2\" >1.3135</td>\n",
       "      <td id=\"T_01194_row6_col3\" class=\"data row6 col3\" >22.5529</td>\n",
       "      <td id=\"T_01194_row6_col4\" class=\"data row6 col4\" >24.1531</td>\n",
       "      <td id=\"T_01194_row6_col5\" class=\"data row6 col5\" >0.4252</td>\n",
       "      <td id=\"T_01194_row6_col6\" class=\"data row6 col6\" >0.3395</td>\n",
       "      <td id=\"T_01194_row6_col7\" class=\"data row6 col7\" >-3.7082</td>\n",
       "      <td id=\"T_01194_row6_col8\" class=\"data row6 col8\" >0.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row7\" class=\"row_heading level0 row7\" >dt_cds_dt</th>\n",
       "      <td id=\"T_01194_row7_col0\" class=\"data row7 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row7_col1\" class=\"data row7 col1\" >1.6200</td>\n",
       "      <td id=\"T_01194_row7_col2\" class=\"data row7 col2\" >1.4929</td>\n",
       "      <td id=\"T_01194_row7_col3\" class=\"data row7 col3\" >24.0055</td>\n",
       "      <td id=\"T_01194_row7_col4\" class=\"data row7 col4\" >27.5088</td>\n",
       "      <td id=\"T_01194_row7_col5\" class=\"data row7 col5\" >0.4328</td>\n",
       "      <td id=\"T_01194_row7_col6\" class=\"data row7 col6\" >0.3448</td>\n",
       "      <td id=\"T_01194_row7_col7\" class=\"data row7 col7\" >-5.8182</td>\n",
       "      <td id=\"T_01194_row7_col8\" class=\"data row7 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row8\" class=\"row_heading level0 row8\" >knn_cds_dt</th>\n",
       "      <td id=\"T_01194_row8_col0\" class=\"data row8 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row8_col1\" class=\"data row8 col1\" >1.6407</td>\n",
       "      <td id=\"T_01194_row8_col2\" class=\"data row8 col2\" >1.4203</td>\n",
       "      <td id=\"T_01194_row8_col3\" class=\"data row8 col3\" >24.3133</td>\n",
       "      <td id=\"T_01194_row8_col4\" class=\"data row8 col4\" >26.1455</td>\n",
       "      <td id=\"T_01194_row8_col5\" class=\"data row8 col5\" >0.4536</td>\n",
       "      <td id=\"T_01194_row8_col6\" class=\"data row8 col6\" >0.3575</td>\n",
       "      <td id=\"T_01194_row8_col7\" class=\"data row8 col7\" >-4.8511</td>\n",
       "      <td id=\"T_01194_row8_col8\" class=\"data row8 col8\" >0.1650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row9\" class=\"row_heading level0 row9\" >ada_cds_dt</th>\n",
       "      <td id=\"T_01194_row9_col0\" class=\"data row9 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row9_col1\" class=\"data row9 col1\" >1.6510</td>\n",
       "      <td id=\"T_01194_row9_col2\" class=\"data row9 col2\" >1.4391</td>\n",
       "      <td id=\"T_01194_row9_col3\" class=\"data row9 col3\" >24.4126</td>\n",
       "      <td id=\"T_01194_row9_col4\" class=\"data row9 col4\" >26.4064</td>\n",
       "      <td id=\"T_01194_row9_col5\" class=\"data row9 col5\" >0.4622</td>\n",
       "      <td id=\"T_01194_row9_col6\" class=\"data row9 col6\" >0.3612</td>\n",
       "      <td id=\"T_01194_row9_col7\" class=\"data row9 col7\" >-4.0171</td>\n",
       "      <td id=\"T_01194_row9_col8\" class=\"data row9 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row10\" class=\"row_heading level0 row10\" >rf_cds_dt</th>\n",
       "      <td id=\"T_01194_row10_col0\" class=\"data row10 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row10_col1\" class=\"data row10 col1\" >1.7756</td>\n",
       "      <td id=\"T_01194_row10_col2\" class=\"data row10 col2\" >1.5556</td>\n",
       "      <td id=\"T_01194_row10_col3\" class=\"data row10 col3\" >26.3137</td>\n",
       "      <td id=\"T_01194_row10_col4\" class=\"data row10 col4\" >28.6624</td>\n",
       "      <td id=\"T_01194_row10_col5\" class=\"data row10 col5\" >0.4898</td>\n",
       "      <td id=\"T_01194_row10_col6\" class=\"data row10 col6\" >0.3777</td>\n",
       "      <td id=\"T_01194_row10_col7\" class=\"data row10 col7\" >-6.3730</td>\n",
       "      <td id=\"T_01194_row10_col8\" class=\"data row10 col8\" >0.2450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row11\" class=\"row_heading level0 row11\" >huber_cds_dt</th>\n",
       "      <td id=\"T_01194_row11_col0\" class=\"data row11 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row11_col1\" class=\"data row11 col1\" >1.7953</td>\n",
       "      <td id=\"T_01194_row11_col2\" class=\"data row11 col2\" >1.5694</td>\n",
       "      <td id=\"T_01194_row11_col3\" class=\"data row11 col3\" >26.6253</td>\n",
       "      <td id=\"T_01194_row11_col4\" class=\"data row11 col4\" >28.9127</td>\n",
       "      <td id=\"T_01194_row11_col5\" class=\"data row11 col5\" >0.5031</td>\n",
       "      <td id=\"T_01194_row11_col6\" class=\"data row11 col6\" >0.3809</td>\n",
       "      <td id=\"T_01194_row11_col7\" class=\"data row11 col7\" >-6.4647</td>\n",
       "      <td id=\"T_01194_row11_col8\" class=\"data row11 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row12\" class=\"row_heading level0 row12\" >omp_cds_dt</th>\n",
       "      <td id=\"T_01194_row12_col0\" class=\"data row12 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row12_col1\" class=\"data row12 col1\" >1.8093</td>\n",
       "      <td id=\"T_01194_row12_col2\" class=\"data row12 col2\" >1.5955</td>\n",
       "      <td id=\"T_01194_row12_col3\" class=\"data row12 col3\" >26.8289</td>\n",
       "      <td id=\"T_01194_row12_col4\" class=\"data row12 col4\" >29.3798</td>\n",
       "      <td id=\"T_01194_row12_col5\" class=\"data row12 col5\" >0.5099</td>\n",
       "      <td id=\"T_01194_row12_col6\" class=\"data row12 col6\" >0.3836</td>\n",
       "      <td id=\"T_01194_row12_col7\" class=\"data row12 col7\" >-6.4951</td>\n",
       "      <td id=\"T_01194_row12_col8\" class=\"data row12 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row13\" class=\"row_heading level0 row13\" >lr_cds_dt</th>\n",
       "      <td id=\"T_01194_row13_col0\" class=\"data row13 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row13_col1\" class=\"data row13 col1\" >1.8093</td>\n",
       "      <td id=\"T_01194_row13_col2\" class=\"data row13 col2\" >1.5955</td>\n",
       "      <td id=\"T_01194_row13_col3\" class=\"data row13 col3\" >26.8289</td>\n",
       "      <td id=\"T_01194_row13_col4\" class=\"data row13 col4\" >29.3798</td>\n",
       "      <td id=\"T_01194_row13_col5\" class=\"data row13 col5\" >0.5099</td>\n",
       "      <td id=\"T_01194_row13_col6\" class=\"data row13 col6\" >0.3836</td>\n",
       "      <td id=\"T_01194_row13_col7\" class=\"data row13 col7\" >-6.4951</td>\n",
       "      <td id=\"T_01194_row13_col8\" class=\"data row13 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row14\" class=\"row_heading level0 row14\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_01194_row14_col0\" class=\"data row14 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row14_col1\" class=\"data row14 col1\" >1.8094</td>\n",
       "      <td id=\"T_01194_row14_col2\" class=\"data row14 col2\" >1.5955</td>\n",
       "      <td id=\"T_01194_row14_col3\" class=\"data row14 col3\" >26.8291</td>\n",
       "      <td id=\"T_01194_row14_col4\" class=\"data row14 col4\" >29.3799</td>\n",
       "      <td id=\"T_01194_row14_col5\" class=\"data row14 col5\" >0.5099</td>\n",
       "      <td id=\"T_01194_row14_col6\" class=\"data row14 col6\" >0.3836</td>\n",
       "      <td id=\"T_01194_row14_col7\" class=\"data row14 col7\" >-6.4953</td>\n",
       "      <td id=\"T_01194_row14_col8\" class=\"data row14 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row15\" class=\"row_heading level0 row15\" >en_cds_dt</th>\n",
       "      <td id=\"T_01194_row15_col0\" class=\"data row15 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row15_col1\" class=\"data row15 col1\" >1.8099</td>\n",
       "      <td id=\"T_01194_row15_col2\" class=\"data row15 col2\" >1.5958</td>\n",
       "      <td id=\"T_01194_row15_col3\" class=\"data row15 col3\" >26.8373</td>\n",
       "      <td id=\"T_01194_row15_col4\" class=\"data row15 col4\" >29.3848</td>\n",
       "      <td id=\"T_01194_row15_col5\" class=\"data row15 col5\" >0.5100</td>\n",
       "      <td id=\"T_01194_row15_col6\" class=\"data row15 col6\" >0.3837</td>\n",
       "      <td id=\"T_01194_row15_col7\" class=\"data row15 col7\" >-6.5004</td>\n",
       "      <td id=\"T_01194_row15_col8\" class=\"data row15 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row16\" class=\"row_heading level0 row16\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_01194_row16_col0\" class=\"data row16 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row16_col1\" class=\"data row16 col1\" >1.8103</td>\n",
       "      <td id=\"T_01194_row16_col2\" class=\"data row16 col2\" >1.5960</td>\n",
       "      <td id=\"T_01194_row16_col3\" class=\"data row16 col3\" >26.8427</td>\n",
       "      <td id=\"T_01194_row16_col4\" class=\"data row16 col4\" >29.3888</td>\n",
       "      <td id=\"T_01194_row16_col5\" class=\"data row16 col5\" >0.5101</td>\n",
       "      <td id=\"T_01194_row16_col6\" class=\"data row16 col6\" >0.3837</td>\n",
       "      <td id=\"T_01194_row16_col7\" class=\"data row16 col7\" >-6.5039</td>\n",
       "      <td id=\"T_01194_row16_col8\" class=\"data row16 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row17\" class=\"row_heading level0 row17\" >llar_cds_dt</th>\n",
       "      <td id=\"T_01194_row17_col0\" class=\"data row17 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row17_col1\" class=\"data row17 col1\" >1.8103</td>\n",
       "      <td id=\"T_01194_row17_col2\" class=\"data row17 col2\" >1.5960</td>\n",
       "      <td id=\"T_01194_row17_col3\" class=\"data row17 col3\" >26.8427</td>\n",
       "      <td id=\"T_01194_row17_col4\" class=\"data row17 col4\" >29.3888</td>\n",
       "      <td id=\"T_01194_row17_col5\" class=\"data row17 col5\" >0.5101</td>\n",
       "      <td id=\"T_01194_row17_col6\" class=\"data row17 col6\" >0.3837</td>\n",
       "      <td id=\"T_01194_row17_col7\" class=\"data row17 col7\" >-6.5039</td>\n",
       "      <td id=\"T_01194_row17_col8\" class=\"data row17 col8\" >0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row18\" class=\"row_heading level0 row18\" >br_cds_dt</th>\n",
       "      <td id=\"T_01194_row18_col0\" class=\"data row18 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row18_col1\" class=\"data row18 col1\" >1.8435</td>\n",
       "      <td id=\"T_01194_row18_col2\" class=\"data row18 col2\" >1.6160</td>\n",
       "      <td id=\"T_01194_row18_col3\" class=\"data row18 col3\" >27.3402</td>\n",
       "      <td id=\"T_01194_row18_col4\" class=\"data row18 col4\" >29.7656</td>\n",
       "      <td id=\"T_01194_row18_col5\" class=\"data row18 col5\" >0.5176</td>\n",
       "      <td id=\"T_01194_row18_col6\" class=\"data row18 col6\" >0.3889</td>\n",
       "      <td id=\"T_01194_row18_col7\" class=\"data row18 col7\" >-6.8305</td>\n",
       "      <td id=\"T_01194_row18_col8\" class=\"data row18 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row19\" class=\"row_heading level0 row19\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_01194_row19_col0\" class=\"data row19 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row19_col1\" class=\"data row19 col1\" >1.8608</td>\n",
       "      <td id=\"T_01194_row19_col2\" class=\"data row19 col2\" >1.6161</td>\n",
       "      <td id=\"T_01194_row19_col3\" class=\"data row19 col3\" >27.5911</td>\n",
       "      <td id=\"T_01194_row19_col4\" class=\"data row19 col4\" >29.7686</td>\n",
       "      <td id=\"T_01194_row19_col5\" class=\"data row19 col5\" >0.5199</td>\n",
       "      <td id=\"T_01194_row19_col6\" class=\"data row19 col6\" >0.3923</td>\n",
       "      <td id=\"T_01194_row19_col7\" class=\"data row19 col7\" >-6.8330</td>\n",
       "      <td id=\"T_01194_row19_col8\" class=\"data row19 col8\" >0.1300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row20\" class=\"row_heading level0 row20\" >exp_smooth</th>\n",
       "      <td id=\"T_01194_row20_col0\" class=\"data row20 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_01194_row20_col1\" class=\"data row20 col1\" >1.8692</td>\n",
       "      <td id=\"T_01194_row20_col2\" class=\"data row20 col2\" >1.5791</td>\n",
       "      <td id=\"T_01194_row20_col3\" class=\"data row20 col3\" >27.7265</td>\n",
       "      <td id=\"T_01194_row20_col4\" class=\"data row20 col4\" >29.1237</td>\n",
       "      <td id=\"T_01194_row20_col5\" class=\"data row20 col5\" >0.5117</td>\n",
       "      <td id=\"T_01194_row20_col6\" class=\"data row20 col6\" >0.3932</td>\n",
       "      <td id=\"T_01194_row20_col7\" class=\"data row20 col7\" >-7.0360</td>\n",
       "      <td id=\"T_01194_row20_col8\" class=\"data row20 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row21\" class=\"row_heading level0 row21\" >ets</th>\n",
       "      <td id=\"T_01194_row21_col0\" class=\"data row21 col0\" >ETS</td>\n",
       "      <td id=\"T_01194_row21_col1\" class=\"data row21 col1\" >1.8692</td>\n",
       "      <td id=\"T_01194_row21_col2\" class=\"data row21 col2\" >1.5792</td>\n",
       "      <td id=\"T_01194_row21_col3\" class=\"data row21 col3\" >27.7272</td>\n",
       "      <td id=\"T_01194_row21_col4\" class=\"data row21 col4\" >29.1247</td>\n",
       "      <td id=\"T_01194_row21_col5\" class=\"data row21 col5\" >0.5117</td>\n",
       "      <td id=\"T_01194_row21_col6\" class=\"data row21 col6\" >0.3932</td>\n",
       "      <td id=\"T_01194_row21_col7\" class=\"data row21 col7\" >-7.0363</td>\n",
       "      <td id=\"T_01194_row21_col8\" class=\"data row21 col8\" >0.0550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row22\" class=\"row_heading level0 row22\" >polytrend</th>\n",
       "      <td id=\"T_01194_row22_col0\" class=\"data row22 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_01194_row22_col1\" class=\"data row22 col1\" >1.8930</td>\n",
       "      <td id=\"T_01194_row22_col2\" class=\"data row22 col2\" >1.6432</td>\n",
       "      <td id=\"T_01194_row22_col3\" class=\"data row22 col3\" >28.0740</td>\n",
       "      <td id=\"T_01194_row22_col4\" class=\"data row22 col4\" >30.2739</td>\n",
       "      <td id=\"T_01194_row22_col5\" class=\"data row22 col5\" >0.5283</td>\n",
       "      <td id=\"T_01194_row22_col6\" class=\"data row22 col6\" >0.3970</td>\n",
       "      <td id=\"T_01194_row22_col7\" class=\"data row22 col7\" >-7.1962</td>\n",
       "      <td id=\"T_01194_row22_col8\" class=\"data row22 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01194_level0_row23\" class=\"row_heading level0 row23\" >et_cds_dt</th>\n",
       "      <td id=\"T_01194_row23_col0\" class=\"data row23 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_01194_row23_col1\" class=\"data row23 col1\" >1.9695</td>\n",
       "      <td id=\"T_01194_row23_col2\" class=\"data row23 col2\" >1.8435</td>\n",
       "      <td id=\"T_01194_row23_col3\" class=\"data row23 col3\" >29.0815</td>\n",
       "      <td id=\"T_01194_row23_col4\" class=\"data row23 col4\" >33.7596</td>\n",
       "      <td id=\"T_01194_row23_col5\" class=\"data row23 col5\" >0.5678</td>\n",
       "      <td id=\"T_01194_row23_col6\" class=\"data row23 col6\" >0.4080</td>\n",
       "      <td id=\"T_01194_row23_col7\" class=\"data row23 col7\" >-6.4308</td>\n",
       "      <td id=\"T_01194_row23_col8\" class=\"data row23 col8\" >0.2150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc7159510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_204a7_row28_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_204a7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_204a7_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_204a7_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_204a7_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_204a7_row0_col1\" class=\"data row0 col1\" >42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_204a7_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_204a7_row1_col1\" class=\"data row1 col1\" >TotalSeatsSold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_204a7_row2_col0\" class=\"data row2 col0\" >Approach</td>\n",
       "      <td id=\"T_204a7_row2_col1\" class=\"data row2 col1\" >Univariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_204a7_row3_col0\" class=\"data row3 col0\" >Exogenous Variables</td>\n",
       "      <td id=\"T_204a7_row3_col1\" class=\"data row3 col1\" >Not Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_204a7_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_204a7_row4_col1\" class=\"data row4 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_204a7_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_204a7_row5_col1\" class=\"data row5 col1\" >(30, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_204a7_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_204a7_row6_col1\" class=\"data row6 col1\" >(25, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_204a7_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_204a7_row7_col1\" class=\"data row7 col1\" >(5, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_204a7_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_204a7_row8_col1\" class=\"data row8 col1\" >0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_204a7_row9_col0\" class=\"data row9 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_204a7_row9_col1\" class=\"data row9 col1\" >ExpandingWindowSplitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_204a7_row10_col0\" class=\"data row10 col0\" >Fold Number</td>\n",
       "      <td id=\"T_204a7_row10_col1\" class=\"data row10 col1\" >2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_204a7_row11_col0\" class=\"data row11 col0\" >Enforce Prediction Interval</td>\n",
       "      <td id=\"T_204a7_row11_col1\" class=\"data row11 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_204a7_row12_col0\" class=\"data row12 col0\" >Splits used for hyperparameters</td>\n",
       "      <td id=\"T_204a7_row12_col1\" class=\"data row12 col1\" >all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_204a7_row13_col0\" class=\"data row13 col0\" >User Defined Seasonal Period(s)</td>\n",
       "      <td id=\"T_204a7_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_204a7_row14_col0\" class=\"data row14 col0\" >Ignore Seasonality Test</td>\n",
       "      <td id=\"T_204a7_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_204a7_row15_col0\" class=\"data row15 col0\" >Seasonality Detection Algo</td>\n",
       "      <td id=\"T_204a7_row15_col1\" class=\"data row15 col1\" >auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_204a7_row16_col0\" class=\"data row16 col0\" >Max Period to Consider</td>\n",
       "      <td id=\"T_204a7_row16_col1\" class=\"data row16 col1\" >60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_204a7_row17_col0\" class=\"data row17 col0\" >Seasonal Period(s) Tested</td>\n",
       "      <td id=\"T_204a7_row17_col1\" class=\"data row17 col1\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_204a7_row18_col0\" class=\"data row18 col0\" >Significant Seasonal Period(s)</td>\n",
       "      <td id=\"T_204a7_row18_col1\" class=\"data row18 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_204a7_row19_col0\" class=\"data row19 col0\" >Significant Seasonal Period(s) without Harmonics</td>\n",
       "      <td id=\"T_204a7_row19_col1\" class=\"data row19 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_204a7_row20_col0\" class=\"data row20 col0\" >Remove Harmonics</td>\n",
       "      <td id=\"T_204a7_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_204a7_row21_col0\" class=\"data row21 col0\" >Harmonics Order Method</td>\n",
       "      <td id=\"T_204a7_row21_col1\" class=\"data row21 col1\" >harmonic_max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_204a7_row22_col0\" class=\"data row22 col0\" >Num Seasonalities to Use</td>\n",
       "      <td id=\"T_204a7_row22_col1\" class=\"data row22 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_204a7_row23_col0\" class=\"data row23 col0\" >All Seasonalities to Use</td>\n",
       "      <td id=\"T_204a7_row23_col1\" class=\"data row23 col1\" >[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_204a7_row24_col0\" class=\"data row24 col0\" >Primary Seasonality</td>\n",
       "      <td id=\"T_204a7_row24_col1\" class=\"data row24 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_204a7_row25_col0\" class=\"data row25 col0\" >Seasonality Present</td>\n",
       "      <td id=\"T_204a7_row25_col1\" class=\"data row25 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_204a7_row26_col0\" class=\"data row26 col0\" >Seasonality Type</td>\n",
       "      <td id=\"T_204a7_row26_col1\" class=\"data row26 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_204a7_row27_col0\" class=\"data row27 col0\" >Target Strictly Positive</td>\n",
       "      <td id=\"T_204a7_row27_col1\" class=\"data row27 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_204a7_row28_col0\" class=\"data row28 col0\" >Target White Noise</td>\n",
       "      <td id=\"T_204a7_row28_col1\" class=\"data row28 col1\" >Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_204a7_row29_col0\" class=\"data row29 col0\" >Recommended d</td>\n",
       "      <td id=\"T_204a7_row29_col1\" class=\"data row29 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_204a7_row30_col0\" class=\"data row30 col0\" >Recommended Seasonal D</td>\n",
       "      <td id=\"T_204a7_row30_col1\" class=\"data row30 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_204a7_row31_col0\" class=\"data row31 col0\" >Preprocess</td>\n",
       "      <td id=\"T_204a7_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_204a7_row32_col0\" class=\"data row32 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_204a7_row32_col1\" class=\"data row32 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_204a7_row33_col0\" class=\"data row33 col0\" >Use GPU</td>\n",
       "      <td id=\"T_204a7_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_204a7_row34_col0\" class=\"data row34 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_204a7_row34_col1\" class=\"data row34 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_204a7_row35_col0\" class=\"data row35 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_204a7_row35_col1\" class=\"data row35 col1\" >ts-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_204a7_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_204a7_row36_col0\" class=\"data row36 col0\" >USI</td>\n",
       "      <td id=\"T_204a7_row36_col1\" class=\"data row36 col1\" >37ed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cc72fbac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7012d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7012d_row0_col0, #T_7012d_row1_col0, #T_7012d_row2_col0, #T_7012d_row2_col1, #T_7012d_row2_col2, #T_7012d_row2_col3, #T_7012d_row2_col4, #T_7012d_row2_col5, #T_7012d_row2_col6, #T_7012d_row2_col7, #T_7012d_row3_col0, #T_7012d_row3_col1, #T_7012d_row3_col2, #T_7012d_row3_col3, #T_7012d_row3_col4, #T_7012d_row3_col5, #T_7012d_row3_col6, #T_7012d_row3_col7, #T_7012d_row4_col0, #T_7012d_row4_col1, #T_7012d_row4_col2, #T_7012d_row4_col3, #T_7012d_row4_col4, #T_7012d_row4_col5, #T_7012d_row4_col6, #T_7012d_row4_col7, #T_7012d_row5_col0, #T_7012d_row5_col1, #T_7012d_row5_col2, #T_7012d_row5_col3, #T_7012d_row5_col4, #T_7012d_row5_col5, #T_7012d_row5_col6, #T_7012d_row5_col7, #T_7012d_row6_col0, #T_7012d_row6_col1, #T_7012d_row6_col2, #T_7012d_row6_col3, #T_7012d_row6_col4, #T_7012d_row6_col5, #T_7012d_row6_col6, #T_7012d_row6_col7, #T_7012d_row7_col0, #T_7012d_row7_col1, #T_7012d_row7_col2, #T_7012d_row7_col3, #T_7012d_row7_col4, #T_7012d_row7_col5, #T_7012d_row7_col6, #T_7012d_row7_col7, #T_7012d_row8_col0, #T_7012d_row8_col1, #T_7012d_row8_col2, #T_7012d_row8_col3, #T_7012d_row8_col4, #T_7012d_row8_col5, #T_7012d_row8_col6, #T_7012d_row8_col7, #T_7012d_row9_col0, #T_7012d_row9_col1, #T_7012d_row9_col2, #T_7012d_row9_col3, #T_7012d_row9_col4, #T_7012d_row9_col5, #T_7012d_row9_col6, #T_7012d_row9_col7, #T_7012d_row10_col0, #T_7012d_row10_col1, #T_7012d_row10_col2, #T_7012d_row10_col3, #T_7012d_row10_col4, #T_7012d_row10_col5, #T_7012d_row10_col6, #T_7012d_row10_col7, #T_7012d_row11_col0, #T_7012d_row11_col1, #T_7012d_row11_col2, #T_7012d_row11_col3, #T_7012d_row11_col4, #T_7012d_row11_col5, #T_7012d_row11_col6, #T_7012d_row11_col7, #T_7012d_row12_col0, #T_7012d_row12_col1, #T_7012d_row12_col2, #T_7012d_row12_col3, #T_7012d_row12_col4, #T_7012d_row12_col5, #T_7012d_row12_col6, #T_7012d_row12_col7, #T_7012d_row13_col0, #T_7012d_row13_col1, #T_7012d_row13_col2, #T_7012d_row13_col3, #T_7012d_row13_col4, #T_7012d_row13_col5, #T_7012d_row13_col6, #T_7012d_row13_col7, #T_7012d_row14_col0, #T_7012d_row14_col1, #T_7012d_row14_col2, #T_7012d_row14_col3, #T_7012d_row14_col4, #T_7012d_row14_col5, #T_7012d_row14_col6, #T_7012d_row14_col7, #T_7012d_row15_col0, #T_7012d_row15_col1, #T_7012d_row15_col2, #T_7012d_row15_col3, #T_7012d_row15_col4, #T_7012d_row15_col5, #T_7012d_row15_col6, #T_7012d_row15_col7, #T_7012d_row16_col0, #T_7012d_row16_col1, #T_7012d_row16_col2, #T_7012d_row16_col3, #T_7012d_row16_col4, #T_7012d_row16_col5, #T_7012d_row16_col6, #T_7012d_row16_col7, #T_7012d_row17_col0, #T_7012d_row17_col1, #T_7012d_row17_col2, #T_7012d_row17_col3, #T_7012d_row17_col4, #T_7012d_row17_col5, #T_7012d_row17_col6, #T_7012d_row17_col7, #T_7012d_row18_col0, #T_7012d_row18_col1, #T_7012d_row18_col2, #T_7012d_row18_col3, #T_7012d_row18_col4, #T_7012d_row18_col5, #T_7012d_row18_col6, #T_7012d_row18_col7, #T_7012d_row19_col0, #T_7012d_row19_col1, #T_7012d_row19_col2, #T_7012d_row19_col3, #T_7012d_row19_col4, #T_7012d_row19_col5, #T_7012d_row19_col6, #T_7012d_row19_col7, #T_7012d_row20_col0, #T_7012d_row20_col1, #T_7012d_row20_col2, #T_7012d_row20_col3, #T_7012d_row20_col4, #T_7012d_row20_col5, #T_7012d_row20_col6, #T_7012d_row20_col7, #T_7012d_row21_col0, #T_7012d_row21_col1, #T_7012d_row21_col2, #T_7012d_row21_col3, #T_7012d_row21_col4, #T_7012d_row21_col5, #T_7012d_row21_col6, #T_7012d_row21_col7, #T_7012d_row22_col0, #T_7012d_row22_col1, #T_7012d_row22_col2, #T_7012d_row22_col3, #T_7012d_row22_col4, #T_7012d_row22_col5, #T_7012d_row22_col6, #T_7012d_row22_col7, #T_7012d_row23_col0, #T_7012d_row23_col1, #T_7012d_row23_col2, #T_7012d_row23_col3, #T_7012d_row23_col4, #T_7012d_row23_col5, #T_7012d_row23_col6, #T_7012d_row23_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_7012d_row0_col1, #T_7012d_row0_col2, #T_7012d_row0_col3, #T_7012d_row0_col4, #T_7012d_row0_col5, #T_7012d_row0_col6, #T_7012d_row0_col7, #T_7012d_row1_col1, #T_7012d_row1_col2, #T_7012d_row1_col3, #T_7012d_row1_col4, #T_7012d_row1_col5, #T_7012d_row1_col6, #T_7012d_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_7012d_row0_col8, #T_7012d_row1_col8, #T_7012d_row2_col8, #T_7012d_row4_col8, #T_7012d_row5_col8, #T_7012d_row6_col8, #T_7012d_row7_col8, #T_7012d_row8_col8, #T_7012d_row9_col8, #T_7012d_row10_col8, #T_7012d_row11_col8, #T_7012d_row12_col8, #T_7012d_row13_col8, #T_7012d_row14_col8, #T_7012d_row15_col8, #T_7012d_row16_col8, #T_7012d_row17_col8, #T_7012d_row18_col8, #T_7012d_row19_col8, #T_7012d_row20_col8, #T_7012d_row21_col8, #T_7012d_row22_col8, #T_7012d_row23_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_7012d_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7012d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7012d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_7012d_level0_col1\" class=\"col_heading level0 col1\" >MASE</th>\n",
       "      <th id=\"T_7012d_level0_col2\" class=\"col_heading level0 col2\" >RMSSE</th>\n",
       "      <th id=\"T_7012d_level0_col3\" class=\"col_heading level0 col3\" >MAE</th>\n",
       "      <th id=\"T_7012d_level0_col4\" class=\"col_heading level0 col4\" >RMSE</th>\n",
       "      <th id=\"T_7012d_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "      <th id=\"T_7012d_level0_col6\" class=\"col_heading level0 col6\" >SMAPE</th>\n",
       "      <th id=\"T_7012d_level0_col7\" class=\"col_heading level0 col7\" >R2</th>\n",
       "      <th id=\"T_7012d_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row0\" class=\"row_heading level0 row0\" >grand_means</th>\n",
       "      <td id=\"T_7012d_row0_col0\" class=\"data row0 col0\" >Grand Means Forecaster</td>\n",
       "      <td id=\"T_7012d_row0_col1\" class=\"data row0 col1\" >0.6471</td>\n",
       "      <td id=\"T_7012d_row0_col2\" class=\"data row0 col2\" >0.6489</td>\n",
       "      <td id=\"T_7012d_row0_col3\" class=\"data row0 col3\" >650.1533</td>\n",
       "      <td id=\"T_7012d_row0_col4\" class=\"data row0 col4\" >860.6169</td>\n",
       "      <td id=\"T_7012d_row0_col5\" class=\"data row0 col5\" >0.1002</td>\n",
       "      <td id=\"T_7012d_row0_col6\" class=\"data row0 col6\" >0.0932</td>\n",
       "      <td id=\"T_7012d_row0_col7\" class=\"data row0 col7\" >-0.5097</td>\n",
       "      <td id=\"T_7012d_row0_col8\" class=\"data row0 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row1\" class=\"row_heading level0 row1\" >auto_arima</th>\n",
       "      <td id=\"T_7012d_row1_col0\" class=\"data row1 col0\" >Auto ARIMA</td>\n",
       "      <td id=\"T_7012d_row1_col1\" class=\"data row1 col1\" >0.6471</td>\n",
       "      <td id=\"T_7012d_row1_col2\" class=\"data row1 col2\" >0.6489</td>\n",
       "      <td id=\"T_7012d_row1_col3\" class=\"data row1 col3\" >650.1533</td>\n",
       "      <td id=\"T_7012d_row1_col4\" class=\"data row1 col4\" >860.6169</td>\n",
       "      <td id=\"T_7012d_row1_col5\" class=\"data row1 col5\" >0.1002</td>\n",
       "      <td id=\"T_7012d_row1_col6\" class=\"data row1 col6\" >0.0932</td>\n",
       "      <td id=\"T_7012d_row1_col7\" class=\"data row1 col7\" >-0.5097</td>\n",
       "      <td id=\"T_7012d_row1_col8\" class=\"data row1 col8\" >0.1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row2\" class=\"row_heading level0 row2\" >arima</th>\n",
       "      <td id=\"T_7012d_row2_col0\" class=\"data row2 col0\" >ARIMA</td>\n",
       "      <td id=\"T_7012d_row2_col1\" class=\"data row2 col1\" >0.6612</td>\n",
       "      <td id=\"T_7012d_row2_col2\" class=\"data row2 col2\" >0.6678</td>\n",
       "      <td id=\"T_7012d_row2_col3\" class=\"data row2 col3\" >664.5704</td>\n",
       "      <td id=\"T_7012d_row2_col4\" class=\"data row2 col4\" >885.3560</td>\n",
       "      <td id=\"T_7012d_row2_col5\" class=\"data row2 col5\" >0.1026</td>\n",
       "      <td id=\"T_7012d_row2_col6\" class=\"data row2 col6\" >0.0951</td>\n",
       "      <td id=\"T_7012d_row2_col7\" class=\"data row2 col7\" >-0.6258</td>\n",
       "      <td id=\"T_7012d_row2_col8\" class=\"data row2 col8\" >0.0600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row3\" class=\"row_heading level0 row3\" >croston</th>\n",
       "      <td id=\"T_7012d_row3_col0\" class=\"data row3 col0\" >Croston</td>\n",
       "      <td id=\"T_7012d_row3_col1\" class=\"data row3 col1\" >0.6937</td>\n",
       "      <td id=\"T_7012d_row3_col2\" class=\"data row3 col2\" >0.6750</td>\n",
       "      <td id=\"T_7012d_row3_col3\" class=\"data row3 col3\" >697.6771</td>\n",
       "      <td id=\"T_7012d_row3_col4\" class=\"data row3 col4\" >894.6845</td>\n",
       "      <td id=\"T_7012d_row3_col5\" class=\"data row3 col5\" >0.1072</td>\n",
       "      <td id=\"T_7012d_row3_col6\" class=\"data row3 col6\" >0.0994</td>\n",
       "      <td id=\"T_7012d_row3_col7\" class=\"data row3 col7\" >-0.6724</td>\n",
       "      <td id=\"T_7012d_row3_col8\" class=\"data row3 col8\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row4\" class=\"row_heading level0 row4\" >ada_cds_dt</th>\n",
       "      <td id=\"T_7012d_row4_col0\" class=\"data row4 col0\" >AdaBoost w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row4_col1\" class=\"data row4 col1\" >0.9763</td>\n",
       "      <td id=\"T_7012d_row4_col2\" class=\"data row4 col2\" >0.9177</td>\n",
       "      <td id=\"T_7012d_row4_col3\" class=\"data row4 col3\" >987.0056</td>\n",
       "      <td id=\"T_7012d_row4_col4\" class=\"data row4 col4\" >1212.4565</td>\n",
       "      <td id=\"T_7012d_row4_col5\" class=\"data row4 col5\" >0.1474</td>\n",
       "      <td id=\"T_7012d_row4_col6\" class=\"data row4 col6\" >0.1343</td>\n",
       "      <td id=\"T_7012d_row4_col7\" class=\"data row4 col7\" >-2.7856</td>\n",
       "      <td id=\"T_7012d_row4_col8\" class=\"data row4 col8\" >0.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row5\" class=\"row_heading level0 row5\" >rf_cds_dt</th>\n",
       "      <td id=\"T_7012d_row5_col0\" class=\"data row5 col0\" >Random Forest w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row5_col1\" class=\"data row5 col1\" >1.1248</td>\n",
       "      <td id=\"T_7012d_row5_col2\" class=\"data row5 col2\" >0.9811</td>\n",
       "      <td id=\"T_7012d_row5_col3\" class=\"data row5 col3\" >1138.2136</td>\n",
       "      <td id=\"T_7012d_row5_col4\" class=\"data row5 col4\" >1295.1622</td>\n",
       "      <td id=\"T_7012d_row5_col5\" class=\"data row5 col5\" >0.1707</td>\n",
       "      <td id=\"T_7012d_row5_col6\" class=\"data row5 col6\" >0.1532</td>\n",
       "      <td id=\"T_7012d_row5_col7\" class=\"data row5 col7\" >-3.5997</td>\n",
       "      <td id=\"T_7012d_row5_col8\" class=\"data row5 col8\" >0.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row6\" class=\"row_heading level0 row6\" >theta</th>\n",
       "      <td id=\"T_7012d_row6_col0\" class=\"data row6 col0\" >Theta Forecaster</td>\n",
       "      <td id=\"T_7012d_row6_col1\" class=\"data row6 col1\" >1.1290</td>\n",
       "      <td id=\"T_7012d_row6_col2\" class=\"data row6 col2\" >0.9603</td>\n",
       "      <td id=\"T_7012d_row6_col3\" class=\"data row6 col3\" >1141.4918</td>\n",
       "      <td id=\"T_7012d_row6_col4\" class=\"data row6 col4\" >1268.3645</td>\n",
       "      <td id=\"T_7012d_row6_col5\" class=\"data row6 col5\" >0.1715</td>\n",
       "      <td id=\"T_7012d_row6_col6\" class=\"data row6 col6\" >0.1545</td>\n",
       "      <td id=\"T_7012d_row6_col7\" class=\"data row6 col7\" >-3.2483</td>\n",
       "      <td id=\"T_7012d_row6_col8\" class=\"data row6 col8\" >0.0350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row7\" class=\"row_heading level0 row7\" >exp_smooth</th>\n",
       "      <td id=\"T_7012d_row7_col0\" class=\"data row7 col0\" >Exponential Smoothing</td>\n",
       "      <td id=\"T_7012d_row7_col1\" class=\"data row7 col1\" >1.1711</td>\n",
       "      <td id=\"T_7012d_row7_col2\" class=\"data row7 col2\" >0.9961</td>\n",
       "      <td id=\"T_7012d_row7_col3\" class=\"data row7 col3\" >1186.5925</td>\n",
       "      <td id=\"T_7012d_row7_col4\" class=\"data row7 col4\" >1313.4913</td>\n",
       "      <td id=\"T_7012d_row7_col5\" class=\"data row7 col5\" >0.1754</td>\n",
       "      <td id=\"T_7012d_row7_col6\" class=\"data row7 col6\" >0.1577</td>\n",
       "      <td id=\"T_7012d_row7_col7\" class=\"data row7 col7\" >-4.1553</td>\n",
       "      <td id=\"T_7012d_row7_col8\" class=\"data row7 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row8\" class=\"row_heading level0 row8\" >et_cds_dt</th>\n",
       "      <td id=\"T_7012d_row8_col0\" class=\"data row8 col0\" >Extra Trees w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row8_col1\" class=\"data row8 col1\" >1.1729</td>\n",
       "      <td id=\"T_7012d_row8_col2\" class=\"data row8 col2\" >1.1548</td>\n",
       "      <td id=\"T_7012d_row8_col3\" class=\"data row8 col3\" >1186.0128</td>\n",
       "      <td id=\"T_7012d_row8_col4\" class=\"data row8 col4\" >1523.9994</td>\n",
       "      <td id=\"T_7012d_row8_col5\" class=\"data row8 col5\" >0.1792</td>\n",
       "      <td id=\"T_7012d_row8_col6\" class=\"data row8 col6\" >0.1554</td>\n",
       "      <td id=\"T_7012d_row8_col7\" class=\"data row8 col7\" >-5.5087</td>\n",
       "      <td id=\"T_7012d_row8_col8\" class=\"data row8 col8\" >0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row9\" class=\"row_heading level0 row9\" >huber_cds_dt</th>\n",
       "      <td id=\"T_7012d_row9_col0\" class=\"data row9 col0\" >Huber w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row9_col1\" class=\"data row9 col1\" >1.1872</td>\n",
       "      <td id=\"T_7012d_row9_col2\" class=\"data row9 col2\" >0.9823</td>\n",
       "      <td id=\"T_7012d_row9_col3\" class=\"data row9 col3\" >1199.4780</td>\n",
       "      <td id=\"T_7012d_row9_col4\" class=\"data row9 col4\" >1298.0073</td>\n",
       "      <td id=\"T_7012d_row9_col5\" class=\"data row9 col5\" >0.1799</td>\n",
       "      <td id=\"T_7012d_row9_col6\" class=\"data row9 col6\" >0.1620</td>\n",
       "      <td id=\"T_7012d_row9_col7\" class=\"data row9 col7\" >-3.2911</td>\n",
       "      <td id=\"T_7012d_row9_col8\" class=\"data row9 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row10\" class=\"row_heading level0 row10\" >dt_cds_dt</th>\n",
       "      <td id=\"T_7012d_row10_col0\" class=\"data row10 col0\" >Decision Tree w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row10_col1\" class=\"data row10 col1\" >1.1921</td>\n",
       "      <td id=\"T_7012d_row10_col2\" class=\"data row10 col2\" >1.1357</td>\n",
       "      <td id=\"T_7012d_row10_col3\" class=\"data row10 col3\" >1205.0844</td>\n",
       "      <td id=\"T_7012d_row10_col4\" class=\"data row10 col4\" >1498.3836</td>\n",
       "      <td id=\"T_7012d_row10_col5\" class=\"data row10 col5\" >0.1821</td>\n",
       "      <td id=\"T_7012d_row10_col6\" class=\"data row10 col6\" >0.1585</td>\n",
       "      <td id=\"T_7012d_row10_col7\" class=\"data row10 col7\" >-5.4384</td>\n",
       "      <td id=\"T_7012d_row10_col8\" class=\"data row10 col8\" >0.0850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row11\" class=\"row_heading level0 row11\" >lasso_cds_dt</th>\n",
       "      <td id=\"T_7012d_row11_col0\" class=\"data row11 col0\" >Lasso w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row11_col1\" class=\"data row11 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row11_col2\" class=\"data row11 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row11_col3\" class=\"data row11 col3\" >1217.7605</td>\n",
       "      <td id=\"T_7012d_row11_col4\" class=\"data row11 col4\" >1315.4964</td>\n",
       "      <td id=\"T_7012d_row11_col5\" class=\"data row11 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row11_col6\" class=\"data row11 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row11_col7\" class=\"data row11 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row11_col8\" class=\"data row11 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row12\" class=\"row_heading level0 row12\" >lr_cds_dt</th>\n",
       "      <td id=\"T_7012d_row12_col0\" class=\"data row12 col0\" >Linear w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row12_col1\" class=\"data row12 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row12_col2\" class=\"data row12 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row12_col3\" class=\"data row12 col3\" >1217.7604</td>\n",
       "      <td id=\"T_7012d_row12_col4\" class=\"data row12 col4\" >1315.4963</td>\n",
       "      <td id=\"T_7012d_row12_col5\" class=\"data row12 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row12_col6\" class=\"data row12 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row12_col7\" class=\"data row12 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row12_col8\" class=\"data row12 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row13\" class=\"row_heading level0 row13\" >llar_cds_dt</th>\n",
       "      <td id=\"T_7012d_row13_col0\" class=\"data row13 col0\" >Lasso Least Angular Regressor w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row13_col1\" class=\"data row13 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row13_col2\" class=\"data row13 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row13_col3\" class=\"data row13 col3\" >1217.7605</td>\n",
       "      <td id=\"T_7012d_row13_col4\" class=\"data row13 col4\" >1315.4964</td>\n",
       "      <td id=\"T_7012d_row13_col5\" class=\"data row13 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row13_col6\" class=\"data row13 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row13_col7\" class=\"data row13 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row13_col8\" class=\"data row13 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row14\" class=\"row_heading level0 row14\" >omp_cds_dt</th>\n",
       "      <td id=\"T_7012d_row14_col0\" class=\"data row14 col0\" >Orthogonal Matching Pursuit w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row14_col1\" class=\"data row14 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row14_col2\" class=\"data row14 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row14_col3\" class=\"data row14 col3\" >1217.7604</td>\n",
       "      <td id=\"T_7012d_row14_col4\" class=\"data row14 col4\" >1315.4963</td>\n",
       "      <td id=\"T_7012d_row14_col5\" class=\"data row14 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row14_col6\" class=\"data row14 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row14_col7\" class=\"data row14 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row14_col8\" class=\"data row14 col8\" >0.0950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row15\" class=\"row_heading level0 row15\" >en_cds_dt</th>\n",
       "      <td id=\"T_7012d_row15_col0\" class=\"data row15 col0\" >Elastic Net w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row15_col1\" class=\"data row15 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row15_col2\" class=\"data row15 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row15_col3\" class=\"data row15 col3\" >1217.7605</td>\n",
       "      <td id=\"T_7012d_row15_col4\" class=\"data row15 col4\" >1315.4963</td>\n",
       "      <td id=\"T_7012d_row15_col5\" class=\"data row15 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row15_col6\" class=\"data row15 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row15_col7\" class=\"data row15 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row15_col8\" class=\"data row15 col8\" >0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row16\" class=\"row_heading level0 row16\" >ridge_cds_dt</th>\n",
       "      <td id=\"T_7012d_row16_col0\" class=\"data row16 col0\" >Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row16_col1\" class=\"data row16 col1\" >1.2055</td>\n",
       "      <td id=\"T_7012d_row16_col2\" class=\"data row16 col2\" >0.9954</td>\n",
       "      <td id=\"T_7012d_row16_col3\" class=\"data row16 col3\" >1217.7604</td>\n",
       "      <td id=\"T_7012d_row16_col4\" class=\"data row16 col4\" >1315.4963</td>\n",
       "      <td id=\"T_7012d_row16_col5\" class=\"data row16 col5\" >0.1830</td>\n",
       "      <td id=\"T_7012d_row16_col6\" class=\"data row16 col6\" >0.1644</td>\n",
       "      <td id=\"T_7012d_row16_col7\" class=\"data row16 col7\" >-3.3625</td>\n",
       "      <td id=\"T_7012d_row16_col8\" class=\"data row16 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row17\" class=\"row_heading level0 row17\" >br_cds_dt</th>\n",
       "      <td id=\"T_7012d_row17_col0\" class=\"data row17 col0\" >Bayesian Ridge w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row17_col1\" class=\"data row17 col1\" >1.2120</td>\n",
       "      <td id=\"T_7012d_row17_col2\" class=\"data row17 col2\" >1.0034</td>\n",
       "      <td id=\"T_7012d_row17_col3\" class=\"data row17 col3\" >1224.3862</td>\n",
       "      <td id=\"T_7012d_row17_col4\" class=\"data row17 col4\" >1325.9853</td>\n",
       "      <td id=\"T_7012d_row17_col5\" class=\"data row17 col5\" >0.1841</td>\n",
       "      <td id=\"T_7012d_row17_col6\" class=\"data row17 col6\" >0.1652</td>\n",
       "      <td id=\"T_7012d_row17_col7\" class=\"data row17 col7\" >-3.4584</td>\n",
       "      <td id=\"T_7012d_row17_col8\" class=\"data row17 col8\" >0.0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row18\" class=\"row_heading level0 row18\" >lightgbm_cds_dt</th>\n",
       "      <td id=\"T_7012d_row18_col0\" class=\"data row18 col0\" >Light Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row18_col1\" class=\"data row18 col1\" >1.2120</td>\n",
       "      <td id=\"T_7012d_row18_col2\" class=\"data row18 col2\" >1.0035</td>\n",
       "      <td id=\"T_7012d_row18_col3\" class=\"data row18 col3\" >1224.4327</td>\n",
       "      <td id=\"T_7012d_row18_col4\" class=\"data row18 col4\" >1326.0575</td>\n",
       "      <td id=\"T_7012d_row18_col5\" class=\"data row18 col5\" >0.1841</td>\n",
       "      <td id=\"T_7012d_row18_col6\" class=\"data row18 col6\" >0.1652</td>\n",
       "      <td id=\"T_7012d_row18_col7\" class=\"data row18 col7\" >-3.4590</td>\n",
       "      <td id=\"T_7012d_row18_col8\" class=\"data row18 col8\" >0.1350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row19\" class=\"row_heading level0 row19\" >polytrend</th>\n",
       "      <td id=\"T_7012d_row19_col0\" class=\"data row19 col0\" >Polynomial Trend Forecaster</td>\n",
       "      <td id=\"T_7012d_row19_col1\" class=\"data row19 col1\" >1.2267</td>\n",
       "      <td id=\"T_7012d_row19_col2\" class=\"data row19 col2\" >1.0144</td>\n",
       "      <td id=\"T_7012d_row19_col3\" class=\"data row19 col3\" >1239.4248</td>\n",
       "      <td id=\"T_7012d_row19_col4\" class=\"data row19 col4\" >1340.4181</td>\n",
       "      <td id=\"T_7012d_row19_col5\" class=\"data row19 col5\" >0.1863</td>\n",
       "      <td id=\"T_7012d_row19_col6\" class=\"data row19 col6\" >0.1669</td>\n",
       "      <td id=\"T_7012d_row19_col7\" class=\"data row19 col7\" >-3.5907</td>\n",
       "      <td id=\"T_7012d_row19_col8\" class=\"data row19 col8\" >0.0250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row20\" class=\"row_heading level0 row20\" >knn_cds_dt</th>\n",
       "      <td id=\"T_7012d_row20_col0\" class=\"data row20 col0\" >K Neighbors w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row20_col1\" class=\"data row20 col1\" >1.2519</td>\n",
       "      <td id=\"T_7012d_row20_col2\" class=\"data row20 col2\" >1.0339</td>\n",
       "      <td id=\"T_7012d_row20_col3\" class=\"data row20 col3\" >1265.1980</td>\n",
       "      <td id=\"T_7012d_row20_col4\" class=\"data row20 col4\" >1365.7204</td>\n",
       "      <td id=\"T_7012d_row20_col5\" class=\"data row20 col5\" >0.1899</td>\n",
       "      <td id=\"T_7012d_row20_col6\" class=\"data row20 col6\" >0.1698</td>\n",
       "      <td id=\"T_7012d_row20_col7\" class=\"data row20 col7\" >-3.8653</td>\n",
       "      <td id=\"T_7012d_row20_col8\" class=\"data row20 col8\" >0.1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row21\" class=\"row_heading level0 row21\" >naive</th>\n",
       "      <td id=\"T_7012d_row21_col0\" class=\"data row21 col0\" >Naive Forecaster</td>\n",
       "      <td id=\"T_7012d_row21_col1\" class=\"data row21 col1\" >1.2901</td>\n",
       "      <td id=\"T_7012d_row21_col2\" class=\"data row21 col2\" >1.0830</td>\n",
       "      <td id=\"T_7012d_row21_col3\" class=\"data row21 col3\" >1305.5000</td>\n",
       "      <td id=\"T_7012d_row21_col4\" class=\"data row21 col4\" >1428.9550</td>\n",
       "      <td id=\"T_7012d_row21_col5\" class=\"data row21 col5\" >0.1960</td>\n",
       "      <td id=\"T_7012d_row21_col6\" class=\"data row21 col6\" >0.1734</td>\n",
       "      <td id=\"T_7012d_row21_col7\" class=\"data row21 col7\" >-4.8225</td>\n",
       "      <td id=\"T_7012d_row21_col8\" class=\"data row21 col8\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row22\" class=\"row_heading level0 row22\" >ets</th>\n",
       "      <td id=\"T_7012d_row22_col0\" class=\"data row22 col0\" >ETS</td>\n",
       "      <td id=\"T_7012d_row22_col1\" class=\"data row22 col1\" >1.3176</td>\n",
       "      <td id=\"T_7012d_row22_col2\" class=\"data row22 col2\" >1.1077</td>\n",
       "      <td id=\"T_7012d_row22_col3\" class=\"data row22 col3\" >1333.3554</td>\n",
       "      <td id=\"T_7012d_row22_col4\" class=\"data row22 col4\" >1462.1824</td>\n",
       "      <td id=\"T_7012d_row22_col5\" class=\"data row22 col5\" >0.1925</td>\n",
       "      <td id=\"T_7012d_row22_col6\" class=\"data row22 col6\" >0.1774</td>\n",
       "      <td id=\"T_7012d_row22_col7\" class=\"data row22 col7\" >-4.8860</td>\n",
       "      <td id=\"T_7012d_row22_col8\" class=\"data row22 col8\" >0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7012d_level0_row23\" class=\"row_heading level0 row23\" >gbr_cds_dt</th>\n",
       "      <td id=\"T_7012d_row23_col0\" class=\"data row23 col0\" >Gradient Boosting w/ Cond. Deseasonalize & Detrending</td>\n",
       "      <td id=\"T_7012d_row23_col1\" class=\"data row23 col1\" >1.4041</td>\n",
       "      <td id=\"T_7012d_row23_col2\" class=\"data row23 col2\" >1.2860</td>\n",
       "      <td id=\"T_7012d_row23_col3\" class=\"data row23 col3\" >1415.6461</td>\n",
       "      <td id=\"T_7012d_row23_col4\" class=\"data row23 col4\" >1700.3617</td>\n",
       "      <td id=\"T_7012d_row23_col5\" class=\"data row23 col5\" >0.2116</td>\n",
       "      <td id=\"T_7012d_row23_col6\" class=\"data row23 col6\" >0.1864</td>\n",
       "      <td id=\"T_7012d_row23_col7\" class=\"data row23 col7\" >-6.0561</td>\n",
       "      <td id=\"T_7012d_row23_col8\" class=\"data row23 col8\" >0.1150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23cb28df850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pycaret.time_series import TSForecastingExperiment\n",
    "\n",
    "# Define the datasets for 203\n",
    "datasets_203 = {\n",
    "    \"df_seats_sold_203\": df_seats_sold_203,\n",
    "    \"df_average_fare_203\": df_average_fare_203,\n",
    "    \"df_weighted_average_fare_203\": df_weighted_average_fare_203,\n",
    "    \"df_total_seats_sold_203\": df_total_seats_sold_203\n",
    "}\n",
    "\n",
    "# Define the datasets for 202\n",
    "datasets_202 = {\n",
    "    \"df_seats_sold_202\": df_seats_sold_202,\n",
    "    \"df_average_fare_202\": df_average_fare_202,\n",
    "    \"df_weighted_average_fare_202\": df_weighted_average_fare_202,\n",
    "    \"df_total_seats_sold_202\": df_total_seats_sold_202\n",
    "}\n",
    "\n",
    "# Function to run the forecasting model and get predictions\n",
    "def run_forecasting(exp, data, target_column, fh=61):\n",
    "    # Setup the experiment without a specified seasonal period\n",
    "    exp.setup(data=data, target=target_column, index='DepartureDate',\n",
    "              session_id=42, fold=2, fh=5, enforce_exogenous=False)\n",
    "    \n",
    "    # Compare models and finalize the best one\n",
    "    best_model = exp.compare_models()\n",
    "    final_model = exp.finalize_model(best_model)\n",
    "    \n",
    "    # Predict future values\n",
    "    future_predictions = exp.predict_model(final_model, fh=fh)\n",
    "    \n",
    "    # Filter predictions for August 2019\n",
    "    august_predictions = future_predictions['2019-08-01':'2019-08-30']\n",
    "    \n",
    "    # Rename the prediction column to match the target column name\n",
    "    august_predictions.rename(columns={'y_pred': target_column}, inplace=True)\n",
    "    \n",
    "    return august_predictions\n",
    "\n",
    "# Initialize the TSForecastingExperiment\n",
    "exp = TSForecastingExperiment()\n",
    "\n",
    "# Collect predictions for 203 datasets into a single DataFrame\n",
    "predictions_203 = pd.DataFrame()\n",
    "\n",
    "for dataset_name, dataset in datasets_203.items():\n",
    "    target_column = dataset.columns[1]  # Extract the target column name (assuming it's the second column)\n",
    "    predictions = run_forecasting(exp, dataset, target_column)\n",
    "    \n",
    "    # Merge predictions into a single DataFrame\n",
    "    if predictions_203.empty:\n",
    "        predictions_203 = predictions\n",
    "    else:\n",
    "        predictions_203 = predictions_203.join(predictions, how='outer')\n",
    "\n",
    "# Collect predictions for 202 datasets into a single DataFrame\n",
    "predictions_202 = pd.DataFrame()\n",
    "\n",
    "for dataset_name, dataset in datasets_202.items():\n",
    "    target_column = dataset.columns[1]  # Extract the target column name (assuming it's the second column)\n",
    "    predictions = run_forecasting(exp, dataset, target_column)\n",
    "    \n",
    "    # Merge predictions into a single DataFrame\n",
    "    if predictions_202.empty:\n",
    "        predictions_202 = predictions\n",
    "    else:\n",
    "        predictions_202 = predictions_202.join(predictions, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in predicted_ts: Index(['DepartureDate', 'SeatsSold', 'AverageFare(SGD)',\n",
      "       'WeightedAverageFare(SGD)', 'TotalSeatsSold', 'FlightNumber'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Add FlightNumber to each dataframe\n",
    "predictions_202['FlightNumber'] = 'TR 202'\n",
    "predictions_203['FlightNumber'] = 'TR 203'\n",
    "\n",
    "# Ensure 'DepartureDate' is a column\n",
    "if 'DepartureDate' not in predictions_202.columns:\n",
    "    predictions_202 = predictions_202.reset_index().rename(columns={'index': 'DepartureDate'})\n",
    "if 'DepartureDate' not in predictions_203.columns:\n",
    "    predictions_203 = predictions_203.reset_index().rename(columns={'index': 'DepartureDate'})\n",
    "\n",
    "# Combine the dataframes\n",
    "predicted_ts = pd.concat([predictions_202, predictions_203])\n",
    "\n",
    "# Debugging step: Print out the columns in the final DataFrame\n",
    "print(\"Columns in predicted_ts:\", predicted_ts.columns)\n",
    "\n",
    "# Ensure 'DepartureDate' is still in the columns\n",
    "if 'DepartureDate' in predicted_ts.columns:\n",
    "    # Reset the index (optional)\n",
    "    predicted_ts = predicted_ts.reset_index(drop=True)\n",
    "\n",
    "    # Arrange the columns in alphabetical order, with DepartureDate first\n",
    "    columns_order = ['DepartureDate'] + sorted([col for col in predicted_ts.columns if col != 'DepartureDate'])\n",
    "    predicted_ts = predicted_ts[columns_order]\n",
    "else:\n",
    "    print(\"Error: 'DepartureDate' is not in the columns of predicted_ts.\")\n",
    "\n",
    "# predicted_ts = predicted_ts.drop(columns=['level_0'])\n",
    "\n",
    "# Arrange the columns in the desired order\n",
    "columns_order = ['DepartureDate', 'FlightNumber'] + sorted([col for col in predicted_ts.columns if col not in ['DepartureDate', 'FlightNumber']])\n",
    "predicted_ts = predicted_ts[columns_order]\n",
    "\n",
    "# Round up SGD values to the nearest cent and seats sold to the nearest whole number\n",
    "for col in predicted_ts.columns:\n",
    "    if 'SGD' in col:\n",
    "        predicted_ts[col] = np.ceil(predicted_ts[col] * 100) / 100\n",
    "    elif 'SeatsSold' in col:\n",
    "        predicted_ts[col] = np.ceil(predicted_ts[col]).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Series Forecasting Results\n",
    "\n",
    "The following dataframe shows the predicted fares and seats sold for TR202 and TR203.\n",
    "\n",
    "As a reminder:\n",
    "1. **SeatsSold (Seats Predictions)**: This column shows the predicted number of seats sold, based on each entry.\n",
    "\n",
    "2. **AverageFare(SGD) (Fare Predictions)**: This column represents the fare predictions, based on each entry.\n",
    "   \n",
    "3. **WeightedAverageFare(SGD) (Fare Predictions)**: This column uses a weighted approach to predict fares, considering the average of all the fares for that departure date's flight.\n",
    "   \n",
    "4. **TotalSeatsSold (Seats Predictions)**: Similar to the SeatsSold predictions, considering total seat availability for for that departure date's flight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>179</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>175</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>178</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>170</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>181</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>171</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>168</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>160</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>179</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>175</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>178</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>170</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>181</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>171</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>168</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>160</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>37.34</td>\n",
       "      <td>187</td>\n",
       "      <td>4989</td>\n",
       "      <td>41.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>34.86</td>\n",
       "      <td>187</td>\n",
       "      <td>4903</td>\n",
       "      <td>46.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>44.89</td>\n",
       "      <td>187</td>\n",
       "      <td>4817</td>\n",
       "      <td>52.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>93.47</td>\n",
       "      <td>188</td>\n",
       "      <td>4730</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>72.88</td>\n",
       "      <td>188</td>\n",
       "      <td>4644</td>\n",
       "      <td>78.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.56</td>\n",
       "      <td>189</td>\n",
       "      <td>4558</td>\n",
       "      <td>57.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>47.31</td>\n",
       "      <td>189</td>\n",
       "      <td>4471</td>\n",
       "      <td>52.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>38.42</td>\n",
       "      <td>190</td>\n",
       "      <td>4385</td>\n",
       "      <td>42.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>35.86</td>\n",
       "      <td>190</td>\n",
       "      <td>4299</td>\n",
       "      <td>48.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>46.17</td>\n",
       "      <td>190</td>\n",
       "      <td>4212</td>\n",
       "      <td>54.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>96.13</td>\n",
       "      <td>191</td>\n",
       "      <td>4126</td>\n",
       "      <td>101.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>74.95</td>\n",
       "      <td>191</td>\n",
       "      <td>4040</td>\n",
       "      <td>81.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.96</td>\n",
       "      <td>192</td>\n",
       "      <td>3953</td>\n",
       "      <td>59.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>48.65</td>\n",
       "      <td>192</td>\n",
       "      <td>3867</td>\n",
       "      <td>53.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>39.49</td>\n",
       "      <td>192</td>\n",
       "      <td>3781</td>\n",
       "      <td>43.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>36.86</td>\n",
       "      <td>193</td>\n",
       "      <td>3694</td>\n",
       "      <td>49.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>47.46</td>\n",
       "      <td>193</td>\n",
       "      <td>3608</td>\n",
       "      <td>55.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>98.80</td>\n",
       "      <td>194</td>\n",
       "      <td>3522</td>\n",
       "      <td>104.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>77.02</td>\n",
       "      <td>194</td>\n",
       "      <td>3435</td>\n",
       "      <td>83.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.37</td>\n",
       "      <td>194</td>\n",
       "      <td>3349</td>\n",
       "      <td>61.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.98</td>\n",
       "      <td>195</td>\n",
       "      <td>3263</td>\n",
       "      <td>55.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>40.57</td>\n",
       "      <td>195</td>\n",
       "      <td>3176</td>\n",
       "      <td>44.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>37.86</td>\n",
       "      <td>196</td>\n",
       "      <td>3090</td>\n",
       "      <td>50.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>48.74</td>\n",
       "      <td>196</td>\n",
       "      <td>3004</td>\n",
       "      <td>56.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>101.46</td>\n",
       "      <td>196</td>\n",
       "      <td>2917</td>\n",
       "      <td>107.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>79.09</td>\n",
       "      <td>197</td>\n",
       "      <td>2831</td>\n",
       "      <td>85.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.77</td>\n",
       "      <td>197</td>\n",
       "      <td>2744</td>\n",
       "      <td>62.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.31</td>\n",
       "      <td>198</td>\n",
       "      <td>2658</td>\n",
       "      <td>56.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>41.65</td>\n",
       "      <td>198</td>\n",
       "      <td>2572</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>38.86</td>\n",
       "      <td>199</td>\n",
       "      <td>2485</td>\n",
       "      <td>52.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate FlightNumber  AverageFare(SGD)  SeatsSold  TotalSeatsSold  \\\n",
       "0     2019-08-01       TR 202             63.36        180            7280   \n",
       "1     2019-08-02       TR 202             63.36        172            7280   \n",
       "2     2019-08-03       TR 202             63.36        179            7280   \n",
       "3     2019-08-04       TR 202             63.36        175            7280   \n",
       "4     2019-08-05       TR 202             63.36        178            7280   \n",
       "5     2019-08-06       TR 202             63.36        170            7280   \n",
       "6     2019-08-07       TR 202             63.36        172            7280   \n",
       "7     2019-08-08       TR 202             63.36        181            7280   \n",
       "8     2019-08-09       TR 202             63.36        171            7280   \n",
       "9     2019-08-10       TR 202             63.36        168            7280   \n",
       "10    2019-08-11       TR 202             63.36        160            7280   \n",
       "11    2019-08-12       TR 202             63.36        180            7280   \n",
       "12    2019-08-13       TR 202             63.36        180            7280   \n",
       "13    2019-08-14       TR 202             63.36        180            7280   \n",
       "14    2019-08-15       TR 202             63.36        180            7280   \n",
       "15    2019-08-16       TR 202             63.36        172            7280   \n",
       "16    2019-08-17       TR 202             63.36        179            7280   \n",
       "17    2019-08-18       TR 202             63.36        175            7280   \n",
       "18    2019-08-19       TR 202             63.36        178            7280   \n",
       "19    2019-08-20       TR 202             63.36        170            7280   \n",
       "20    2019-08-21       TR 202             63.36        172            7280   \n",
       "21    2019-08-22       TR 202             63.36        181            7280   \n",
       "22    2019-08-23       TR 202             63.36        171            7280   \n",
       "23    2019-08-24       TR 202             63.36        168            7280   \n",
       "24    2019-08-25       TR 202             63.36        160            7280   \n",
       "25    2019-08-26       TR 202             63.36        180            7280   \n",
       "26    2019-08-27       TR 202             63.36        180            7280   \n",
       "27    2019-08-28       TR 202             63.36        180            7280   \n",
       "28    2019-08-29       TR 202             63.36        180            7280   \n",
       "29    2019-08-30       TR 202             63.36        172            7280   \n",
       "30    2019-08-01       TR 203             37.34        187            4989   \n",
       "31    2019-08-02       TR 203             34.86        187            4903   \n",
       "32    2019-08-03       TR 203             44.89        187            4817   \n",
       "33    2019-08-04       TR 203             93.47        188            4730   \n",
       "34    2019-08-05       TR 203             72.88        188            4644   \n",
       "35    2019-08-06       TR 203             49.56        189            4558   \n",
       "36    2019-08-07       TR 203             47.31        189            4471   \n",
       "37    2019-08-08       TR 203             38.42        190            4385   \n",
       "38    2019-08-09       TR 203             35.86        190            4299   \n",
       "39    2019-08-10       TR 203             46.17        190            4212   \n",
       "40    2019-08-11       TR 203             96.13        191            4126   \n",
       "41    2019-08-12       TR 203             74.95        191            4040   \n",
       "42    2019-08-13       TR 203             50.96        192            3953   \n",
       "43    2019-08-14       TR 203             48.65        192            3867   \n",
       "44    2019-08-15       TR 203             39.49        192            3781   \n",
       "45    2019-08-16       TR 203             36.86        193            3694   \n",
       "46    2019-08-17       TR 203             47.46        193            3608   \n",
       "47    2019-08-18       TR 203             98.80        194            3522   \n",
       "48    2019-08-19       TR 203             77.02        194            3435   \n",
       "49    2019-08-20       TR 203             52.37        194            3349   \n",
       "50    2019-08-21       TR 203             49.98        195            3263   \n",
       "51    2019-08-22       TR 203             40.57        195            3176   \n",
       "52    2019-08-23       TR 203             37.86        196            3090   \n",
       "53    2019-08-24       TR 203             48.74        196            3004   \n",
       "54    2019-08-25       TR 203            101.46        196            2917   \n",
       "55    2019-08-26       TR 203             79.09        197            2831   \n",
       "56    2019-08-27       TR 203             53.77        197            2744   \n",
       "57    2019-08-28       TR 203             51.31        198            2658   \n",
       "58    2019-08-29       TR 203             41.65        198            2572   \n",
       "59    2019-08-30       TR 203             38.86        199            2485   \n",
       "\n",
       "    WeightedAverageFare(SGD)  \n",
       "0                      65.21  \n",
       "1                      65.21  \n",
       "2                      65.21  \n",
       "3                      65.21  \n",
       "4                      65.21  \n",
       "5                      65.21  \n",
       "6                      65.21  \n",
       "7                      65.21  \n",
       "8                      65.21  \n",
       "9                      65.21  \n",
       "10                     65.21  \n",
       "11                     65.21  \n",
       "12                     65.21  \n",
       "13                     65.21  \n",
       "14                     65.21  \n",
       "15                     65.21  \n",
       "16                     65.21  \n",
       "17                     65.21  \n",
       "18                     65.21  \n",
       "19                     65.21  \n",
       "20                     65.21  \n",
       "21                     65.21  \n",
       "22                     65.21  \n",
       "23                     65.21  \n",
       "24                     65.21  \n",
       "25                     65.21  \n",
       "26                     65.21  \n",
       "27                     65.21  \n",
       "28                     65.21  \n",
       "29                     65.21  \n",
       "30                     41.11  \n",
       "31                     46.90  \n",
       "32                     52.59  \n",
       "33                     99.23  \n",
       "34                     78.94  \n",
       "35                     57.91  \n",
       "36                     52.23  \n",
       "37                     42.24  \n",
       "38                     48.19  \n",
       "39                     54.03  \n",
       "40                    101.94  \n",
       "41                     81.09  \n",
       "42                     59.48  \n",
       "43                     53.64  \n",
       "44                     43.38  \n",
       "45                     49.48  \n",
       "46                     55.48  \n",
       "47                    104.65  \n",
       "48                     83.24  \n",
       "49                     61.05  \n",
       "50                     55.06  \n",
       "51                     44.52  \n",
       "52                     50.77  \n",
       "53                     56.92  \n",
       "54                    107.37  \n",
       "55                     85.39  \n",
       "56                     62.63  \n",
       "57                     56.47  \n",
       "58                     45.66  \n",
       "59                     52.07  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Could The Regression Model Truly Predict the Remaining Seats to be Sold in August 2019?**\n",
    "\n",
    "The answer is **not really**. While the model provides predictions based on historical data and other features, it's essential to understand that there are limitations:\n",
    "\n",
    "**predicted_regress**\n",
    "\n",
    "This dataframe shows the regression model predictions for flight TR202 and TR203:\n",
    "\n",
    "1. **Fare Predictions (Based on AverageFare(SGD))**:\n",
    "   - The predicted fare generally varies within a range of SGD 51 to SGD 68, with most values clustering between SGD 53 and SGD 57. This suggests that the model expects the average fare to stay relatively stable throughout the month, with a slight increase on August 20th, possibly due to anticipated higher demand.\n",
    "\n",
    "2. **Seats Predictions (Based on SeatsSold)**:\n",
    "   - The seat predictions in this column consistently hover around 4 to 5, which seems to be an unusual representation if it indicates actual numbers of seats sold. Given that this value is low, it might suggest that the model is predicting in terms of blocks of seats or uses a scaling factor that isnâ€™t directly interpretable as the actual number of seats. Alternatively, this could be an error or misinterpretation in the prediction results.\n",
    "\n",
    "3. **Fare Predictions (Based on WeightedAverageFare(SGD))**:\n",
    "   - The weighted average fare predictions show even less variability than the average fare, almost consistently predicting SGD 49.0 across all dates, with only minor deviations (SGD 48 or SGD 50 on a few dates). This suggests the model assumes a stable pricing strategy that doesnâ€™t fluctuate much with expected demand or other variables.\n",
    "\n",
    "4. **Seats Predictions (Based on TotalSeatsSold)**:\n",
    "   - The total seats sold predictions are fairly consistent, with most values around 170 to 172. These values align more closely with the seat capacity of the airplane (180 seats) and suggest that the model expects near-full occupancy for most flights.\n",
    "\n",
    "**Additional Insights**\n",
    "\n",
    "- **Model Consistency**:\n",
    "   - The model shows a high level of consistency in its predictions, especially for weighted average fare and total seats sold. This could indicate that the model is built on a stable, non-volatile dataset where prices and seat sales donâ€™t vary much day-to-day.\n",
    "\n",
    "- **Potential Model Limitations**:\n",
    "   - The low variation in fare predictions (particularly in the weighted average) and the somewhat confusing low seat predictions based on seats sold suggest that the model might be oversimplifying its predictions. It might not be fully capturing the day-to-day fluctuations that are typical in airline sales, such as those caused by promotional activities, holidays, or other demand spikes.\n",
    "\n",
    "- **Focus on Full Occupancy**:\n",
    "   - The prediction for total seats sold hovering near 171-172 indicates that the model expects the flight to operate near full capacity consistently. This is a good sign in terms of operational efficiency, as it implies that most flights are expected to be fully booked.\n",
    "\n",
    "Overall, this dataframe provides a stable and somewhat conservative outlook on flight TR202's performance throughout August 2019, with predictions suggesting consistent pricing and near-full capacity for each flight. However, the lack of variability in the predictions raises questions about the model's ability to adapt to sudden changes in market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4</td>\n",
       "      <td>168</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate FlightNumber  AverageFare(SGD)  SeatsSold  TotalSeatsSold  \\\n",
       "0     2019-08-01       TR 202              57.0          5             172   \n",
       "1     2019-08-02       TR 202              54.0          4             171   \n",
       "2     2019-08-03       TR 202              55.0          5             172   \n",
       "3     2019-08-04       TR 202              57.0          5             172   \n",
       "4     2019-08-05       TR 202              55.0          5             172   \n",
       "5     2019-08-06       TR 202              51.0          5             172   \n",
       "6     2019-08-07       TR 202              55.0          5             172   \n",
       "7     2019-08-08       TR 202              59.0          5             172   \n",
       "8     2019-08-09       TR 202              56.0          4             170   \n",
       "9     2019-08-10       TR 202              56.0          4             171   \n",
       "10    2019-08-11       TR 202              55.0          4             171   \n",
       "11    2019-08-12       TR 202              53.0          4             171   \n",
       "12    2019-08-13       TR 202              53.0          5             172   \n",
       "13    2019-08-14       TR 202              54.0          4             171   \n",
       "14    2019-08-15       TR 202              56.0          5             172   \n",
       "15    2019-08-16       TR 202              55.0          4             171   \n",
       "16    2019-08-17       TR 202              53.0          5             172   \n",
       "17    2019-08-18       TR 202              54.0          5             172   \n",
       "18    2019-08-19       TR 202              54.0          5             172   \n",
       "19    2019-08-20       TR 202              68.0          5             172   \n",
       "20    2019-08-21       TR 202              55.0          5             172   \n",
       "21    2019-08-22       TR 202              57.0          5             172   \n",
       "22    2019-08-23       TR 202              58.0          4             171   \n",
       "23    2019-08-24       TR 202              55.0          5             172   \n",
       "24    2019-08-25       TR 202              55.0          5             172   \n",
       "25    2019-08-26       TR 202              59.0          5             172   \n",
       "26    2019-08-27       TR 202              54.0          5             172   \n",
       "27    2019-08-28       TR 202              53.0          5             172   \n",
       "28    2019-08-29       TR 202              57.0          4             171   \n",
       "29    2019-08-30       TR 202              55.0          4             171   \n",
       "30    2019-08-01       TR 203              53.0          4             169   \n",
       "31    2019-08-02       TR 203              51.0          4             168   \n",
       "32    2019-08-03       TR 203              49.0          4             169   \n",
       "33    2019-08-04       TR 203              52.0          4             169   \n",
       "34    2019-08-05       TR 203              52.0          4             169   \n",
       "35    2019-08-06       TR 203              50.0          4             169   \n",
       "36    2019-08-07       TR 203              51.0          4             169   \n",
       "37    2019-08-08       TR 203              54.0          4             169   \n",
       "38    2019-08-09       TR 203              53.0          3             168   \n",
       "39    2019-08-10       TR 203              54.0          4             168   \n",
       "40    2019-08-11       TR 203              52.0          4             168   \n",
       "41    2019-08-12       TR 203              52.0          4             168   \n",
       "42    2019-08-13       TR 203              49.0          4             169   \n",
       "43    2019-08-14       TR 203              51.0          4             168   \n",
       "44    2019-08-15       TR 203              54.0          4             169   \n",
       "45    2019-08-16       TR 203              50.0          4             168   \n",
       "46    2019-08-17       TR 203              50.0          4             169   \n",
       "47    2019-08-18       TR 203              51.0          4             169   \n",
       "48    2019-08-19       TR 203              50.0          4             169   \n",
       "49    2019-08-20       TR 203              63.0          4             169   \n",
       "50    2019-08-21       TR 203              52.0          4             169   \n",
       "51    2019-08-22       TR 203              53.0          4             169   \n",
       "52    2019-08-23       TR 203              55.0          4             168   \n",
       "53    2019-08-24       TR 203              51.0          4             169   \n",
       "54    2019-08-25       TR 203              51.0          4             169   \n",
       "55    2019-08-26       TR 203              56.0          4             169   \n",
       "56    2019-08-27       TR 203              51.0          4             169   \n",
       "57    2019-08-28       TR 203              50.0          4             169   \n",
       "58    2019-08-29       TR 203              52.0          4             168   \n",
       "59    2019-08-30       TR 203              51.0          4             168   \n",
       "\n",
       "    WeightedAverageFare(SGD)  \n",
       "0                       48.0  \n",
       "1                       49.0  \n",
       "2                       49.0  \n",
       "3                       49.0  \n",
       "4                       50.0  \n",
       "5                       49.0  \n",
       "6                       48.0  \n",
       "7                       49.0  \n",
       "8                       49.0  \n",
       "9                       49.0  \n",
       "10                      49.0  \n",
       "11                      49.0  \n",
       "12                      49.0  \n",
       "13                      49.0  \n",
       "14                      49.0  \n",
       "15                      49.0  \n",
       "16                      49.0  \n",
       "17                      48.0  \n",
       "18                      49.0  \n",
       "19                      48.0  \n",
       "20                      48.0  \n",
       "21                      48.0  \n",
       "22                      49.0  \n",
       "23                      49.0  \n",
       "24                      49.0  \n",
       "25                      49.0  \n",
       "26                      49.0  \n",
       "27                      48.0  \n",
       "28                      49.0  \n",
       "29                      49.0  \n",
       "30                      27.0  \n",
       "31                      27.0  \n",
       "32                      27.0  \n",
       "33                      27.0  \n",
       "34                      27.0  \n",
       "35                      27.0  \n",
       "36                      27.0  \n",
       "37                      27.0  \n",
       "38                      27.0  \n",
       "39                      27.0  \n",
       "40                      27.0  \n",
       "41                      27.0  \n",
       "42                      27.0  \n",
       "43                      27.0  \n",
       "44                      27.0  \n",
       "45                      27.0  \n",
       "46                      27.0  \n",
       "47                      27.0  \n",
       "48                      27.0  \n",
       "49                      27.0  \n",
       "50                      27.0  \n",
       "51                      27.0  \n",
       "52                      27.0  \n",
       "53                      27.0  \n",
       "54                      27.0  \n",
       "55                      27.0  \n",
       "56                      27.0  \n",
       "57                      27.0  \n",
       "58                      27.0  \n",
       "59                      27.0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_regress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Could The Time-Series Model Truly Predict the Remaining Seats to be Sold in August 2019?**\n",
    "\n",
    "The answer is **it's better than the regression model**. Hereâ€™s why:\n",
    "\n",
    "**predicted_ts**\n",
    "\n",
    "This dataframe shows the time-series model predictions for flight TR202 and TR203:\n",
    "\n",
    "1. **For TR202 predictions**:\n",
    "   - The model did not detect sufficient variability or patterns in the historical data used for training, leading it to predict the same `AverageFare`, `WeightedAverageFare`, and `TotalSeatsSold` for all dates in August 2019. This could be addressed by incorporating more diverse and extensive historical data, adjusting the model parameters, or considering different preprocessing techniques to better capture any underlying trends or patterns in the data.\n",
    "\n",
    "2. **For TR203 predictions**:\n",
    "   - Unlike the predictions for TR202 (`predictions_202`), which were static, these predictions exhibit a dynamic range, indicating that the model detected and accounted for underlying trends and fluctuations in the data. The observed fluctuations in `SeatsSold` and fare-related metrics reflect the model's sensitivity to underlying trends and external influences, making it a potentially valuable tool for forecasting in the airline industry.\n",
    "\n",
    "   However, ongoing evaluation and refinement are necessary to ensure the model's continued relevance and accuracy in a highly dynamic market.\n",
    "\n",
    "   - **Overbooking Scenario**:\n",
    "     - It must be made known that the airplane used has a seat limit of 180. The model predicts that the number of seats bought could exceed this limit due to an increasing trend in demand. Is this necessarily a good or bad thing for overbooking a plane?\n",
    "\n",
    "     - **Good Scenario**: If the model is accurately predicting a realistic overbooking scenario, where the actual number of passengers who show up will still fall within the 180-seat limit, this can be a good strategy for maximizing revenue. In this case, the model helps the airline optimize its booking strategy by filling as many seats as possible, even accounting for potential no-shows.\n",
    "\n",
    "     - **Bad Scenario**: If the model overestimates the number of no-shows, leading to predictions that consistently exceed the 180-seat limit without sufficient no-shows to balance out, this could result in too many passengers showing up. The airline would then face the challenges of overbooking, such as needing to compensate bumped passengers and handling customer dissatisfaction.\n",
    "\n",
    "**Additional Insights**\n",
    "- **Impact of Market Dynamics**:\n",
    "   - The model's ability to predict varying outcomes suggests it may be sensitive to changes in market dynamics, such as competitor pricing, macroeconomic conditions, or unexpected events. This adaptability is beneficial, but it also means that the model must be closely monitored and recalibrated as market conditions evolve.\n",
    "\n",
    "In conclusion, while the time-series model shows improvements over the regression model, particularly in detecting trends and variability, careful consideration is needed when applying these predictions, especially regarding overbooking practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>FlightNumber</th>\n",
       "      <th>AverageFare(SGD)</th>\n",
       "      <th>SeatsSold</th>\n",
       "      <th>TotalSeatsSold</th>\n",
       "      <th>WeightedAverageFare(SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>179</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>175</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>178</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>170</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>181</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>171</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>168</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>160</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>179</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>175</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>178</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>170</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>181</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>171</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>168</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>160</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>180</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>63.36</td>\n",
       "      <td>172</td>\n",
       "      <td>7280</td>\n",
       "      <td>65.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>37.34</td>\n",
       "      <td>187</td>\n",
       "      <td>4989</td>\n",
       "      <td>41.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>34.86</td>\n",
       "      <td>187</td>\n",
       "      <td>4903</td>\n",
       "      <td>46.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-08-03</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>44.89</td>\n",
       "      <td>187</td>\n",
       "      <td>4817</td>\n",
       "      <td>52.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>93.47</td>\n",
       "      <td>188</td>\n",
       "      <td>4730</td>\n",
       "      <td>99.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>72.88</td>\n",
       "      <td>188</td>\n",
       "      <td>4644</td>\n",
       "      <td>78.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.56</td>\n",
       "      <td>189</td>\n",
       "      <td>4558</td>\n",
       "      <td>57.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>47.31</td>\n",
       "      <td>189</td>\n",
       "      <td>4471</td>\n",
       "      <td>52.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>38.42</td>\n",
       "      <td>190</td>\n",
       "      <td>4385</td>\n",
       "      <td>42.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>35.86</td>\n",
       "      <td>190</td>\n",
       "      <td>4299</td>\n",
       "      <td>48.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>46.17</td>\n",
       "      <td>190</td>\n",
       "      <td>4212</td>\n",
       "      <td>54.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>96.13</td>\n",
       "      <td>191</td>\n",
       "      <td>4126</td>\n",
       "      <td>101.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>74.95</td>\n",
       "      <td>191</td>\n",
       "      <td>4040</td>\n",
       "      <td>81.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>50.96</td>\n",
       "      <td>192</td>\n",
       "      <td>3953</td>\n",
       "      <td>59.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-08-14</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>48.65</td>\n",
       "      <td>192</td>\n",
       "      <td>3867</td>\n",
       "      <td>53.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-08-15</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>39.49</td>\n",
       "      <td>192</td>\n",
       "      <td>3781</td>\n",
       "      <td>43.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>36.86</td>\n",
       "      <td>193</td>\n",
       "      <td>3694</td>\n",
       "      <td>49.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-08-17</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>47.46</td>\n",
       "      <td>193</td>\n",
       "      <td>3608</td>\n",
       "      <td>55.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-08-18</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>98.80</td>\n",
       "      <td>194</td>\n",
       "      <td>3522</td>\n",
       "      <td>104.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>77.02</td>\n",
       "      <td>194</td>\n",
       "      <td>3435</td>\n",
       "      <td>83.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-08-20</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>52.37</td>\n",
       "      <td>194</td>\n",
       "      <td>3349</td>\n",
       "      <td>61.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-08-21</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>49.98</td>\n",
       "      <td>195</td>\n",
       "      <td>3263</td>\n",
       "      <td>55.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-08-22</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>40.57</td>\n",
       "      <td>195</td>\n",
       "      <td>3176</td>\n",
       "      <td>44.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>37.86</td>\n",
       "      <td>196</td>\n",
       "      <td>3090</td>\n",
       "      <td>50.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-08-24</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>48.74</td>\n",
       "      <td>196</td>\n",
       "      <td>3004</td>\n",
       "      <td>56.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-08-25</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>101.46</td>\n",
       "      <td>196</td>\n",
       "      <td>2917</td>\n",
       "      <td>107.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>79.09</td>\n",
       "      <td>197</td>\n",
       "      <td>2831</td>\n",
       "      <td>85.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>53.77</td>\n",
       "      <td>197</td>\n",
       "      <td>2744</td>\n",
       "      <td>62.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>51.31</td>\n",
       "      <td>198</td>\n",
       "      <td>2658</td>\n",
       "      <td>56.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>41.65</td>\n",
       "      <td>198</td>\n",
       "      <td>2572</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>38.86</td>\n",
       "      <td>199</td>\n",
       "      <td>2485</td>\n",
       "      <td>52.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate FlightNumber  AverageFare(SGD)  SeatsSold  TotalSeatsSold  \\\n",
       "0     2019-08-01       TR 202             63.36        180            7280   \n",
       "1     2019-08-02       TR 202             63.36        172            7280   \n",
       "2     2019-08-03       TR 202             63.36        179            7280   \n",
       "3     2019-08-04       TR 202             63.36        175            7280   \n",
       "4     2019-08-05       TR 202             63.36        178            7280   \n",
       "5     2019-08-06       TR 202             63.36        170            7280   \n",
       "6     2019-08-07       TR 202             63.36        172            7280   \n",
       "7     2019-08-08       TR 202             63.36        181            7280   \n",
       "8     2019-08-09       TR 202             63.36        171            7280   \n",
       "9     2019-08-10       TR 202             63.36        168            7280   \n",
       "10    2019-08-11       TR 202             63.36        160            7280   \n",
       "11    2019-08-12       TR 202             63.36        180            7280   \n",
       "12    2019-08-13       TR 202             63.36        180            7280   \n",
       "13    2019-08-14       TR 202             63.36        180            7280   \n",
       "14    2019-08-15       TR 202             63.36        180            7280   \n",
       "15    2019-08-16       TR 202             63.36        172            7280   \n",
       "16    2019-08-17       TR 202             63.36        179            7280   \n",
       "17    2019-08-18       TR 202             63.36        175            7280   \n",
       "18    2019-08-19       TR 202             63.36        178            7280   \n",
       "19    2019-08-20       TR 202             63.36        170            7280   \n",
       "20    2019-08-21       TR 202             63.36        172            7280   \n",
       "21    2019-08-22       TR 202             63.36        181            7280   \n",
       "22    2019-08-23       TR 202             63.36        171            7280   \n",
       "23    2019-08-24       TR 202             63.36        168            7280   \n",
       "24    2019-08-25       TR 202             63.36        160            7280   \n",
       "25    2019-08-26       TR 202             63.36        180            7280   \n",
       "26    2019-08-27       TR 202             63.36        180            7280   \n",
       "27    2019-08-28       TR 202             63.36        180            7280   \n",
       "28    2019-08-29       TR 202             63.36        180            7280   \n",
       "29    2019-08-30       TR 202             63.36        172            7280   \n",
       "30    2019-08-01       TR 203             37.34        187            4989   \n",
       "31    2019-08-02       TR 203             34.86        187            4903   \n",
       "32    2019-08-03       TR 203             44.89        187            4817   \n",
       "33    2019-08-04       TR 203             93.47        188            4730   \n",
       "34    2019-08-05       TR 203             72.88        188            4644   \n",
       "35    2019-08-06       TR 203             49.56        189            4558   \n",
       "36    2019-08-07       TR 203             47.31        189            4471   \n",
       "37    2019-08-08       TR 203             38.42        190            4385   \n",
       "38    2019-08-09       TR 203             35.86        190            4299   \n",
       "39    2019-08-10       TR 203             46.17        190            4212   \n",
       "40    2019-08-11       TR 203             96.13        191            4126   \n",
       "41    2019-08-12       TR 203             74.95        191            4040   \n",
       "42    2019-08-13       TR 203             50.96        192            3953   \n",
       "43    2019-08-14       TR 203             48.65        192            3867   \n",
       "44    2019-08-15       TR 203             39.49        192            3781   \n",
       "45    2019-08-16       TR 203             36.86        193            3694   \n",
       "46    2019-08-17       TR 203             47.46        193            3608   \n",
       "47    2019-08-18       TR 203             98.80        194            3522   \n",
       "48    2019-08-19       TR 203             77.02        194            3435   \n",
       "49    2019-08-20       TR 203             52.37        194            3349   \n",
       "50    2019-08-21       TR 203             49.98        195            3263   \n",
       "51    2019-08-22       TR 203             40.57        195            3176   \n",
       "52    2019-08-23       TR 203             37.86        196            3090   \n",
       "53    2019-08-24       TR 203             48.74        196            3004   \n",
       "54    2019-08-25       TR 203            101.46        196            2917   \n",
       "55    2019-08-26       TR 203             79.09        197            2831   \n",
       "56    2019-08-27       TR 203             53.77        197            2744   \n",
       "57    2019-08-28       TR 203             51.31        198            2658   \n",
       "58    2019-08-29       TR 203             41.65        198            2572   \n",
       "59    2019-08-30       TR 203             38.86        199            2485   \n",
       "\n",
       "    WeightedAverageFare(SGD)  \n",
       "0                      65.21  \n",
       "1                      65.21  \n",
       "2                      65.21  \n",
       "3                      65.21  \n",
       "4                      65.21  \n",
       "5                      65.21  \n",
       "6                      65.21  \n",
       "7                      65.21  \n",
       "8                      65.21  \n",
       "9                      65.21  \n",
       "10                     65.21  \n",
       "11                     65.21  \n",
       "12                     65.21  \n",
       "13                     65.21  \n",
       "14                     65.21  \n",
       "15                     65.21  \n",
       "16                     65.21  \n",
       "17                     65.21  \n",
       "18                     65.21  \n",
       "19                     65.21  \n",
       "20                     65.21  \n",
       "21                     65.21  \n",
       "22                     65.21  \n",
       "23                     65.21  \n",
       "24                     65.21  \n",
       "25                     65.21  \n",
       "26                     65.21  \n",
       "27                     65.21  \n",
       "28                     65.21  \n",
       "29                     65.21  \n",
       "30                     41.11  \n",
       "31                     46.90  \n",
       "32                     52.59  \n",
       "33                     99.23  \n",
       "34                     78.94  \n",
       "35                     57.91  \n",
       "36                     52.23  \n",
       "37                     42.24  \n",
       "38                     48.19  \n",
       "39                     54.03  \n",
       "40                    101.94  \n",
       "41                     81.09  \n",
       "42                     59.48  \n",
       "43                     53.64  \n",
       "44                     43.38  \n",
       "45                     49.48  \n",
       "46                     55.48  \n",
       "47                    104.65  \n",
       "48                     83.24  \n",
       "49                     61.05  \n",
       "50                     55.06  \n",
       "51                     44.52  \n",
       "52                     50.77  \n",
       "53                     56.92  \n",
       "54                    107.37  \n",
       "55                     85.39  \n",
       "56                     62.63  \n",
       "57                     56.47  \n",
       "58                     45.66  \n",
       "59                     52.07  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Final Thoughts**\n",
    "\n",
    "The following shows the actual metrics for the month of August starting from 2019-08-04 to 2019-08-12. \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartureDate</th>\n",
       "      <th>Flight Number</th>\n",
       "      <th>Seat Capacity</th>\n",
       "      <th>SegmentCityPair</th>\n",
       "      <th>Seats Sold</th>\n",
       "      <th>AverageFare (SGD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>50</td>\n",
       "      <td>15.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>59</td>\n",
       "      <td>14.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>67</td>\n",
       "      <td>34.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>59</td>\n",
       "      <td>61.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>54</td>\n",
       "      <td>138.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>98</td>\n",
       "      <td>193.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>46</td>\n",
       "      <td>74.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>38</td>\n",
       "      <td>12.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 202</td>\n",
       "      <td>180</td>\n",
       "      <td>SINPNH</td>\n",
       "      <td>29</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-08-04</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>52</td>\n",
       "      <td>26.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>27</td>\n",
       "      <td>24.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>49</td>\n",
       "      <td>14.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>42</td>\n",
       "      <td>11.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>57</td>\n",
       "      <td>15.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>56</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>63</td>\n",
       "      <td>35.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>44</td>\n",
       "      <td>34.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>TR 203</td>\n",
       "      <td>180</td>\n",
       "      <td>PNHSIN</td>\n",
       "      <td>87</td>\n",
       "      <td>207.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartureDate Flight Number  Seat Capacity SegmentCityPair  Seats Sold  \\\n",
       "0     2019-08-04        TR 202            180          SINPNH          50   \n",
       "1     2019-08-05        TR 202            180          SINPNH          59   \n",
       "2     2019-08-06        TR 202            180          SINPNH          67   \n",
       "3     2019-08-07        TR 202            180          SINPNH          59   \n",
       "4     2019-08-08        TR 202            180          SINPNH          54   \n",
       "5     2019-08-09        TR 202            180          SINPNH          98   \n",
       "6     2019-08-10        TR 202            180          SINPNH          46   \n",
       "7     2019-08-11        TR 202            180          SINPNH          38   \n",
       "8     2019-08-12        TR 202            180          SINPNH          29   \n",
       "9     2019-08-04        TR 203            180          PNHSIN          52   \n",
       "10    2019-08-05        TR 203            180          PNHSIN          27   \n",
       "11    2019-08-06        TR 203            180          PNHSIN          49   \n",
       "12    2019-08-07        TR 203            180          PNHSIN          42   \n",
       "13    2019-08-08        TR 203            180          PNHSIN          57   \n",
       "14    2019-08-09        TR 203            180          PNHSIN          56   \n",
       "15    2019-08-10        TR 203            180          PNHSIN          63   \n",
       "16    2019-08-11        TR 203            180          PNHSIN          44   \n",
       "17    2019-08-12        TR 203            180          PNHSIN          87   \n",
       "\n",
       "    AverageFare (SGD)  \n",
       "0               15.04  \n",
       "1               14.57  \n",
       "2               34.61  \n",
       "3               61.90  \n",
       "4              138.42  \n",
       "5              193.64  \n",
       "6               74.96  \n",
       "7               12.22  \n",
       "8                5.71  \n",
       "9               26.99  \n",
       "10              24.09  \n",
       "11              14.93  \n",
       "12              11.68  \n",
       "13              15.59  \n",
       "14              29.27  \n",
       "15              35.21  \n",
       "16              34.03  \n",
       "17             207.39  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data for the DataFrame\n",
    "data = {\n",
    "    'DepartureDate': [\n",
    "        '2019-08-04', '2019-08-04', '2019-08-05', '2019-08-05', '2019-08-06', '2019-08-06',\n",
    "        '2019-08-07', '2019-08-07', '2019-08-08', '2019-08-08', '2019-08-09', '2019-08-09',\n",
    "        '2019-08-10', '2019-08-10', '2019-08-11', '2019-08-11', '2019-08-12', '2019-08-12'\n",
    "    ],\n",
    "    'Flight Number': [\n",
    "        'TR 202', 'TR 203', 'TR 202', 'TR 203', 'TR 202', 'TR 203',\n",
    "        'TR 202', 'TR 203', 'TR 202', 'TR 203', 'TR 202', 'TR 203',\n",
    "        'TR 202', 'TR 203', 'TR 202', 'TR 203', 'TR 202', 'TR 203'\n",
    "    ],\n",
    "    'Seat Capacity': [180] * 18,\n",
    "    'SegmentCityPair': [\n",
    "        'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN',\n",
    "        'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN',\n",
    "        'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN', 'SINPNH', 'PNHSIN'\n",
    "    ],\n",
    "    'Seats Sold': [\n",
    "        50, 52, 59, 27, 67, 49,\n",
    "        59, 42, 54, 57, 98, 56,\n",
    "        46, 63, 38, 44, 29, 87\n",
    "    ],\n",
    "    'AverageFare (SGD)': [\n",
    "        15.04, 26.99, 14.57, 24.09, 34.61, 14.93,\n",
    "        61.90, 11.68, 138.42, 15.59, 193.64, 29.27,\n",
    "        74.96, 35.21, 12.22, 34.03, 5.71, 207.39\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Creating the DataFrame\n",
    "actual_august_metrics = pd.DataFrame(data)\n",
    "actual_august_metrics = actual_august_metrics.sort_values(by=['Flight Number', 'DepartureDate',])\n",
    "actual_august_metrics = actual_august_metrics.reset_index(drop=True)\n",
    "\n",
    "actual_august_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regression Model**\n",
    "While the regression model provides a reasonable estimate based on the available data, the predictions might not accurately reflect the reality of seat sales in August 2019 due to its limitations in handling time-dependent factors. Additionally, the limited dataset (only June 2019) further constrains the model's ability to make accurate predictions. \n",
    "\n",
    "For more accurate forecasting, especially in the airline industry where demand fluctuates based on numerous time-dependent factors, a dedicated time-series model, combined with more extensive historical data, could provide more reliable results.\n",
    "\n",
    "### **Time-Series Model**\n",
    "The time-series model offers a more accurate approach to predicting seat sales, but its effectiveness is directly tied to the quality and quantity of the historical data available. A model trained on a robust dataset that includes multiple years of data will likely outperform one that is limited to a shorter time frame. This is because long-term patterns, such as year-over-year trends, can be crucial in making accurate predictions.\n",
    "\n",
    "However, the model is not without its challenges. Time-series forecasting can be complex and may require fine-tuning to adjust to sudden changes in the market, such as economic downturns, unexpected events, or changes in customer behavior. Additionally, the model may need to be regularly updated with new data to maintain its accuracy over time.\n",
    "\n",
    "Therefore, while the prediction of exceeding 180 seats could indicate a proactive strategy to maximize revenue, it also highlights the importance of closely monitoring the actual show-up rates and being prepared with contingency plans to manage any potential overbooking fallout.\n",
    "\n",
    "### **Remarks**\n",
    "It is also important to note that no fine-tuning was done to either model, which could prove vital in providing even better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
